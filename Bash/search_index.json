[
["index.html", "Linux学习 EHBIO Gene Technology", " Linux学习 易生信 www.ehbio.com/Training train@ehbio.com 2020-08-16 EHBIO Gene Technology "],
["linux-basic.html", "1 Linux基础内容 1.1 Linux系统简介和目录理解 1.2 Linux下文件操作 1.3 Linux终端常用快捷操作 1.4 Linux下的标准输入、输出、重定向、管道 1.5 Linux文件内容操作 1.6 Linux下的查找命令 1.7 一句话加速grep近30倍 1.8 命令运行监测 1.9 References", " 1 Linux基础内容 视频课见 http://bioinfo.ke.qq.com。 1.1 Linux系统简介和目录理解 1.1.1 为什么要用Linux系统 个人认为，Linux操作系统和类Linux操作系统的命令行界面是最适合进行生物信息分析的操作系统。原因有三点： 长期运行的稳定性 多数软件只有Linux版本 强大的Bash命令简化繁琐的操作，尤其是大大简化重复性工作 但对于初学者来说，接触和理解Linux操作系统需要一些时间和摸索。陡然从可视化点选操作的Windows进入到只有命令行界面的Linux，最大的陌生感是不知道做什么，不知道文件在哪？ 我们这篇教程就带大家学习、熟悉、体会Linux系统的使用。 1.1.2 Linux系统简介 Linux是一种多用户、多任务的操作系统。最开始是由Linus Torvalds与1991年发布，后由社区维护，产生了不同的分发版。 常见版本有Centos, Ubuntu, RedHat, Debian等。服务器多用Centos系统，免费，稳定，但更新慢。Ubuntu系统更新快，注重界面的体验，适合自己笔记本安装。有面向中国的“麒麟”系统。其它两个没用过，Centos与RedHat, Debian与Ubuntu同宗，命令行操作起来很相似。 1.1.3 如何获取Linux系统 如果自己的单位有共有服务器，可以尝试申请账号。 自己的电脑安装双系统或虚拟机。 使用gitforwindows在windows下模拟使用Linux命令。 购买一块云服务器 试验下在线学习平台实验楼 https://www.shiyanlou.com (里面也有不少Linux教程，任意点一个进去，双击桌面的Xfce图标，都可以启动Linux终端) 1.1.4 Linux系统登录 登录服务器的IP是：192.168.1.107; 端口是：22；用户名是每个人的姓名全拼，如陈同为chentong (全小写，无空格)；密码是 yishengxin。 Figure 1.1: 配置Xshell登录服务器1。 Figure 1.2: 配置Xshell登录服务器2。 1.1.5 初识Linux系统 既然用Linux，我们就摒弃界面操作，体验其命令行的魅力和庞大。后续操作都是在命令行下进行的，主要靠键盘，少数靠鼠标。 登录Linux系统后，呈现在眼前的是这样一个界面: 首先解释下出现的这几个字母和符号: ct: 用户名 ehbio：如果是登录的远程服务器，则为宿主机的名字；若是本地电脑，则为自己电脑的名字。 ~: 代表家目录, 在我们进入新的目录后，这个地方会跟着改变 $: 用来指示普通用户输入命令的地方；对根用户来说一般是# http://bashrcgenerator.com/可视化定制不同的显示方式。 个人习惯的展示：PS1=\\[\\e]0;\\u@\\h: \\w\\a\\]${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ 1.1.6 我的电脑在哪？ 打开Windows，首先看到的是桌面；不爱整理文件的我，桌面的东西已经多到需要2个屏幕才能显示的完。另外一个常用的就是我的电脑，然后打开D盘，依次点开对应的文件夹，然后点开文件。 Linux的文件系统组织方式与Windows略有不同，登录进去就是家目录，可视为Windows下的桌面[^Linux的家目录严格来说可能类似于Windows下的`C:\\\\Users\\\\ct`]。在这个目录下，我们可以新建文件、新建文件夹，就像在桌面上的操作一样。 而Linux的完整目录结构如下： Figure 1.3: Linux目录层级结构。 Table 1.1: Linux下目录简介 Path Description / 根目录 /bin 常用软件如ls, mkdir, top等的存放地 /dev 硬件相关 /etc 存放系统管理和配置相关文件 /etc/cron* 与定时任务相关的文件夹，可执行程序放置到对应文件夹就可以定时执行 /etc/profile.d 目录下存放Bash相关的配置文件，相当于全局的.bashrc /etc/profile.d/custom.sh 我在配置全局环境时，一般写入这个文件；如果不存在，可以新建。 /home 家目录，默认新建用户的个人家目录都在此文件夹下 /home/ct 用户名为ct的用户的家目录 /lib -&gt; usr/lib 存放动态库的目录 (library)，安装软件时碰到依赖的动态库一般存储于此 /lib64 -&gt; usr/lib64 64位软件动态库，-&gt; 表示软连接，等同于快捷方式 /mnt 文件系统挂载，一般插入U盘会显示在这。 /opt 部分额外安装的软件会置于此 /root 根用户的家目录 /sbin -&gt; usr/sbin 根用户的管理命令 /tmp 临时目录，会定时清空，常用于存放中间文件 /usr 存放系统应用的目录，前面有几个目录都是该目录下子目录的软链 /usr/bin 大部分应用程序安装于此 /usr/sbin 根用户的管理命令 /usr/lib 存放动态库的目录 (library)，安装软件时碰到依赖的动态库一般存储于此 /usr/lib64 64位软件动态库 /usr/local/bin 存放本地安装的命令 /usr/local/lib 存放本地安装的库 /var 存放各服务的日志文件。若装有网络服务，一般在/var/www/html下。 作为一个普通用户，通常只在/home/usr, /tmp下有可写的权限，其它目录最多是可读、可执行，部分目录连读的权限都没有。这种权限管理方式是Linux能成为真正多用户系统的一个原因。后面我们会讲解如何查看并修改这些权限。 1.1.7 硬件信息查看 看完目录结构了，来看一下硬盘有多大，有多少可用空间，只需要运行df -h命令。 除了看硬盘，还想看下CPU、内存、操作系统呢？ Hostname is localhost.localdomain,Ip address is 192.168.1.30. The 64 bit operating system is CentOS release 6.9 (Final), Nuclear info is 2.6.32-696.10.1.el6.x86_64. The CPU is Intel(R) Xeon(R) CPU E9-5799 v2 @ 3.90GHz. There are 8 physical cpu, each physical cpu has 0 cores, 0 threads. There are 96 logical cpu. The memory of this server is 252G. 1.1.8 目录内容查看 通常登陆后直接进入家目录，下面大部分操作也是在家目录下完成的。如果想查看当前目录下都有什么内容，输入命令 ls，回车即可 (ls可以理解为单词list的缩写)。当前目录下什么也没有，所以没有任何输出。 如果错把l看成了i，输入了is，则会出现下面的提示未找到命令。如果输入的是Linux基本命令，出现这个提示，基本可以判定是命令输入错了，瞪大眼睛仔细看就是了。 在敲完命令回车后，注意查看终端的输出，以判断是否有问题。 当前目录下只有一个文件，看不出效果，我们可以新建几个文件和文件夹。 1.1.9 新建目录 mkdir是新建一个目录 (make a directory)；data是目录的名字。 如果目录存在，则会出现提示，“无法创建已存在的目录”。这时可以使用参数-p忽略这个错误。 cat是一个命令，主要用来查看文件；在这与&lt;&lt;END连用用于读入大段数据。输入cat &lt;&lt;END之后，回车，会看到终端出现一个大于号，大于号后面可以输入内容，再回车，继续输入内容，直到我们输入END (大写的，与上面一致)，输入过程结束，我们输入的内容都显示在了屏幕上。 如果我们想把这些内容写入文件，就需要使用 command &gt; filename格式。 &gt;是一个重定向符号，即把前面命令的输出写入到&gt;后面的文件中。如下所示，新建了一个Fasta格式的文件。 ls -l列出文件的详细信息；-l表示命令行参数，是程序预留的一些选项，保证在不更改程序的情况下获得更灵活的操作。可使用man ls查看ls所有的命令行参数, 上下箭头翻页，按q退出查看。(man: manual, 手册) 1.1.10 访问文件 查看写入的文件的内容，cat 文件名；需要注意的是文件所在的目录，默认是当前目录；如下面第一个命令，会提示cat: test.fa: 没有那个文件或目录，是因为当前目录下不存在文件test.fa。(注意文件末尾的end) test.fa在目录data下，可以先进入data目录，然后再查看文件。类比于Windows下先点开一个文件夹，再点开下面的文件。 这个例子中文件test.fa在当前目录的子目录data里面，在当前目录下直接查看test.fa就像在我的电脑里面不进入C盘，就像打开Program file文件夹。这属于隔空打牛的境界，不是一般人能练就的。起码Linux下不可以。 提到目录，Linux下有绝对路径和相对路径的概念。 绝对路径：以/开头的路径为绝对路径，如/home/ct, /usr/bin, /home/ct/data等。需要注意的是~/data等同于/home/ct/data, 多数情况下可以等同于绝对路径，但在一个情况下例外，软件安装时用于--prefix后的路径必须是/开头的绝对路径。 相对路径: 不以/和~开头的路径都是相对路径，如data表示当前目录下的data目录，等同于./data (.为当前目录), ../data表示当前目录的上一层目录下的data目录 (../表示上层目录)。 pwd (print working directory) 获取当前工作目录。 cd (change dir)切换目录。若cd后没有指定切换到那个目录，则调回家目录。特别地，cd -表示返回到最近的cd操作前所在目录，相当于回撤到上一个工作目录。 head查看文件最开始的几行，默认为10行，可使用-n 6指定查看前6行。 另外less和more也可以用来查看文件，尤其是文件内容特别多的时候。 1.1.11 获取可用命令行参数 前面使用的命令，有几个用到了参数如ls -l, head -n 6等，需要注意的是命令跟参数之间要有空格。 终端运行man ls可以查看ls所有可用的参数，上下箭头翻页，按q退出查看。(man: manual, 手册) 1.1.12 小结 Linux是多用户操作系统。这一点可以从我们每个人能同时登录到同一台Linux电脑各自进行操作而不相互干扰可以体会出来。大家可以尝试下是否可以看到其它人家目录下的东西。我们后期在权限管理部分会涉及如何开放或限制自己的文件被他人访问。 Linux下所有目录都在根目录下。根目录某种程度上可类比于Windows的我的电脑，第一级子目录类比于C盘，D盘等 (等我们熟练了，就忘记这个拙劣的类比吧)。 使用mkdir新建目录，cd切换目录，pwd获取当前工作目录，ls查看目录下的内容, cat查看文件，man ls查看ls命令的使用。 访问一个文件需要指定这个文件的路径，当前目录下的文件可省略其路径./，其它目录下则需要指定全路径 (可以是相对路径，也可以是绝对路径)。 1.1.13 练习题 在家目录下新建文件夹bin和soft。 在bin和soft目录下各自新建一个文件，名字都是README。 在bin/README文件中写入内容：This folder is used to save executable files。 在soft/README文件中写入内容：This folder is used to save software source files。 查看两个README文件的大小。 1.2 Linux下文件操作 1.2.1 文件上下翻转和左右翻转 两个有意思的命令，tac: 文件翻转，第一行变为最后一行，第二行变为倒数第二行；rev每列反转，第一个字符变为最后一个字符，第二个字符变为倒数第二个字符。 1.2.2 其它新建文件的方式 nano类似于Windows下记事本的功能，nano filename就可以新建一个文件，并在里面写内容；ctrl+x退出，根据提示按Y保存。 vim 功能更强大的文本编辑器。vim filename就可以新建一个文件, 敲击键盘字母i，进入写作模式。写完后，敲击键盘Esc, 退出写作模式，然后输入:w (会显示在屏幕左下角)，回车保存。vim的常用方法，后面会有单独介绍。 1.2.3 文件拷贝、移动、重命名 常用的文件操作有移动文件到另一个文件夹、复制文件到另一个文件夹、文件重命名等。 cp (copy): 拷贝文件或文件夹 (cp -r 拷贝文件夹时的参数，递归拷贝). cp source1 source2 ... target_dir 将一个或多个源文件或者目录复制到已经存在的目标目录。 cp常用参数 -r: 递归拷贝 -f: 强制覆盖 -i: 覆盖前先询问 -p: 保留文件或目录的属性，主要是时间戳 -b: 备份复制，若目标文件存在，先备份之前的，再把新的覆盖过去 -u: 更新复制，若源文件和目标文件都存在，只在源文件的修改时间比较新时才复制 mv (move): 移动文件或文件夹 mv source target, 常用参数有 -f: 强制覆盖 -i: 覆盖前询问 -u: 更新移动 rename: 文件重命名 (常用于批量重命名，不同的系统可能用法略有不同，使用前先man rename查看使用方法) ln (link): 给文件建立快捷方式 (ln -s source_file target 创建软连接)。 在建立软连接时，原文件要使用全路径。全路径指以/开头的路径。如果希望软链可以让不同的用户访问，不要使用~。 建立软连接，是为了在不增加硬盘存储的情况下，简化文件访问方式的一个办法。把其它文件夹下的文件链接到当前目录，使用时只需要写文件的名字就可以了，不需要再写长串的目录了。 ln命令常用参数 -s: 软连接 -f: 强制创建 ../: 表示上一层目录；../../: 表示上面两层目录 pwd (print current/working directory): 输出当前所在的目录 \\``为键盘Esc下第一个按键 (与家目录~`符号同一个键)，写在反引号内的命令会被运行，运行结果会放置在反引号所在的位置 使用全路径名，尤其使用家目录 ~ 符号时，只限操作用户自身有效。另外不同用户之间建立软连接，需要考虑访问权限问题，任意一层目录都需要可读权限 (目录的可读为rx都有)。 复制、移动或创建软连接时，如果目标已存在，除了使用-f强制覆盖外，还可以使用rm命令删除。 rm可以删除一个或多个文件和目录，也可以递归删除所有子目录，使用时一定要慎重。rm命令删除的文件很难恢复。 rm -rf *: 可以删除当前目录下所有文件和文件夹，慎用。 rm命令常见参数： -f：强制删除 -i: 删除前询问是否删除 -r: 递归删除 1.2.4 Linux下命令的一些异常情况 命令不全：在命令没有输入完 (引号或括号没有配对)，就不小心按下了Enter键，终端会提示出一个&gt;代表命令不完整，这是可以继续输入，也可以ctrl+c终止输入，重新再来。(下面sed命令使用时，还有另外一种命令不全的问题) 文件名输入错误: 多一个字母、少一个字母、大小写问题 所在目录不对: 访问的文件不存在于当前目录，而又没有提供绝对路径, 或软连接失效 1.2.5 Linux下文件内容操作 常用的文件内容操作有文件压缩解压缩、文件大小行数统计、文件内容查询等。 gzip: 压缩文件; gunzip: 解压缩文件 wc (word count): 一般使用wc -l获取文件的行数。 获取文件中包含大于号 (&gt;)的行, grep (print lines matching a pattern，对每一行进行模式匹配)。 grep的用法很多，支持正则表达式匹配，这个后面我们会详细讲解。 替换文件中的字符: sed是一个功能强大的文件内容编辑工具，常用于替换、取得行号等操作。现在先有个认识，后面会详细介绍。 | 为管道符，在相邻命令之间传递数据流，表示把上一个命令的输出作为下一个命令的输入。 另外一个方式，去除HAHA，使用cut命令。cut更适合于矩阵操作，去除其中的一列或者多列。但在处理FASTA格式文件时有这么一个妙用。FASTA文件中序列里面是没有任何符号的，而如果名字比较长，则可以指定相应分隔符就行cut，这样既处理了名字，又保留了序列。 -f: 指定取出哪一列，使用方法为-f 2 (取出第2列)，-f 2-5 (取出第2-5列)，-f 2,5 (取出第2和第5列)。注意不同符号之间的区别。 -d: 设定分隔符, 默认为TAB键。如果某一行没有指定的分隔符，整行都为第一列。 1.2.6 小结和练习 Linux下文件拷贝、移动、重命名、软连接、压缩、替换等操作。 Linux下常见问题 ehbio2.fa: 没有那个文件或目录：这个错误通常由什么引起，应该怎么解决？ 若文件a存在，运行ln a data/b能否成功给a建立软连接？ grep '&gt; ehbio.fa的输出是什么？ 若目标文件存在时，再运行cp, mv或ln会有什么提示？ 计算某一个Fasta序列中序列的个数。 1.3 Linux终端常用快捷操作 命令或文件名自动补全：在输入命令或文件名的前几个字母后，按Tab键，系统会自动补全或提示补全 上下箭头：使用上下箭头可以回溯之前的命令，增加命令的重用，减少输入工作量 !加之前输入过的命令的前几个字母，快速获取前面的命令 ctrl+a回到命令的行首，ctrl+e到命令行尾，(home和end也有类似功能)，用于修改命令或注释掉命令 !! 表示上一条命令。 替换上一个命令中的字符，再运行一遍命令，用于需要对多个文件执行同样的命令，又不想写循环的情况 1.4 Linux下的标准输入、输出、重定向、管道 在Linux系统中，有4个特殊的符号，&lt;, &gt;, |, -，在我们处理输入和输出时存在重要但具有迷惑性的作用。 默认Linux的命令的结果都是输出到标准输出，错误信息 (比如命令未找到或文件格式识别错误等) 输出到标准错误，而标准输出和标准错误默认都会显示到屏幕上。 &gt;表示重定向标准输出，&gt; filename就是把标准输出存储到文件filename里面。标准错误还是会显示在屏幕上。 2 &gt;&amp;1 表示把标准错误重定向到标准输出。Linux终端用2表示标准错误，1表示标准输出。 - (短横线)：表示标准输入，一般用于1个程序需要多个输入的时候。 &lt; 标准输入，后面可以跟可以产生输出的命令，一般用于1个程序需要多个输入的时候。相比-适用范围更广。 |管道符，表示把前一个命令的输出作为后一个命令的输入，前面也有一些展示例子。用于数据在不同的命令之间传输，用途是减少硬盘存取损耗。 下面我们通过一个程序stdout_error.sh来解释上面的文字 (Bash脚本写作，后面会有专门介绍)，内容如下 运行这个脚本 下面看管道符和标准输入的使用。 管道符的更多应用 1.5 Linux文件内容操作 1.5.1 文件生成 seq: 产生一系列的数字; man seq查看其具体使用。我们这使用seq产生下游分析所用到的输入文件。 1.5.2 文件排序 sort: 排序，默认按字符编码排序。如果想按数字大小排序，需添加-n参数。 sort常用参数 -n: 数值排序 -h: 人类刻度的数值排序 (2K 1G等) -r: reverse, 逆序 -c: check, 不排序，查看文件是否已排序好 -k: 指定使用哪列或哪几列排序 -m: 合并已经排序好的文件 -S: 缓冲区大小，用于排序大文件时的分割排序中每次分割的文件大小 -u: 重复行只保留一次 sort -u: 去除重复的行，等同于sort | uniq。 sort file | uniq -d: 获得重复的行。(d=duplication) sort file | uniq -c: 获得每行重复的次数。 整理下uniq -c的结果，使得原始行在前，每行的计数在后。 awk是一个强大的文本处理工具，其处理数据模式为按行处理。每次读入一行，进行操作。 OFS: 输出文件的列分隔符 (output file column separtor)； FS为输入文件的列分隔符 (默认为空白字符)； awk中的列从第1到n列，分别记录为$1, $2 … $n； BEGIN表示在文件读取前先设置基本参数；与之相对应的是END，只文件读取完成之后进行操作； 不以BEGIN, END开头的{}就是文件读取、处理的部分。每次对一行进行处理。后面会详细讲解。 对两列文件，按照第二列进行排序, sort -k2,2n。 1.5.3 FASTA序列提取 生成单行序列FASTA文件，提取特定基因的序列，最简单的是使用grep命令。 grep在前面也提到过，以后还会经常提到，主要用途是匹配文件中的字符串，以此为基础，进行一系列的操作。如果会使用正则表达式，将会非常强大。正则表达式版本很多，几乎每种语言都有自己的规则，后面会详细展开。 多行FASTA序列提取要麻烦些，一个办法就是转成单行序列，用上面的方式处理。 sed和tr都为最常用的字符替换工具。 &gt;SOX2 ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGAC &gt;POU5F1 CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGT CGGAAGGTAGTCGTCAGTGCAGCGAGTCC &gt;NANOG ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGG ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGT # &gt;号前面加换行符 ct@ehbio:~$ cat test.fasta | tr &#39;\\n&#39; &#39;\\t&#39; | sed &#39;s/\\t&gt;/\\n&gt;/g&#39; &gt;SOX2 ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGAC &gt;POU5F1 CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGT CGGAAGGTAGTCGTCAGTGCAGCGAGTCC &gt;NANOG ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGG ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGT # 先把第一个TAB键变为换行符，实现序列名字和序列的分离 # 再去掉序列中所有的TAB键 ct@ehbio:~$ cat test.fasta | tr &#39;\\n&#39; &#39;\\t&#39; | sed &#39;s/\\t&gt;/\\n&gt;/g&#39; \\ | sed &#39;s/\\t/\\n/&#39; | sed &#39;s/\\t//g&#39; &gt;test.oneline.fa &gt;SOX2 ACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGAC &gt;POU5F1 CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGTCGGAAGGTAGTCGTCAGTGCAGCGAGTCC &gt;NANOG ACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGACTGT 或者简单点，直接用前面的awk略微做下修改。 1.6 Linux下的查找命令 查找是我们每天都在做的事情，早上醒来找下手机，出门之前查下公交，坐下之后查下资料，分析数据查下模式。 查找文件，查找信息，查找错误是应用起来更为具体的一些工作，而Linux命令行为我们提供了很多快捷强大的查找方式。 1.6.1 命令/可执行程序查找 whereis program_name: 会在系统默认安装目录(一般是有root权限时默认安装的软件)和$PATH, $MANPATH指定的目录中查找二进制文件、源码、文档中包含给定查询关键词的文件。(默认目录有 /bin, /sbin, /usr/bin, /usr/lib, /usr/local/man等类似路径) which program_name: 会给出所有在环境变量中的程序的路径，一来方便知道运行的程序在哪，二来方便修改。比如vim `which sp_pheatmap.sh`就可以直接修改绘制热图的脚本，cp \\which sp_pheatmap.sh` .`可以直接把源码拷贝到当前目录，省去了写全路径的麻烦。 如果运行which bwa，系统返回是 /usr/bin/which: no bwa in (/home/usr/bin:/bin)则说明bwa没有安装或安装后没有放置在环境变量中，不可以直接写名字调用。 1.6.2 普通文件快速定位 locate locate是快速查找定位文件的好方法，但其依赖于updatedb建立的索引。而updatedb一般是每天运行一次，所以当天新建的文件是索引不到的。如果有根用户权限，可以手动运行updatedb做个更新，然后再locate bwa。(个人用户也可以构建自己的updatedb, 使用locate在局部环境中查找。) ct@ehbio:~$ locate R.sys /soft/R.sys 1.6.3 普通文件多条件查找 find find / -name bwa可以搜索根目录下所有名字为bwa的文件 运行上面的命令时会输出很多Permission denied，是因为 作为普通用户，无权限访问一些目录，因此会有提示输出，可以使用find / -name bwa 2&gt;/dev/null重定向标准错误到空设备，报错信息就被扔掉了，还不影响正常输出。 ct@ehbio:~$ find / -name R 2&gt;/dev/null /usr/bin/R /usr/lib/rstudio-server/R /usr/share/groff/1.22.2/font/devascii/R /usr/share/groff/1.22.2/font/devhtml/R /usr/share/groff/1.22.2/font/devlatin1/R /usr/share/groff/1.22.2/font/devutf8/R /usr/local/bin/R /usr/local/lib64/R /usr/local/lib64/R/share/R /usr/local/lib64/R/bin/R 1.6.3.1 按时间查找 我们开发的在线画图网站 (www.ehbio.com/ImageGP)，为了追踪每天用户使用时碰到了什么问题，需要每天定时去查看日志。 这个命令find . -name *.log -mmin -60可以查看当前目录下(包括所有子目录)一小时内修改的日志文件。再配合head就可以查看每个日志文件的内容，以方便查看使用过程中出现了哪些错误，如何增加提示或修改画图程序。 正是有了这个利器，前台的错误提示中才出现了这么一句话，如果您核对后数据和参数没问题，请过1天再进行尝试。若是程序问题，我们通常会在1天内修复。 当然后台数据都是用时间戳存储的，而且若无报错，数据会直接删掉，有报错的才会保留日志，不会泄露用户信息，这点大家不用担心。 现在画图网站越来越稳定，出现的问题越来越少，前台提示也越来越完善，希望大家使用时多看下提示，查看日志的频率也少了，就使用find . -name *.log -mtime -1查看从现在起24小时内的日志了。 这个也有个问题，每次查看的时间可能不一致，会漏查或有重叠，于是在某次查看完日志后，使用touch check在当前目录下新建了个空文件。以后再查日志文件时，只要使用find . -name *.log -newer check就可以获得所有上次查看过之后的新日志。每次查看完之后，都做个书签，就方便多了。 慢慢发现有空日志文件, 使用find . -name *.log -newer check -size +0过滤掉, 只保留大小大于0的文件。就这样在小伙伴聪明勤奋地维持下，我们绘图网站为7万多用户提供了近100万次服务 (画图手册 | ImageGP：今天你“plot”了吗？)。 1.6.3.2 按类型和大小查找 如果我想得到当前目录下所有png和jpg照片呢？ 使用 find . \\( -name \"*.png\" -o -name \"*.jpg\" \\) | less 或 find . -regex \".*\\(\\.png\\|\\.jpg\\)$\" find . -type f -size +100G可以获取大小超过100G的文件。 1.6.3.3 限制查找深度 只看当前目录2层子目录内的文件find . -maxdepth 2 -name *.log。 查看不是log结尾的文件find . -not -name *.log。还有更多组合操作，详见find文档。 1.6.4 按文件内容查找 grep find可以查找包含某句话的文件吗？ 还是拿我们的日志说事吧，find . -name *.log -exec grep -l 'Error' {} \\;就可以返回所有包含Error单词的文件名。 find . -name *.log | xargs grep -l 'Error'也可以。 grep -rl 'Error' *也可以，不加-l还可以顺便返回匹配的行。 匹配行的前后行 grep -A 5 -B 1 'Bioinfo' ehbio.log可以查看匹配行的前1行(B, before)和后5行(A, after)。 匹配次数 grep -c 'Bioinfo' ehbio.log可以统计包含Bioinfo的行数 grep -ci 'Bioinfo' ehbio.log则会在匹配时忽略大小写。 统计FASTA序列中的序列数 grep '^&gt;' ehbio.fa 统计FASTQ序列中的序列数 grep '^+$' ehbio.fq。(^表示以什么开头，$表示以什么结尾)。 获取未匹配行 grep -v 'Bioinfo' ehbio.log，读读手册(man grep)，可以看到更多参数使用。 序列提取 假设有个基因列表文件 (ID)，有个单行序列的FASTA文件 (ehbio.fa)， 运行如下命令grep -A 1 -Fw -f id ehbio.fa | grep -v -- '--'就可以批量提取序列了。 -f id表示把id文件中的每一行作为一个匹配模式。-F表示匹配模式作为原始字符串，而非正则表达式，这是以防有特殊字符被解析。-w则表示作为一个单词匹配，即假如id中有Sox2，那么它会匹配Sox2，也会匹配Sox21；如果加了-w，则不会匹配Sox21。 更好的序列批量提取见 awk的使用。 模式匹配 grep强大的功能是支持正则匹配，默认使用基本正则表达式，-E使用扩展的正则表达式，-P使用perl格式的正则表达式。 比如想去掉文件中所有的空行grep -v '^$' ehbio.fa &gt;ehbio.clean.fa; 从公众号文章中搜索跟文章写作相关的文章 grep 'writ.*' *.md (可以匹配write, writing等字)； 正则表达式就比较多了，具体可以看http://mp.weixin.qq.com/s/4lUiZ60-aXLilRk9--iQhA。 1.7 一句话加速grep近30倍 最近做一个项目，需要从表达矩阵中提取单个特定基因的表达值。最开始时文件比较小，使用awk单个读取处理也很快，但后来数据多了，从一个1.2 G的文件中提取单个基因的表达需要30 s，用grep来写需要25 S，这在平时写程序是可以接受的，但在网站上是接受不了的。所以就想着如何优化一下。 探索下来优化也很简单，把grep换为LC_ALL=C grep再加其它参数速度就快了近30倍，把时间控制在1 s左右。 下面是整个探索过程 （写这篇总结文章是在早晨，服务器不繁忙，所以下面的示例中只能看出来快了5倍左右。这也表明不加LC_All=C时grep受服务器负载影响较大，加了之后则几乎不受影响。） 1.7.1 获取单基因表达量 查看下文件大小 ls -sh 334d41a7-e34a-4bab-841c-eb07bd84513f.txt # 1.2G 334d41a7-e34a-4bab-841c-eb07bd84513f.txt 查看下文件内容 head 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | cut -f 1,2 # Rnu2-1 -0.52 # Tmsb4Xp6 11.81 # S100A14 1.99 # Krt17 1.26 # Aldh1A1 6.92 # Fxyd3 0.56 # Rnu2-2P 0.35 # Rarres1 6.03 # Rnvu1-7 9.53 # Lcn2 3.44 假设基因名字大小写一致时使用awk提取其表达信息，用时14 s。 time awk &#39;{if($1==&quot;Tmsb4Xp6&quot;) print $2;}&#39; 334d41a7-e34a-4bab-841c-eb07bd84513f.txt &gt;1 real 0m14.569s user 0m12.943s sys 0m0.626s 实际上大小写可能不一致而需要转换，耗时17 s。 time awk &#39;{if(tolower($1)==&quot;tmsb4xp6&quot;) print $2;}&#39; 334d41a7-e34a-4bab-841c-eb07bd84513f.txt &gt;2 real 0m17.638s user 0m17.031s sys 0m0.595s 采用grep命令提取 (-i忽略大小写)，用时5 s。 time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | grep -i &#39;Tmsb4Xp6&#39; &gt;4 real 0m5.454s user 0m5.134s sys 0m1.272s 上面的grep是全句匹配，想着加上^匹配行首是否会减少匹配量，速度能快一些，效果不明显，用时4 s。 time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | grep -iP &#39;^Tmsb4Xp6&#39; &gt;5 real 0m4.262s user 0m3.984s sys 0m1.233s grep是处理匹配关系，获得的是包含关键词但不一定全等于关键词，加一个-w参数，匹配更精确些，耗时6.7 s。 time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | grep -iPw &#39;^Tmsb4Xp6&#39; &gt;6 real 0m6.723s user 0m6.390s sys 0m1.348s 从上面来看，采用正则限定并不能提速，还是采用固定字符串方式提取，速度也差不多，耗时5 s。(fgrep等同于grep -F) time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | fgrep -i &#39;Tmsb4Xp6&#39; &gt;7 real 0m5.496s user 0m5.128s sys 0m1.366s 主角出场，加上LC_ALL=C后，速度明显提升了，只需要1 s时间。 time LC_ALL=C fgrep -i &#39;^Tmsb4Xp6&#39; 334d41a7-e34a-4bab-841c-eb07bd84513f.txt &gt;8 real 0m1.027s user 0m0.671s sys 0m0.355s 多次测试下来，发现添加LC_ALL=C后grep命令快了很多，而且多次测试速度都很稳定 (不论服务器是繁忙还是空闲)。这里面的原理是涉及字符搜索空间的问题，我们操作的文件只包含字母、字符、数字，没有中文或其它复杂符号时都是适用的，具体原理和更多评估可查看文末的两篇参考链接，了解更多信息。 为了简化应用，我们可以alias grep='LC_ALL=C grep' (把这句话放到~/.bashrc或~/.bahs_profile里面)，后续再使用grep时就可以直接得到速度提升了。 time grep -F -i &#39;^Tmsb4Xp6&#39; 334d41a7-e34a-4bab-841c-eb07bd84513f.txt real 0m1.013s user 0m0.679s sys 0m0.334s 1.7.2 那如果获取多个基因怎么操作呢？ 一个方式是使用正则表达式，多个基因一起传递过去，分别匹配，耗时4.6 s。 time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | LC_ALL=C grep -iP &#39;Tmsb4Xp6|Sox1|Sox2|Sox3&#39; real 0m4.654s user 0m4.366s sys 0m1.227s 或者还是使用固定字符串查找模式，把所有基因每行一个写入文件a，然后再去匹配，耗时2.5 s，且测试发现在基因数目少于10时（这是通常的应用场景），基因多少影响不大 (这也说明能用固定字符串查找时最好显示指定)。 time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | LC_ALL=C fgrep -i -f a &gt;11 real 0m2.539s user 0m2.191s sys 0m1.249s 这里还比较了另外2个号称比grep快的命令ag和rg在这个应用场景没体现出性能优势。 time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | LC_ALL=C ag -i &#39;^Tmsb4Xp6|Sox1|Sox2|Sox3&#39; &gt;10 real 0m11.281s user 0m9.713s sys 0m5.326s time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | rg -iF -f a &gt;12 real 0m4.337s user 0m3.444s sys 0m2.787s https://www.inmotionhosting.com/support/website/speed-up-grep-searches-with-lc-all/ https://stackoverflow.com/questions/42239179/fastest-way-to-find-lines-of-a-file-from-another-larger-file-in-bash# 1.8 命令运行监测 监测命令的运行时间 time command ct@ehbio:~$ time sleep 5 real 0m5.003s # 程序开始至结束的时间，包括其它进程占用的时间片和IO时间 user 0m0.001s # 进程真正执行占用CPU的时间, sys 0m0.002s # 进程在内核中调用所消耗的CPU时间 user+sys是进程实际的CPU时间。如果多线程执行，这个时间可能大于Real。如果IO是瓶颈，则real会大于user+sys (单线程)。 查看正在运行的命令和其资源使用 top top输出界面第一行主要信息是负载显示，分别是1分钟、5分钟、15分钟前到现在的任务队列的平均长度。 一般与CPU数目相当为好，过大系统负载超额，反应慢。 在top输出界面输入 u, 会提示输入用户名，以查看某个用户的进程。 重点关注的是%MEM列，查看系统占用的内存是否超出。 ct@ehbio:~$ top -a #按内存排序显示 top - 09:02:11 up 224 days, 8:34, 30 users, load average: 40, 33, 28 Tasks: 1561 total, 1 running, 1550 sleeping, 0 stopped, 10 zombie Cpu(s): 0.6%us, 0.2%sy, 0.0%ni, 99.2%id, 0.0%wa, 0.0%hi, 0.0%si, 0.0%st Mem: 2642768880k total, 2094619800k used, 548149080k free, 4310240k buffers Swap: 86472700k total, 73226016k used, 13246684k free, 193383748k cached PID USER PR NI VIRT RES SHR S %CPU %MEM TIME+ COMMAND 32527 ct 20 0 2631m 1.7g 1332 S 0.0 0.7 100:34.87 rsem-run-em 29273 ct 20 0 4094m 692m 3396 S 0.0 0.3 45:18.83 java -Xmx1000m 40148 mysql 20 0 21.9g 606m 6116 S 1.3 0.2 2536:06 /usr/sbin/mysqld 31040 ct 20 0 1887m 77m 2604 S 0.3 0.0 180:43.16 [celeryd: 查看系统进程 ps auwx | grep 'process_name' 1.9 References 原文链接 http://blog.genesino.com//2017/06/bash1/ 微信公众号 http://mp.weixin.qq.com/s/yKP1Kboji9N4p2Sl1Ovj0Q Linux-总目录 Linux-文件和目录 Linux-文件操作 Linux文件内容操作 Linux-环境变量和可执行属性 Linux - 管道、标准输入输出 Linux - 命令运行监测和软件安装 Linux-常见错误和快捷操作 Linux-文件列太多，很难识别想要的信息在哪列；别焦急，看这里。 Linux-文件排序和FASTA文件操作 Linux-应用Docker安装软件 Linux服务器数据定期同步和备份方式 VIM的强大文本处理方法 Linux - Conda软件安装方法 查看服务器配置信息 Linux - SED操作，awk的姊妹篇 Linux - 常用和不太常用的实用awk命令 Bash概论 - Linux系列教程补充篇 原来你是这样的软连接 一网打进Linux下那些查找命令 有了这些，文件批量重命名还需要求助其它工具吗？ "],
["softinstall.html", "2 Linux下软件安装相关 2.1 文件属性和可执行属性 2.2 PATH和path，傻傻分不清 2.3 软件安装的几种传统方式 2.4 Conda安装配置生物信息软件 2.5 Docker安装 2.6 Makefile知识 2.7 References", " 2 Linux下软件安装相关 视频课见 http://bioinfo.ke.qq.com。 软件安装的几个概念：环境变量、可执行属性、编译安装、Conda安装。 2.1 文件属性和可执行属性 2.1.1 文件属性 文件属性rwx中r表示read (数字表示为4)、w表示write (数字表示为2)、x表示执行 (数字表示为1)。三个为一组，连续出现三次(如下面命令行中所示), 第一组表示文件的所有者拥有的权限，第二组为文件所有者所在的用户组所拥有的权限，组内所有成员都具有的权限，第三组为其它用户的权限。 chmod可以修改文件或文件夹属性。 2.1.2 可执行属性 Linux下文件有一个特殊的属性即可执行属性，用来指示这个文件是一个可执行的脚本或可以运行的二进制文件。前面所提到的这些命令，都具有可执行属性。 which: 表示查看命令的路径。一般用于当我们想知道使用的命令来源于什么地方时，比如安装了多个R或多个python，但又分不清用的是哪个时，which一下，立即明了。在这儿我们用which获取的是可执行的命令所在的路径，进而查看其属性。 chmod a+x file: 表示给文件增加所有人(a)可执行权限 (+x) chmod u+x file: 表示给文件增加所有者(u，user，)可执行权限 (+x) chmod g+x, chmod o+X: 表示给文件增加组内人或其它人可执行权限 chmod 755 file: 表示拥有者有可读写执行权限，其它人有可读执行权限。(7=4+2+1; 5=4+1) 具体使用man chmod查看其它参数使用。 如果一个文件有了可执行权限，是不是就可以执行了，我们来检测下。 事实上并非如此，输入命令，回车后，提示命令未找打，这是为什么呢？ 这就涉及到环境变量的概念，通俗的讲，环境变量就是告诉电脑 (实际是操作系统)几个目录。这几个目录下存储又可执行文件，如前面显示的/usr/bin目录，大部分的系统命令都在这个目录下。 2.2 PATH和path，傻傻分不清 习惯了Windows电脑下的所见即所得，找到程序或文件双击即可运行或打开；于是我们被惯得以为电脑会像人一样聪明，给他一个名字就可以运行程序或打开文件；于是在命令行下或程序里不断碰壁，为啥这个命令不运行了呢？ 我们不能太高估电脑（或操作系统），不要以为只要输入一个程序名或文件名，电脑（或操作系统）就可以满硬盘的去找这个文件在哪；这一来效率太低了，二来重名了怎么办？比如有2个文件都叫“子房.txt”，一个存储汉初三杰之张良，一个存储被子植物生长种子的器官；可能打开前我们自己也不知道要开哪个吧。 想一下，我们在Windows下寻找文件时，是不是先打开我的电脑，然后打开D盘，打开学习目录，再打开学习计划.docx这个文件。即便我们从来没有执行过这个计划，每天我们还是不厌其烦的一层层打开然后制定新的计划。只是，我们忽略了这个一层层打开。 path我们一般指文件的路径，也就是一层层打开的过程。以Linux为例： 我们要查看一个在自己家目录下的文件 I_am_home.txt，那登录后，直接可见： YSX@ehbio:~$ tree . ├── I_am_home.txt └── train ├── amplicon │ └── pipeline_amplicon.sh ├── metagenome │ └── pipeline_metagenome.sh ├── population_genomics │ └── pipeline_gatk.sh ├── single_cell │ ├── Scanpy.ipynb │ └── Seurat.Rmd └── transcriptome └── pipeline_salmon.sh YSX@ehbio:~$ head I_am_home.txt I am home! 那如果想看Seurat.Rmd，怎么查看？一步步找下去就对了。 YSX@ehbio:~$ less Seurat.Rmd Seurat.Rmd: 没有那个文件或目录 YSX@ehbio:~$ less train/Seurat.Rmd train/Seurat.Rmd: 没有那个文件或目录 YSX@ehbio:~$ less train/single_cell/Seurat.Rmd 也可以一步步先做目录切换，然后再查看 YSX@ehbio:~$ cd train YSX@ehbio:~/train$ cd single_cell/ YSX@ehbio:~/train/single_cell$ less Seurat.Rmd 那如果你这时你想运行pipeline_metagenome.sh快速分析宏基因组数据怎么办？ YSX@ehbio:~/train/single_cell$ pipeline_metagenome.sh -bash: pipeline_metagenome.sh: 未找到命令 pipeline_metagenome.sh命令去哪儿了？上面我们都看到了，就在metagenome目录下，为啥电脑（操作系统）这么笨却找不到？另外为什么运行head就可以找到？难道有一些黑魔法在里面？ 确实是有一些黑魔法的，不过我们一般称之为规则。 操作系统为了便捷性和安全性，定义了一系列环境变量，存储常用信息，PATH (注意全是大写字母)是其中一个。 PATH: 是存放有(可执行)命令和程序的目录集合；在操作系统接到用户输入的命令时，会对PATH存储的目录进行查找，看下是否有与用户输入的命令同名的文件存在，而且是从前到后一个个查找，而且是查到就停，最后查不到就报错。（从这几个加粗的文字，可以看到操作系统很懒，当然懒是好的程序员的必备属性。） 我们先看下PATH里面存了哪些目录？ YSX@ehbio:~/train/single_cell$ echo $PATH /usr/bin:/usr/local/bin 在我们前面输入head命令时，操作系统收到回车指令后，先去看下$PATH里面有哪些目录，然后从第一个/usr/bin开始寻找，很幸运，一下找到了/usr/bin/head文件，尝试运行，成功。所以在这个情况下，我们输入head等同于输入/usr/bin/head。那这个会不会给我们一些启发呢？ 我们只要提供pipeline_metagenome.sh的路径就可以运行了。 # 相对路径 YSX@ehbio:~/train/single_cell$ ../metagenome/pipeline_metagenome.sh # 绝对路径 YSX@ehbio:~/train/single_cell$ ~/train/metagenome/pipeline_metagenome.sh # 再绝对一些 YSX@ehbio:~/train/single_cell$ /home/YSX/train/metagenome/pipeline_metagenome.sh 程序可以运行了，但是不是写起来太麻烦了？既然head可以只写命令，系统就可以帮着我们去找，那么我们是否也可以把/home/YSX/train/metagenome/放到PATH里面。这就是如何去设置环境变量了。 # 加到环境变量的路径必须是全路径，全路径指以/开头或已~开头的路径 # 注意第一个PATH不含$, 第二个PATH有$符号 # 我们后面会讲什么时候用$, 什么时候不用$ # 给原变量PATH后面加一个路径（绝对路径），冒号(:)分割 YSX@ehbio:~/train/single_cell$ PATH=$PATH:/home/YSX/train/metagenome/ # 导出变量，使其对系统（Shell）可见 YSX@ehbio:~/train/single_cell$ export PATH # 上面两句可以合并为一句，如下： YSX@ehbio:~/train/single_cell$ export PATH=$PATH:/home/YSX/train/metagenome/ # 再次运行，可以运行了 YSX@ehbio:~/train/single_cell$ pipeline_metagenome.sh # 看下PATH存储的目录，多了我们的新增 YSX@ehbio:~/train/single_cell$ echo $PATH /usr/bin:/usr/local/bin:/home/YSX/train/metagenome/ 这样就新增一个目录到环境变量里面了，可以依次继续增加更多目录。 YSX@ehbio:~/train/single_cell$ export PATH=$PATH:/home/YSX/train/metagenome/:/home/YSX/train/amplicon/ 加到环境变量的路径必须是全路径，全路径指以/开头或以~或${HOME}开头的路径 (注意：~开头的路径只能个人用户有效)。 有时我们也会看的这样的写法：export PATH=my_path:$PATH，这与export PATH=$PATH:my_path有什么区别呢？ 回顾下这几个关键字：从前到后，查到就停。写出官话就是：PATH中越靠前的路径优先级越高。这有什么用处呢？ 比如，一般的操作系统都会有系统的python和R，通常版本比较老，我们作为普通用户也没权限修改。 那怎么办？自己装一份新的python和R，然后用自己的，这时就涉及到优先级问题了。 假如我在/home/YSX/soft/anaconda/bin下安装了一个python，那么我需要设置优先调用我自己的python，设置环境变量时，我就得把/home/YSX/soft/anaconda/bin放到前面，如export PATH=/home/YSX/soft/anaconda/bin:$PATH。如果反过来写，那么/usr/bin/python就会优先被调用了。 # which 常用工具，查看当前调用的程序的具体来源 YSX@ehbio:~/train/single_cell$ which python /usr/bin/python # 优先调用自己的python YSX@ehbio:~/train/single_cell$ export PATH=/home/YSX/soft/anaconda/bin:$PATH YSX@ehbio:~/train/single_cell$ which python /home/YSX/soft/anaconda/bin/python 环境变量学会怎么设置了，关机，下班，睡觉。 第二天早上起来，打开电脑，再运行程序 YSX@ehbio:~/train/single_cell$ which python /usr/bin/python YSX@ehbio:~/train/single_cell$ pipeline_metagenome.sh -bash: pipeline_metagenome.sh: 未找到命令 结果发现昨天的设置都无效了，去生信宝典群里提问 “有谁对Linux比较精通？”。半晌，无人响应，敢说自己精通的不多。提问还是不能这么问，应该怎么问，具体见：如何优雅的提问。 后来，有好心人回复“你遇到什么问题，具体描述下？” 经过半个小时的沟通，理清了，关键点：环境变量设置后失效了，怎么长期有效？ 如果早这么问，估计程序都运行完了。 这时需要用到另一个规则: 登录远程服务器时，系统会自动运行~/.bash_profile里面的命令，所以把前面写的这句话export PATH=/home/YSX/soft/anaconda/bin:$PATH:/home/YSX/train/metagenome/:/home/YSX/train/amplicon/放到文件~/.bash_profile里面就好了。 文件输入后，不要忘记source ~/.bash_profile使设置生效（当然，关掉登录窗口，再次登录也可以）。 2.2.1 其它被忽略的事情 其它环境变量 环境变量PATH：定义可执行程序的目录 LD_LIBRARY_PATH：定义动态库的目录 PYTHONPATH：定义Python包的目录 PERL5LIB：定义Perl模块的目录 .bashrc和.bash_profile ~/.bashrc本地登录时读取 （文件若无，可新建） ~/.bash_profile远程登录时读取（文件若无，可新建） 如果想在系统层面设置环境变量，应该写到/etc/profile.d/custom.sh里面（文件若无，可新建）。 设置环境变量要注意2点：1. 设置新的环境变量时一般要包含原始的环境变量，不能覆盖；2. 注意自己的目录和系统环境变量的目录的顺序，想让哪个先被找到，就先放哪个。 每次安装一个软件都设置一次环境变量有些麻烦，假如我们已经把/home/ct/bin目录放在环境变量中了，以后新安装的软件，只要把可执行命令软连到/home/ct/bin目录下就好了，简单方便，即时生效 (操作可见下面NCBI-blast的安装)。 2.3 软件安装的几种传统方式 不同于windows，Linux下软件安装的方式比较多样，有些也比较复杂。每种安装方式都有自己的优点和局限，也都有可能遇到问题。在我们理解了原理之后，借助谷歌，可以更好地帮助解决问题。 2.3.1 系统包管理器安装 软件安装最方便的、一般也不容易出问题的是利用系统自带的包管理工具，可以解决大部分的依赖问题。 # centos # 如果长时间没更新，先运行下update yum update # 如果不知道软件具体名字，可以先用一个关键字search一下, 选择正式的名字 # 需要注意的是一般的服务器都是64 bit，需要选x86_64版本 yum search soft_name or soft_description yum search soft_official_name 但也有一些不足，主要3点： 需要根用户的权限。 如果系统版本老，安装的软件版本也会比较老。使用新版本有时又会发生冲突。 生物信息学中不少软件不在系统的安装源里面。 2.3.2 下载二进制文件 解决这些问题，就需要自己去软件官网查找最新的分法包，又有两种可能，一种是分发包直接就是编译好的软件，下载下来设置下可执行属性并放入环境变量就可以运行了，如于blast或bowtie这样的工具。 blast的链接为ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.7.1+-x64-linux.tar.gz。 另一种则是需要从源码编译安装，下面主要讲解下这个。 2.3.3 源码编译安装 源码编译经典的三部曲configure, make, make install。如果不出问题，一步步执行下来就安装好了，也不一定要知其所以然。但出了问题，就不是比较容易解决的。如果知道这背后的机制，还是会有帮助的。 configure是检查系统的库文件、类文件、依赖软件是否存在以及它们的版本是否满足需求，并根据实际检测结果生成Makefile的工具。一般是一堆bash命令的组合。通常也需要在这一步配置一些参数。最常用的就是指定软件的安装目录--prefix=/home/ct/soft/specific_name。 make则是具体的编译过程。编译的语句都写在了Makefile中。make默认编译Makefile中出现的第一个target，也可以指定target编译，并根据Makefile的设置方式依次编译所有依赖的东西。 有些软件的安装，在执行完make后就获得了可执行程序，可以跳过make install的过程，只需要把可执行程序放入环境变量就可以运行了。但部分软件还需要一些依赖关系，所以需要执行make install才算完成了完整的安装。 make install通常是拷贝make编译出来的可执行文件或者依赖的库文件(如果有的话)到configure时的--prefix指定的目录下。 安装好的软件放入环境变量, 就可以快乐的运行了。 两条注意: 从源码编译最难解决的问题就是依赖的库文件、头文件、其它软件的缺失或版本不匹配，没有统一的解决办法，原则就是缺啥补啥。 三部曲每一步的执行，屏幕上都会输出比较多的信息，一定仔细看最后有没有ERROR类的字样，对判断软件有无安装成功和下一步要怎么做会很有帮助。 举一个例子，编译安装samtools。具体看视频解释http://bioinfo.ke.qq.com。 小练习： 尝试源码安装EMBOSS, 下载地址 ftp://emboss.open-bio.org/pub/EMBOSS/emboss-latest.tar.gz. EMBOSS是欧洲分子生物学开放软件包，主要做序列比对，数据库搜搜，蛋白motif分析和功能域分析，序列模式搜索，引物设计等。 Table 2.1: Popular applications of EMBOSS. Popular.applications Functions prophet Gapped alignment for profiles. infoseq Displays some simple information about sequences. water Smith-Waterman local alignment. pepstats Protein statistics. showfeat Show features of a sequence. palindrome Looks for inverted repeats in a nucleotide sequence. eprimer3 Picks PCR primers and hybridization oligos. profit Scan a sequence or database with a matrix or profile. extractseq Extract regions from a sequence. marscan Finds MAR/SAR sites in nucleic sequences. tfscan Scans DNA sequences for transcription factors. patmatmotifs Compares a protein sequence to the PROSITE motif database. showdb Displays information on the currently available databases. wossname Finds programs by keywords in their one-line documentation. abiview Reads ABI file and display the trace. tranalign Align nucleic coding regions given the aligned proteins. 2.3.4 Python包的安装 在没有Anaconda(或其前身canopy)出现之前，Python包以其管理混乱、安装困难著称。有了Anaconda后，不只python包的安装简单了，其它软件的安装也都方便了 (详见后面Anaconda的两个福利)。 首先下载Anaconda的安装包 https://www.continuum.io/downloads。 Anaconda的安装包做的很人性化，一个bash脚本，只要运行bash Anacond*x86_64.sh，然后按照提示操作就可以了。 安装好后，设置或刷新下环境变量就可以使用了。 此后再安装python的包只需要执行pip install pakcage_name或conda install pakckage_name就可以了。 这里唯一需要注意的就是确认使用的python或pip确实是Anaconda安装的python或pip。 which python查看使用的python命令。 如果使用的还是系统默认的python，则需要检查下环境变量的设置，尤其前面提到的环境变量里面不同目录放置的顺序。 2.3.5 Anaconda的两个福利 头文件和库文件库 这是Anaconda安装后的目录结构 bin envs Examples imports lib LICENSE.txt pkgs share var conda-meta etc gcc include lib64 mkspecsplugins ssl 其中lib目录下，一部分是依赖的动态链接库, .so文件；这也是在源码编译时最常见的拦路虎。通常，只需要把这个目录放入环境变量LD_LIBRARY_PATH里面比如export LD_LIBARY_PATH=${LD_LIBARY_PATH}:anaconda_path/lib就可以解决问题。 cairo libitm.a libQtScript.so.4 cmake libitm.la libQtScript.so.4.8 engines libitm.so libQtScript.so.4.8.7 gcc libitm.so.1 libQtScriptTools.la gcj-4.8.5-14 libitm.so.1.0.0 libQtScriptTools.prl glib-2.0 libitm.spec libQtScriptTools.so libargtable2.a libjpeg.a libQtScriptTools.so.4 libargtable2.la libjpeg.la libQtScriptTools.so.4.8 libargtable2.so libjpeg.so libQtScriptTools.so.4.8.7 libargtable2.so.0 libjpeg.so.8 libQtSql.la libargtable2.so.0.1.8 libjpeg.so.8.4.0 libQtSql.prl libasan.a libmkl_avx2.so libQtSql.so libasan.la libmkl_avx512_mic.so libQtSql.so.4 libasan_preinit.o libmkl_avx512.so libQtSql.so.4.8 libasan.so libmkl_avx.so libQtSql.so.4.8.7 bioconda bioconda生物分析软件安装的通道，后面专门介绍。 2.3.6 R和R包的安装 见R系列教程。 2.3.7 Perl包的安装 # 假设~/bin已在环境变量中 cd ~/bin curl -L https://cpanmin.us/ -o cpanm chmod +x cpanm cpanm List::MoreUtils Bio::Perl 2.4 Conda安装配置生物信息软件 Conda是一种通用包管理系统，旨在构建和管理任何语言的任何类型的软件。通常与Anaconda (集成了更多软件包，https://www.anaconda.com/products/individual)和Miniconda (只包含基本功能软件包, https://conda.io/miniconda.html)一起分发。 最初接触到Anaconda是用于Python包的安装。Anaconda囊括了100多个常用的Python包，一键式安装，解决Python包安装的痛苦。但后来发现，其还有更多的功能，尤其是其增加了bionconda (https://bioconda.github.io/index.html)通道后，生物信息分析的7925多个软件都可以一键安装了 (具体列表在：https://anaconda.org/bioconda/repo)，免去了编译时间浪费和解决库文件安装的问题。另外其最有吸引力的是它的虚拟软件环境概念，可以简单的配置不同Python版本的环境、不同Python包的环境、不同R环境和R包的环境，对于生物信息软件繁杂的应用和频繁的更新提供了很大的便利。 2.4.1 Conda安装和配置 在链接https://www.anaconda.com/products/individual下载Anaconda或Miniconda对应版本的分发包之后，安装就是运行下面的命令，根据提示一步步操作，主要是修改安装路径 (如果是根用户，可以安装到/anaconda下，其它任意目录都可以，但路径短还是有好处的；普通用户安装到自己有权限的目录下，如~/miniconda2)。 # soft目录为conda安装的目录，可自己修改 soft=~/miniconda2 echo &#39;export PATH=&quot;&#39;${soft}&#39;/bin:$PATH&quot;&#39; &gt;&gt;~/.bash_profile export PATH=&quot;${soft}/bin:$PATH&quot; wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh bash Miniconda2-latest-Linux-x86_64.sh -b -f -p ${soft} 安装完成之后，记得把安装路径下的bin文件夹加入到环境变量中 (上面命令中我们已经帮您加进去了)。 2.4.2 Conda基本使用 在Conda安装配置好之后，就可以使用了。 conda list # 列出安装的软件包 # conda所有软件名都是小写 conda search &lt;package ambigious name&gt; # 搜索需要安装的软件包，获取其完成名字 以搜索numpy为例： conda search numpy # * 表示对于版本的包已安装 Fetching package metadata ............... numpy 1.7.2 py27_blas_openblas_201 conda-forge [blas_openblas] 1.7.2 py27_blas_openblas_202 conda-forge [blas_openblas] 1.12.0 py36_0 defaults 1.12.0 py36_nomkl_0 defaults [nomkl] * 1.12.1 py27_0 defaults 1.12.1 py27_nomkl_0 defaults [nomkl] 1.13.1 py36_0 defaults 1.13.1 py36_nomkl_0 defaults [nomkl] numpy-indexed 0.3.2 py27_0 conda-forge 1.0.47 py35_0 conda-forge 1.0.47 py36_0 conda-forge numpy_groupies 0.9.6 py27_0 conda-forge 0.9.6 py35_0 conda-forge 0.9.6 py36_0 conda-forge numpy_sugar 1.0.6 py27_0 conda-forge 1.0.6 py34_0 conda-forge numpydoc 0.6.0 py27_0 conda-forge 0.6.0 py34_0 conda-forge xnumpy 0.0.1 py27_0 conda-forge 安装包 conda install &lt;package name&gt; # 安装软件包 # -y是同意安装，不写的话会弹出提示，需要再次确认 conda install numpy=1.7.2 -y # 安装特定版本的软件包 conda remove &lt;package name&gt; # 移除软件包 安装R # 具体见下面 # 安装R,及80多个常用的数据分析包, 包括idplyr, shiny, ggplot2, tidyr, caret 和 nnet conda install -c r r-base=4.0.2 r-essentials # 安装单个包 # conda install -c https://conda.binstar.org/bokeh ggplot 更新包 # 更新基础conda，新版本conda使用起来更快 conda update -n base -c defaults conda conda update r-base 获取帮助信息 conda -h # 查看conda可用的命令 conda install -h #查看install子命令的帮助 只是这些命令就可以省去不少安装的麻烦了，但是如果软件没搜索到呢？ 2.4.3 Conda的channel Conda默认的源访问速度有些慢，可以增加国内的源；另外还可以增加几个源，以便于安装更多的软件，尤其是bioconda安装生信类工具。conda-forge通道是Conda社区维护的包含很多不在默认通道里面的通用型软件。r通道是向后兼容性通道，尤其是使用R3.3.1版本时会用到，现在则不需要单独添加了。后加的通道优先级更高，因此一般用下面列出的顺序添加。清华镜像具体见https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/ (有时清华镜像也不稳定，不稳定时直接用官方镜像，早上下载速度还是好的)。 conda config --add channels r # Optional # Lowest priority conda config --add channels defaults conda config --add channels conda-forge conda config --add channels bioconda conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ # Anocanda清华镜像 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/cond-forge # 清华通道, 最高优先级 conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ conda config --set show_channel_urls yes 注意通道的顺序是会影响solving environment和软件包下载的速度的。 # 显示已有的通道 conda config --get channels conda通道的配置文件一般在~/.condarc里面，内容如下。全局控制conda的安装在conda_path/.condarc，具体操作见https://conda.io/docs/user-guide/configuration/admin-multi-user-install.html。 channels: - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/cond-forge - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # Anocanda清华镜像 - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/ - bioconda - conda-forge - r 2.4.4 创建不同的软件运行环境 这是Conda最有特色的地方，可以通过创建不同的环境，同时运行不同软件的多个版本。 新创建的软件环境的目录为anaconda_path/envs/enrironment_name，具体见下面的3个例子。 创建一个环境transcriptome安装常用转录组分析软件 # 新建一个环境，命名为transcriptome # 环境名字为 transcriptome # 环境中安装 samtools multiqc rseqc conda create -n transcriptome samtools multiqc rseqc # 如果还想继续安装 conda install -n transcriptome fastqc salmon star stringtie sra-tools trimmomatic rmats rmats2sashimiplot # 启动新环境 source activate transcriptome salmon -h # 默认安装到了anaconda_path下面的envs/transcriptome目录下（在屏幕输出也会有显示） # 这个目录下存在bin文件夹，一般使用全路径就可以调用，如下 # anaconda_path/envs/transcriptome/bin/salmon -h # 但有时会因为依赖关系而失败 source deactivate transcriptome 不少软件不激活环境也可以使用全路径调用，比如anaconda_path/envs/transcriptome/bin/salmon就可以直接使用salmon程序，这样我们就可以根据前面的PATH介绍，把目录anaconda_path/envs/transcriptome/bin/放入环境变量，就可以直接调用这个环境中的大部分程序了。 新版的conda默认会使用conda activate transcriptome激活环境。 初次使用时会弹出一个提示，需要运行conda init： conda activate qiime2-2020.6 CommandNotFoundError: Your shell has not been properly configured to use &#39;conda activate&#39;. To initialize your shell, run $ conda init &lt;SHELL_NAME&gt; Currently supported shells are: - bash - fish - tcsh - xonsh - zsh - powershell See &#39;conda init --help&#39; for more information and options. IMPORTANT: You may need to close and restart your shell after running &#39;conda init&#39;. 不过，个人更喜欢用source anaconda_path/bin/activate transcriptome激活环境，用起来更灵活一些。而且如果是根用户安装时，不建议把conda环境默认加到环境变量中，会引起不必要的系统冲突。可以给个用户自己使用是自己配置对应的环境变量。 激活环境后，会看到命令行提示前多了一个环境名字，比如下面激活qiime2-2020.6环境后的展示。 ct@ehbio:~# source /anaconda3/bin/activate qiime2-2020.6 (qiime2-2020.6) ct@ehbio:~# which python /anaconda3/envs/qiime2-2020.6/bin/python (qiime2-2020.6) ct@ehbio:~# source /anaconda3/bin/deactivate DeprecationWarning: &#39;source deactivate&#39; is deprecated. Use &#39;conda deactivate&#39;. ct@ehbio:~# which python /usr/bin/python 在环境phylo中安装ete3 起因是使用官方的推荐命令安装时出了问题，py3.5的包装到了py2.7环境下。解决办法，新建一个py2.7的环境，然后安装。 # 新建一个环境，命名为phylo，指定其内安装的python版本为2.7 conda create -n phylo python=2.7 # 在phylo环境中安装 ete3 # ete3存在于2个通道中，官方推荐使用自己的通道，但没有成功 # -n 指定安装环境 -c 指定下载通道 # conda install -n phylo -c etetoolkit ete3 ete3_external_apps # bioconda通道里面也有ete3, 下面的安装未指定具体通道， # 将在前面设定的几个通道里面按先后顺序查找安装 conda install -n phylo ete3 ete3_external_apps # 默认安装到了anaconda_path下面的envs/phylo目录下（在屏幕输出也会有显示） # 这个目录下存在bin文件夹，一般使用全路径就可以调用，如下 # anaconda_path/envs/phylo/bin/ete3 -h # 但有时会因为依赖关系而失败 # 所以激活本次安装环境是比较不容易出问题的使用方式 source activate phylo # 在新环境里面执行命令操作 ete3 -h # 其它操作 # 退出新环境 source deactivate phylo 创建R环境 Reference1 # Create a new conda environment called r,并且在里面安装anaconda conda create -n r anaconda # Switch to r environment source activate r # 在新环境里面安装R Installs R conda install -c r r # Install R kernel for IPython notebook conda install -c r r-irkernel # Install ggplot conda install -c https://conda.binstar.org/bokeh ggplot # 最后退出新环境 source deactivate r 列出所有的环境 conda env list # conda environments: # /anaconda2 /anaconda2/envs/lefse /anaconda2/envs/metagenome_env /anaconda2/envs/metawrap /anaconda2/envs/prokka_env /anaconda2/envs/py3 /anaconda2/envs/r-environment /anaconda2/envs/reseq /anaconda2/envs/sourmash_env /anaconda3/envs/qiime2-2020.6 2.4.5 移除某个conda环境 如果环境不需要了，或出了错，则可以移除。比如需要移除phylo环境，执行conda remove -n phylo --all。 2.4.6 Conda配置R 在添加了不同的源之后，有些源更新快，有些更新慢，经常会碰到版本不一的问题。而且软件版本的优先级，低于源的优先级。保险期间，先做下搜索，获得合适的版本号，然后再选择安装。 conda search r-essentials r-essentials 1.0 r3.2.1_0 r 1.0 r3.2.1_0a r 1.1 r3.2.1_0 r 1.1 r3.2.2_0 r 1.1 r3.2.1_0a r 1.1 r3.2.2_0a r 1.1 r3.2.2_1 r 1.1 r3.2.2_1a r 1.4 0 r 1.4.1 r3.3.1_0 r 1.4.2 0 r 1.4.2 r3.3.1_0 r 1.4.3 r3.3.1_0 r 1.5.0 0 r 1.5.1 0 r 1.5.2 r3.3.2_0 r 1.5.2 r3.4.1_0 r 1.6.0 r3.4.1_0 r 1.0 r3.2.1_0 defaults 1.0 r3.2.1_0a defaults 1.1 r3.2.1_0 defaults 1.1 r3.2.2_0 defaults 1.1 r3.2.1_0a defaults 1.1 r3.2.2_0a defaults 1.1 r3.2.2_1 defaults 1.1 r3.2.2_1a defaults 1.4 0 defaults 1.4.1 r3.3.1_0 defaults 1.4.2 0 defaults 1.4.2 r3.3.1_0 defaults 1.4.3 r3.3.1_0 defaults 1.5.0 0 defaults 1.5.1 0 defaults 1.5.2 r3.3.2_0 defaults 1.5.2 r3.4.1_0 defaults 1.6.0 r3.4.1_0 defaults 1.5.2 r3.3.2_0 conda-forge 1.5.2 r3.3.2_0 https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge 从上面可以看到清华的源版本同步于conda-forge, 都比较老，还是指定r通道安装。 conda install -c r -n r r-essentials=1.6.0 R会安装于conda_path/envs/r/bin中，软链到位于环境变量的目录中即可正常使用。这就是环境变量的活学活用。 2.4.7 Conda环境简化运行 为了方便不同环境里面程序的运行，我写了一个shell脚本 (conda_env_run.sh)，具体运行如下： # -c: 表示实际需要运行的命令 # -e: 表示需要启动的软件环境，也就是上面conda create建立的环境 # -b：一般不需要指定，如果conda没在环境变量中需要给出conda的安装路径 conda_env_run.sh -c &#39;ete3 -h mod&#39; -e phylo conda_env_run.sh -c &#39;bwa mem -h&#39; -e aligner -b &quot;/usr/local/anaconda2/bin&quot; conda_env_run.sh内容如下 2.4.8 Conda环境备份 有的时候会出现装一个新包，装着装着就把当前环境搞装崩了的情况，所以备份一个环境还是必要的，conda create -n python35copy --clone python35，把python35备份为python35copy。 2.4.9 Conda环境导出和导入 做培训时需要给参加培训的老师提供配置环境的脚本，之前都是提供一个Bash文件全部运行下来就可以完成整个环境的配置，更简单的方式是可以导出环境，自己配置时再导入就好了。 # 假设我们有一个环境叫 ehbio，可以导出为一个yml文件 conda env export --file ehbio_env.yml --name ehbio # 然后换一台电脑，就可以完全重现这个环境了 # 这么做的另一个优势是yml中明确列出了软件的版本， # 使用 conda solving environment时速度会快很多 conda env create -f ehbio_env.yml 2.4.10 Conda软件安装 core dump error/Segment fault/段错误 怎么办 # 清空缓存 # https://github.com/conda/conda/issues/7815 conda clean -a 2.4.11 Conda为什么越来越慢？ Conda中包含的软件越来越多，而且软件的不同版本都保留了下来，软件的索引文件越来越大，安装一个新软件时搜索满足环境中所有软件依赖的软件的搜索空间也会越来越大，导致solving environment越来越慢。 2.4.12 Conda是如何工作的 从设定的通道 (channel)处下载通道中所有软件的索引信息 (repodata.json) (Collecting package metadata (repodata.json)) &quot;packages&quot; : { &quot;moto-1.3.7-py_0.tar.bz2&quot; : { &quot;build&quot; : &quot;py_0&quot;, &quot;build_number&quot; : 0, &quot;depends&quot; : [ &quot;aws-xray-sdk !=0.96,&gt;=0.93&quot;, &quot;backports.tempfile&quot;, &quot;boto &gt;=2.36.0&quot;, &quot;boto3 &gt;=1.6.15&quot;, &quot;botocore &gt;=1.12.13&quot;, &quot;cookies&quot;, &quot;dicttoxml&quot;, &quot;docker-py&quot;, &quot;flask&quot;, &quot;jinja2 &gt;=2.7.3&quot;, &quot;jsondiff 1.1.1.*&quot;, &quot;mock&quot;, &quot;pyaml&quot;, &quot;python&quot;, &quot;python-dateutil&quot;, &quot;python-jose &lt;3.0.0&quot;, &quot;pytz&quot;, &quot;requests &gt;=2.5&quot;, &quot;responses &gt;=0.9.0&quot;, &quot;six&quot;, &quot;werkzeug&quot;, &quot;xmltodict&quot; ], &quot;license&quot; : &quot;Apache-2.0&quot;, &quot;md5&quot; : &quot;17b424658cd07e678b5feebdc932eb52&quot;, &quot;name&quot; : &quot;moto&quot;, &quot;sha256&quot; : &quot;5924666f8c1758472dc4c3d22b270b46cd1c4b66c50a9ba50d5c636d2237bdd1&quot;, &quot;size&quot; : 399973, &quot;subdir&quot; : &quot;noarch&quot;, &quot;timestamp&quot; : 1552438392680, &quot;version&quot; : &quot;1.3.7&quot; } } 解析repodata中的信息获取所有依赖的包的信息 采用SAT-solver算法决定需要下载包的哪个版本和它们的安装顺序 下载并安装包 2.4.13 Conda哪一步慢？ 主要是第3步，确定待安装包的依赖包之间的兼容和已安装软件之间的兼容，获得需要下载的包和对应版本。 2.4.14 如何提速Conda 采用最新版的conda (Conda4.7相比Conda4.6提速3.5倍, Conda 4.8应该不会比4.7慢) 安装时指定版本减少搜索空间 conda install python=3.7.4 安装R包时指定R的版本也会极大减小搜索空间 (R包因其数目众多，也是生物类软件依赖解析较慢的原因之一) conda install r-base=4.0.2 r-ggplot2=3.3.2 采用mamba加速软件依赖解析 [mamba采用c++重写了部分解析过程，这个提速效果是很明显的] (安装好mamba后就可以用mamba替换conda进行安装了) conda install mamba -c conda-forge mamba install python=3.7.4 ，默认conda解析软件依赖时优先考虑允许的最高版本，设置通道优先级权限高于软件版本新旧后，conda会能更快的解决依赖关系，避免defaults和conda-forge通道的奇怪组合导致软件依赖解析迟迟不能将结束的问题: conda config --set channel_priority strict (这个命令只需要运行一次)。 创建一个新环境 (conda env create -n env_name)再安装软件，这样就不用考虑与已有的软件的兼容问题了，也可以大大降低搜索空间和提高解析软件依赖的速度。 如果安装的软件提供了environment.yaml那么用起来，文件中对应的软件版本都很明确，解析依赖关系时更快。也可以按前面提供的方式导出一个已经配置好的环境的yaml文件，在其它电脑配置时直接读取。 (具体导出方式见Bioconda软件安装神器：多版本并存、环境复制、环境导出。 channels: - qiime2/label/r2020.6 - conda-forge - bioconda - defaults dependencies: - _libgcc_mutex=0.1 - _openmp_mutex=4.5 - _r-mutex=1.0.1 - alsa-lib=1.1.5 - arb-bio-tools=6.0.6 - attrs=19.3.0 - backcall=0.2.0 - bibtexparser=1.1.0 - binutils_impl_linux-64=2.34 - binutils_linux-64=2.34 - bioconductor-biobase=2.42.0 - bioconductor-biocgenerics=0.28.0 - bioconductor-biocparallel=1.16.6 - bioconductor-biostrings=2.50.2 - bioconductor-dada2=1.10.0 添加Bioconda通道时，注意顺序，给予conda-forge最高优先级，其次是bioconda。如果之前已经添加好了通道，自己在~/.condarc中调整顺序。 ~~~~~~~~~~~~~~~~~~~~~~~ conda config –add channels defaults conda config –add channels bioconda conda config –add channels conda-forge ~~~~~~~~~~~~~~~~~~~~~ 综合以上组合，之前尝试多次都没安装好的工具，直接搞定。 2.4.15 下载提速 国内镜像，见软件安装不上，可能是网速慢！Conda/R/pip/brew等国内镜像大全拿走不谢~~ 换个网或从朋友处拷贝已经下载好的压缩包一般在anaconda_root_dir/pkgs下，拷贝放在自己的anaconda3/pkgs下面，再次下载时系统会识别已经下载好的包而跳过 (并不总是有效)。 获取所有相关包的名字，从朋友处拷贝下载好的安装包，自己手动安装。 mamba install r-base=4.0.2 r-ggplot2=3.3.2 --dry-run &gt;package_solving_result # _anaconda_depends pkgs/main/linux-64::_anaconda_depends-2020.07-py37_0 # _r-mutex conda-forge/noarch::_r-mutex-1.0.1-anacondar_1 # binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.33.1-he6710b0_7 # binutils_linux-64 conda-forge/linux-64::binutils_linux-64-2.33.1-h9595d00_17 # brotlipy conda-forge/linux-64::brotlipy-0.7.0-py37h516909a_1000 # bwidget conda-forge/linux-64::bwidget-1.9.14-0 # gcc_impl_linux-64 pkgs/main/linux-64::gcc_impl_linux-64-7.3.0-habb00fd_1 # gcc_linux-64 conda-forge/linux-64::gcc_linux-64-7.3.0-h553295d_17 # 获取所有包的名字 grep &#39;::&#39; a | sed &#39;s/.*:://&#39; | sed &#39;s/$/.tar.bz2/&#39; # 手动安装 for i in `grep &#39;::&#39; a | sed &#39;s/.*:://&#39; | sed &#39;s/$/.tar.bz2/&#39;`; do conda install --offline /anaconda3/pkgs/$i; done 如果拷贝过来未能自动识别，可手动安装 conda install --offline local_path。 2.4.16 使用conda-pack直接从已经安装好的地方拷贝一份 (同一操作系统) 安装conda-pack conda install -c conda-forge conda-pack # pip install git+https://github.com/conda/conda-pack.git 打包已经安装好的环境 conda pack -n my_env_name -o my_env_name.tar.gz 拷贝打包好的环境my_env_name.tar.gz到目标机器，并解压到任何目录，一般推荐放到envs目录下 (anaconda_root/envs)。(注意：anaconda_root改为自己的conda安装路径。) # 解压打包好的环境 # 默认是全都解压到当前目录，场面很壮观 # -C 一定要指定 mkdir -p anaconda_root/envs/my_env tar -xzf my_env.tar.gz -C anaconda_root/envs/my_env # 激活环境 source my_env/bin/activate # Unpack conda-unpack # 至此环境就完全拷贝过来了 # 去激活 source deactivate 2.5 Docker安装 2.5.1 Docker能做什么 The key benefit of Docker is that it allows users to package an application with all of its dependencies into a standardized unit for software development. 提供一个虚拟的操作平台，供我们安装依赖不同版本系统的工具软件。 提供一个即时可用的应用软件或者流程的镜像，开发者把软件部署到系统镜像中， 使用者可以直接下载下来使用，省去了个人安装软件的烦恼。 提供一个系统资源分配手段，给不同用户的程序分配独立的计算资源。 2.5.2 Docker的几个基本概念 镜像 (Images): 可以认为是超级轻量级的虚拟机的快照。 镜像会有自己的唯一ID，名字和标签，比如ubuntu:latest, django:1.6等。 通常都是在已有的镜像（多数是Linux操作系统的镜像）的基础上构建自己的 具有新功能的镜像。 容器 (Containers): 可以认为是超级轻量级的虚拟机， 是镜像运行起来所处的可读写的状态。 容器里面可以安装、运行程序，还可以把安装好的程序存储起来获得新的镜像。 与虚拟机很大的不同在于，一个容器通常只运行一个程序。在Docker中， 应用程序和数据文件是分开的，因此可以在不影响数据的情况下快速升级代码 或系统。 数据卷 (Volumes): 永久保存数据的磁盘空间。 Docker允许用户定义哪一部分是应用程序，哪一步分是数据，并且把他们分隔开。 这就保证了在Docker中容器的生命周期是短暂的，而数据的存储是永恒的。 数据卷存储在运行Docker的宿主机上，对每个容器来说是特有的。 我们可以启动同一个镜像来产生多个容器，并且分别给他们分配一个数据卷。 数据卷也可用于在不同的容器间共享数据。 具体参见http://blog.genesino.com//2016/09/docker-lamp/ 联通 (Links): 容器启动后会分配有一个私有IP，其它容器可以通过这个IP地 址与这个容器通讯。 假如有个正在运行的数据库容器 (dbapp)， 那么我们可以在网络服务器容器 (webserver)中通过指定端口连接dbapp与数据库容器通讯。 2.5.3 安装和配置 Centos 6.5 安装Docker 其他新版操作系统的安装可以直接使用系统自带的yum或apt工具， 启动和配置如上。 2.5.4 Docker用户权限 默认情况下，Docker命令的运行需要根用户权限。一个解决办法是把用户加入 docker用户组，原因是Docker能够将/run/docker.socket的文件权限设为 660、用户组设为docker。当把用户加入到docker用户组后，就无需使用 sudo或su命令切换获取根用户权限。check here 但通常只应把信任的用户加入docker用户组因为docker用户组的权限相当于root。 如果打算只允许用户访问一个特定的容器，可以写一个简单脚本 脚本完成后，配置sudoers 更多权限设置见http://dockone.io/article/589 2.5.5 Docker试用 查看本地Docker的信息 docker info 运行Docker需要有一个镜像和容器。镜像是容器的只读版本， 最基础的镜像是一个操作系统，是运行其他命令的基础。 因此我们需要先获取一个操作系统镜像，通常使用Ubuntu系统, CentOS系统和 Alpine (只有5M)。 我们也可以根据所要运行软件的需要，来获取不同的操作系统， 方便软件的安装。 搜索镜像 docker search ubuntu; 镜像的名字通常由用户名/镜像名构成, 无用户名的为官方认证镜像。 获取镜像 docker pull ubuntu 获取镜像的最新版本(不指定版本号即为latest) docker pull ubuntu:14.04 获取指定版本的镜像；14.04为镜像的版本号(又称TAG)。 查看本机Docker中存在的镜像 docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE ubuntu latest 37b164bb431e 4 days ago 126.6 MB 获得了镜像之后，我们需要运行镜像；运行起来的镜像就是容器，是可读写的。 我们可以在容器中安装软件、运行命令，就如在正常的操作系统中一样。 在容器中运行单个命令或程序, 通常加--rm参数，容器运行结束之后就自动 删除。如果我们想保留容器的修改，则不能加--rm参数。 交互式运行容器 docker run -it ubuntu, 这时可以发现终端的用户名变了 docker run --help可以查看这个命令的参数。 在容器中部署软件，安装build-essential和r-base; build-essential 是编译软件包的基础，提供需要的编译器、头文件和库文件。 r-base 是编译R语言程序包的基础。 这一步我们可以安装任意的软件，测试时可以选择小一点的软件包。 最开始时选择了安装build-essential, 只是为了学习， 到后来发现安装这个并没有什么用，也不方便测试。为了简单起见， 可以尝试安装Apache。在本文后面有个简单的测试Apache安装的例子。 运行docker commit -m 'Add build-essential r-base' -a ct5869 8aca49b869be ct5869/ubuntu-dev:v1''。 测试运行新的镜像 docker run --rm -it username/ubuntu-dev:v1。 挂载宿主机硬盘在容器内部操作, 通过-v参数，路径都为绝对路径， docker run --rm -v /host_absolute_dir:/container_absolute_dir username/ubuntu-dev:v1 echo 'test' &gt;/container_absolute_dir/test_file 这样，就相当于把host机目录/host_absolute_dir链接为docker容器路径 /container_absolute_dir。 如果只是自己用，到现在就可以结束了，我们可以在镜像里面继续更多的操作了。 另外我们还可以运用导出和导入来迁移镜像 导出镜像：docker export image_id &gt;ubuntu-dev.v1.tar 导入镜像：cat ubuntu-dev.v1.tar | docker import - username/ubuntu-dev:v1 如果我们想把镜像分发给别人使用，就需要把镜像传到镜像仓库比如Docker Hub。 我们需要现在Docker hub注册， 用注册的用户名替换掉前文提到的username。 注册成功之后，在本地服务器尝试登录，用以把登录信息存储在本地，方便后续使用。 运行docker login，按提示输入用户名、密码和邮件。登录成功会返回 Login Succeeded. 运行docker push username/ubuntu-dev:v1把准备好的镜像上传； 等待片刻，完成上传。这时就可以再Docker hub上看到上传的镜像了。 其它用户可以使用 docker pull username/ubuntu-dev:v1来获取安装好编 译环境的ubuntu系统了。 2.5.6 Docker系统基本操作 当一个容器不再使用时，运行docker rm container_id移除容器，以节省空间。 这不会对镜像造成影响。 当一个容器不再使用时，运行docker rm -v container_id移除容器及其挂载卷， 以节省空间。这不会对镜像造成影响。 批量删除退出的容器docker rm -v $(docker ps -a -q -f status=exited)。 对于只需要单次运行的容器，比如执行一个命令等，则只需要在 docker run时添加--rm参数就好。这样容器运行结束后会自动删除。 运行docker rmi username/ubuntu-dev:v1移除镜像。 运行docker tag 26d99f722dca username/ubuntu-dev:v0修改镜像的名字。 运行docker run -d --name=container_name username/ubuntu-dev:v1 指定运行的container的名字。 运行docker run --rm -ti -v /host_abs_dir:/container_abs_dir:ro username/ubuntu-dev:v1挂载只读目录。 运行docker stop containde_id/container_name停止镜像。 运行docker rm $(docker ps -a -q)和docker rmi $(docker images -q)移除全部镜像。BE CAREFULL 查看Docker镜像的创建历史 docker history image_name IMAGE CREATED CREATED BY SIZE COMMENT 3d4f934accdb 7 months ago /bin/sh -c #(nop) CMD [&quot;/run.sh&quot; ] 0 B aa321fa8d23f 7 months ago /bin/sh -c #(nop) EXPOSE 3306/tcp 80/tcp 0 B 6446fbfc507d 7 months ago /bin/sh -c #(nop) VOLUME [/etc/mysql /var/lib 0 B 44e98bdf2bbf 7 months ago /bin/sh -c #(nop) ENV PHP_POST_MAX_SIZE=10M 0 B bedff16caee9 7 months ago /bin/sh -c #(nop) ENV PHP_UPLOAD_MAX_FILESIZE 0 B 72b723ccc97f 7 months ago /bin/sh -c mkdir -p /app &amp;&amp; rm -fr /var/www/h 0 B 查看镜像的JSON文件 docker inspect image_name Docker images的安装路径为 /var/lib/docker。 /var/lib/docker/{driver-name} will contain the driver specific storage for contents of the images. /var/lib/docker/graph/&lt;id&gt; now only contains metadata about the image, in the json and layersize files. 查看Docker 容器启动和运行日志 docker logs --tail=all container_id 2.5.7 使用Dockerfile自动构建镜像 除了可以像上面那样一步步地获取镜像、修改容器、存储镜像、上传镜像等操作外， 我们还可以使用Dockerfile自动实现上述操作。 典型的Dockerfile如下所示， FROM alpine MAINTAINER username username@internet.com RUN apk add --no-cache apache2 apache2-utils COPY public_html /var/www/html EXPOSE 80 443 CMD [&quot;rc-service apache2 start&quot;] FROM为除注释之外的第一条命令，用来声明镜像的基础系统。 MAINTAINER设置镜像维护人的信息。 RUN在容器内部运行shell命令。 COPY是把本地的bash配置文件拷贝到新维护的镜像中； COPY的文件的路径是相对于docker build的PATH，一般是当前路径； CMD指定容易运行时默认执行的命令，如出现多个，只有最后一个会被运行。 运行命令docker build -t=\"username/httpd-alpine:v1\" .就可以构建镜像了。 最后的.表示Dockerfile在当前目录，也可指定其他目录。public_html必须 与Dockerfile在同一目录。 2.5.8 Docker的特征 Docker will watch only one single process. If you need multiple processes, you need to add a monitor like Monit or Supervisor at the top-level to take care of the others. But this is not recommended. 2.5.9 Docker使用注意 避免安装不必要的软件包。 每个容器都只运行一个进程。 最小化层：每执行一个命令，都会产生一个层。 2.6 Makefile知识 Makefile通常的格式和布局如下，有兴趣的可以自己去学，或者我们再出一个教程。 # 假设当前文件夹下Makefile文件中内容如下 ct@ehbio:~$ cat Makefile # first: target名字 # echo &quot;compile first&quot;: target对应的命令，任何Linux命令都可以 first: echo &quot;compile first&quot; all: first second echo &quot;compile all&quot; second: echo &quot;compile second&quot; # 直接运行make，会make第一个出现的target ct@ehbio:~$ make echo &quot;compile first&quot; compile first # make first与直接make相同，因为它出现在第一个 ct@ehbio:~$ make first echo &quot;compile first&quot; compile first # all依赖于first, second，因此make all会先执行make first, make second # 然后才是自己所代表的命令 ct@ehbio:~$ make all echo &quot;compile first&quot; compile first echo &quot;compile second&quot; compile second echo &quot;compile all&quot; compile all 2.6.1 参考 入门级 http://blog.saymagic.cn/2015/06/01/learning-docker.html 入门级 https://www.dwhd.org/20151115_140935.html 入门级 http://www.cnblogs.com/kevinX/p/5458244.html Start (english version) https://scotch.io/tutorials/getting-started-with-docker Start (english version) https://prakhar.me/docker-curriculum/ Greate english version https://blog.talpor.com/2015/01/docker-beginners-tutorial/ Docker trick https://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/ Docker root and non-root http://www.2cto.com/os/201508/432930.html 2.7 References https://samrelton.wordpress.com/2015/07/02/rconda/ https://www.anaconda.com/blog/developer-blog/anaconda-r-users-sparkr-and-rbokeh/ http://www.bioinfo-scrounger.com/archives/209 清华大学开源镜像站 Linux学习 - 又双叒叕一个软件安装方法 Linux - 命令运行监测和软件安装 Linux - 应用Docker安装软件 Linux - Conda软件安装方法 Nature Method：Bioconda解决生物软件安装的烦恼 手把手教你生信分析平台搭建 Windows轻松实现linux shell环境：gitforwindows Bioconda软件安装神器：多版本并存、环境复制、环境导出 软件安装不上，可能是网速慢！Conda/R/pip/brew等国内镜像大全拿走不谢~~ "],
["LinuxGreatTools.html", "3 Linux神器 3.1 正则表达式 3.2 awk命令 3.3 SED命令 3.4 VIM的使用 3.5 有了这些，文件批量重命名还需要求助其它工具吗？ 3.6 耗时很长的程序忘加nohup就运行了怎么办？ 3.7 References", " 3 Linux神器 视频课见 http://bioinfo.ke.qq.com。 3.1 正则表达式 正则表达式 (regular expression)是用来做模糊匹配的，匹配符合特定模式的文本。最早来源于Unix系统中的sed和grep命令，在各个程序语言，如perl, python中也都有实现。不同程序语言中正则表达式语法大体通用，细节上又各自有自己的特色。 Figure 3.1: 正则表达式基本语法 # 假如有这么一个测试文件 ct@ehbio: ~/$ cat &lt;&lt;END &gt;url.list http://www.ehbio.com/ImageGP http://www.ehbio.com/Training http://www.ehbio.com/Esx www.ehbio.com http://www.ehbio.com/ImageGP/index.php/Home/Index/Lineplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/GOenrichmentplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/PHeatmap.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Volcanoplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Manhattanplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Histogram.html http://www.ehbio.com/ImageGP/index.php/Home/Index/VennDiagram.html http://www.ehbio.com/ImageGP/index.php/Home/Index/UpsetView.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Densityplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/PCAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/PCoAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/CPCoAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Sankey.html http://blog.genesino.com https://blog.csdn.net/qazplm12_3/ https://blog.csdn.net/woodcorpse/ blog.csdn.net/woodcorpse/article/details/79313846 ImageGP is one of the Best online plot. 123456789 END 获取以https开头的行 ct@ehbio: ~/$ grep &#39;^https&#39; url.list https://blog.csdn.net/qazplm12_3/ https://blog.csdn.net/woodcorpse/ 获取包含数字的行 ct@ehbio:~/$ grep &#39;[0-9]&#39; url.list https://blog.csdn.net/qazplm12_3/ blog.csdn.net/woodcorpse/article/details/79313846 123456789 获取空行 ct@ehbio:~/$ grep &#39;^$&#39; url.list 获取html结尾的行 ct@ehbio:~/$ grep &#39;html$&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/Lineplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/GOenrichmentplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/PHeatmap.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Volcanoplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Manhattanplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Histogram.html http://www.ehbio.com/ImageGP/index.php/Home/Index/VennDiagram.html http://www.ehbio.com/ImageGP/index.php/Home/Index/UpsetView.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Densityplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/PCAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/PCoAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/CPCoAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Sankey.html 获取Boxplot和Barplot的地址 # 未能满足要求 ct@ehbio:~/$ grep &#39;B.*plot&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html ImageGP is one of the Best online plot. # 一个办法：更长的匹配 ct@ehbio:~/$ grep &#39;B.*plot.html&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html # 限定中间不能有空格 ct@ehbio:~/$ grep &#39;B[^ ]*plot&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html # 限定中间只能有2个字符 ct@ehbio:~/$ grep &#39;B..plot&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html # 2个字符的另外一种写法 ct@ehbio:~/$ grep -P &#39;B.{2}plot&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html # 2个字符的再一种写法，只允许出现特定字符 ct@ehbio:~/$ grep -P &#39;B[arox]*plot&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html 获取PCA或PCoA相关的行 ct@ehbio:~/$ grep &#39;PCo*A&#39; url.list http://www.ehbio.com/ImageGP/index.php/Home/Index/PCAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/PCoAplot.html http://www.ehbio.com/ImageGP/index.php/Home/Index/CPCoAplot.html 3.2 awk命令 前面的学习过程中已经提到了awk和sed的使用，作为一个引子。现在则详细列举关于awk常用的操作和一些偏门的操作。 3.2.1 awk基本参数解释 awk擅长于对文件按行操作，每次读取一行，然后进行相应的操作。 awk读取单个文件时的基本语法格式是awk 'BEGIN{OFS=FS=\"\\t\"}{print $0, $1;}' filename。 读取多个文件时的语法是awk 'BEGIN{OFS=FS=\"\\t\"}ARGIND==1{print $0, $1;}ARGIND==2{print $0;}' file1 file2。 awk后面的命令部分是用引号括起来的，可以单引号，可以双引号，但注意不能与内部命令中用到的引号相同，否则会导致最相邻的引号视为一组，引发解释错误。引号不可以嵌套 OFS: 文件输出时的列分隔符 (output field separtor) FS: 文件输入时的列分隔符 (field separtor) BEGIN: 设置初始参数，初始化变量 END: 读完文件后做最终的处理 其它{}：循环读取文件的每一行 $0表示一行内容；$1, $2, … $NF表示第一列，第二列到最后一列。 NF (number of fields)文件多少列；NR (number of rows) 文件读了多少行: FNR 当前文件读了多少行，常用于多文件操作时。 a[$1]=1: 索引操作，类似于python中的字典，在ID map，统计中有很多应用。 3.2.2 常见操作 针对特定列的计算，比如wig文件的标准化 # 注意除了第一行是空格，其它行都是tab键分割 ct@ehbio:~/sxbd$ cat &lt;&lt;END &gt;ehbio.wig variableStep chrom=chr2 300701 12 300702 10 300703 11 300704 13 300705 12.5 END ct@localhost:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}\\ {if(FNR&gt;1) $2=$2*10^6/(2.5*10^6); print $0}&#39; ehbio.wig variableStep chrom=chr2 300701 4.8 300702 4 300703 4.4 300704 5.2 300705 5 计算某列内容出现的次数。 # 怎么获得count文件，应该不难吧 ct@ehbio:~/sxbd$ cat count ID Type Pou5f1 Pluripotency Nanog Pluripotency Sox2 Neuron Tet1 Epigenetic Tet3 Epigenetic Myc Oncogene ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{if(FNR&gt;1) a[$2]+=1;}END\\ {print &quot;Type\\tCount&quot;; for(i in a) print i,a[i];}&#39; count Type Count Neuron 1 Epigenetic 2 Oncogene 1 Pluripotency 2 # 这个也可以用下面方式代替，但不直接 ct@ehbio:~/sxbd$ tail -n +2 count | cut -f 2 | sort | uniq -c | \\ sed -e &#39;s/^ *//&#39; -e &#39;s/ */\\t/&#39; 2 Epigenetic 1 Neuron 1 Oncogene 2 Pluripotency 之前也提到过的列操作，从GTF文件中提取启动子区域 GRCh38.gtf可以从ftp://ftp.ensembl.org/pub/release-91/gtf/homo_sapiens/Homo_sapiens.GRCh38.91.gtf.gz下载，或使用提供的测试文件。 ct@ehbio:~/sxbd$ sed &#39;s/&quot;/\\t/g&#39; GRCh38.gtf | \\ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{if($3==&quot;gene&quot;) {ensn=$10; symbol=$16; \\ if($7==&quot;+&quot;) {start=$4-1; up=start-1000; if(up&lt;0) up=0; dw=start+500; \\ print $1,up, dw, ensn, symbol, $7;} else \\ if($7==&quot;-&quot;) {start=$5-1; up=start+1000; dw=start-500; \\ if(dw&lt;0) dw=0; print $1,dw,up,ensn,symbol,$7}}}&#39; | sort -k1,1 -k2,2n \\ &gt;GRCh38.promoter.bed 数据矩阵的格式化输出 ct@ehbio:~/sxbd$ cat numeric.matrix ID A B C a 1.002 1.234 1.999 b 2.333 4.232 0.889 ct@ehbio:~/sxbd$ awk &#39;{if(FNR==1) print $0; \\ else {printf &quot;%s%s&quot;,$1,FS; for (i=2; i&lt;=NF; i++) \\ printf &quot;%.1f %s&quot;, $i, (i==NF?RS:FS)}}&#39; numeric.matrix ID A B C a 1.0 1.2 2.0 b 2.3 4.2 0.9 判断FASTQ文件中，输出质量值的长度是与序列长度不一致的序列ID ct@ehbio:~/sxbd$ cat &lt;&lt;END | gzip -c &gt;Test_2.fq.gz &gt;ehbio1 ACGTCGACGACGAGAGGAGAGGAGCCCTCTCGCCCGCCCTACTACCACCCACACACAACACAAGTGT + FFFFFFA$A#$$AFEEEEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF &gt;ehbio2 ACGTCGACGACGAGAGGAGAGGAGCCCTCTCGCCCGCCCTACTACCACCCACACACAACACAAGTGT + FFFFFF$A#$$AFEEEEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF &gt;ehbio3 ACGTCGACGACGAGAGGAGAGGAGCCTCTCGCCCGCCCTACTACCACCCACACACAACACAAGTGT + FFFFFFA$A#$$AFEEEEFFFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF END ct@ehbio:~/sxbd$ zcat Test_2.fq.gz | \\ awk &#39;{if(FNR%4==1) ID=$0; else if(FNR%4==2) seq_len=length($0); \\ else if(FNR%4==0) {quality_len=length($0); if(seq_len!=quality_len) print ID; }}&#39; 筛选差异基因 # TAB键分割的文件 ct@ehbio:~/sxbd$ cat de_gene ID log2fc padj A 1 0.001 B -1 0.001 C 1 0.001 D 2 0.0001 E -0.51 0.051 F 0.1 0.1 G 1 0.1 ct@ehbio:~/sxbd$ awk &#39;$3&lt;0.05 || NR==1&#39; de_gene ID log2fc padj A 1 0.001 B -1 0.001 C 1 0.001 D 2 0.0001 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{if(FNR==1) print $0; \\ else {abs_log2fc=($2&lt;0?$2*(-1):$2);if(abs_log2fc&gt;=1 &amp;&amp; $3&lt;0.05) print $0;}}&#39; de_gene ID log2fc padj A 1 0.001 B -1 0.001 C 1 0.001 D 2 0.0001 筛选差异基因存储到不同的文件 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;; up=&quot;up&quot;; dw=&quot;dw&quot;;}\\ {if(FNR==1) {print $0 &gt;up; print $0 &gt;dw;} else \\ if ($3&lt;0.05) {if ($2&gt;=1) print $0 &gt;up; else if($2&lt;=-1) print $0 &gt;dw;}}&#39; de_gene ct@ehbio:~/sxbd$ head up dw ==&gt; up &lt;== ID log2fc padj A 1 0.001 C 1 0.001 D 2 0.0001 ==&gt; dw &lt;== ID log2fc padj B -1 0.001 筛选差异基因存储到不同的文件(自动版) awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;; up=ARGV[1]&quot;.up&quot;; dw=ARGV[1]&quot;.dw&quot;;}\\ {if(FNR==1) {print $0 &gt;up; print $0 &gt;dw;} \\ else if ($3&lt;=0.05) {if($2&lt;=-1) print $0 &gt;up; else if ($2&gt;=1) print $0 &gt;dw;}}&#39; de_gene ID map，常用于转换序列的ID、提取信息、合并信息等 # TAB键分割的文件 ct@ehbio:~/sxbd$ cat id_map ENSM Symbol Entrez ENSG00000280516 TMEM42 693149 ENSG00000281886 TGM4 7047 ENSG00000280873 DGKD 8527 ENSG00000281244 ADAMTS13 11093 ENSG00000280701 RP11-272D20.2 ENSG00000280674 ZDHHC3 51304 ENSG00000281623 Y_RNA ENSG00000280479 CACFD1 11094 ENSG00000281165 SLC2A6 11182 ENSG00000281879 ABO 28 ENSG00000282873 BCL7A 605 ENSG00000280651 AC156455.1 100506691 ct@ehbio:~/sxbd$ vim ensm ct@ehbio:~/sxbd$ cat ensm ENSG00000281244 ENSG00000281165 ENSG00000282873 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}ARGIND==1{if(FNR&gt;1) ensm2entrez[$1]=$3;}\\ ARGIND==2{print ensm2entrez[$1];}&#39; id_map ensm 11093 11182 605 # 替代解决方案，注意 -w的使用，避免部分匹配。最稳妥的方式还是使用awk。 ct@ehbio:~/sxbd$ grep -w -f ensm id_map | cut -f 3 11093 11182 605 转换大小写, toupper, tolower ct@ehbio:~/sxbd$ cat symbol Tgm4 Dgkd Abo ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}ARGIND==1{if(FNR&gt;1) ensm2entrez[$2]=$3;}\\ ARGIND==2{print ensm2entrez[toupper($1)];}&#39; id_map symbol 7047 8527 28 awk数值操作 ct@ehbio:~/sxbd$ cat &lt;&lt;END &gt;file 2 4 3.1 4.5 5.4 7.6 8 END # log2对数 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=&quot;\\t&quot;;FS=&quot;\\t&quot;}{print log($0)/log(2)}&#39; file # 取整,四舍五入 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=&quot;\\t&quot;;FS=&quot;\\t&quot;}{print int($1+0.5);}&#39; file awk定义函数 ct@ehbio:~/sxbd$ cat &lt;&lt;END | sed &#39;s/ */\\t/g&#39;&gt;file 1 2 3 4 5 6 7 8 9 10 11 12 END ct@ehbio:~/sxbd$ awk &#39;function abs(x){return ((x &lt; 0.0) ? -x : x)}BEGIN{OFS=&quot;\\t&quot;;FS=&quot;\\t&quot;}\\ {pos[1]=$1;pos[2]=$2;pos[3]=$3;pos[4]=$4; len=asort(pos); \\ for(i=len;i&gt;1;i--) print abs(pos[i]-pos[i-1]);}&#39; file 字符串匹配 # TAB键分割的文件 ct@ehbio:~/sxbd$ cat ens.bed 1 100 105 2 100 105 3 100 105 Mt 100 105 X 100 105 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{if($1~/^[0-9XY]/) $1=&quot;chr&quot;$1; else \\ if($1~/M.*/) gsub(/M.*/, &quot;chrM&quot;, $1); print $0}&#39; ens.bed chr1 100 105 chr2 100 105 chr3 100 105 chrM 100 105 chrX 100 105 字符串分割 ct@ehbio:~/sxbd$ cat trinity_id Trinity_C1_g1_i1 Trinity_C1_g1_i2 Trinity_C1_g1_i3 Trinity_C2_g1_i1 Trinity_C3_g1_i1 Trinity_C3_g3_i2 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{count=split($1, geneL, &quot;_&quot;); gene=geneL[1]; \\ for(i=2;i&lt;count;i++) gene=gene&quot;_&quot;geneL[i]; print gene,$1;}&#39; trinity_id Trinity_C1_g1 Trinity_C1_g1_i1 Trinity_C1_g1 Trinity_C1_g1_i2 Trinity_C1_g1 Trinity_C1_g1_i3 Trinity_C2_g1 Trinity_C2_g1_i1 Trinity_C3_g1 Trinity_C3_g1_i1 Trinity_C3_g3 Trinity_C3_g3_i2 awk脚本 ct@ehbio:~/sxbd$ cat &lt;&lt;END &gt;grade.awk BEGIN{OFS=FS=&quot;\\t&quot;; up=ARGV[1]&quot;.up&quot;; dw=ARGV[1]&quot;.dw&quot;;} {if(FNR==1) {print $0 &gt;up; print $0 &gt;dw;} else if ($3&lt;=0.05) { if($2&lt;=-1) print $0 &gt;up; else if ($2&gt;=1) print $0 &gt;dw;} } END ct@ehbio:~/sxbd$ awk -f grade.awk de_gene awk给每行增加行号，使其变为唯一 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=&quot;\\t&quot;;FS=&quot;\\t&quot;}NR!=1{$4=$4&quot;_&quot;NR;print $0}&#39; file 3.2.3 糅合操作 awk中执行系统命令 (注意引号的使用) # input_mat ct@ehbio:~/sxbd$ cat &lt;&lt;END | sed &#39;s/ */\\t/g&#39; &gt;input_mat SRR1 root SRR2 leaf SRR3 stem END ct@ehbio:~/sxbd$ touch SRR1.fq SRR2.fq SRR3.fq ct@ehbio:~/sxbd$ ls SRR1.fq SRR2.fq SRR3.fq # 系统命令组成字符串，交给system函数运行 ct@ehbio:~/sxbd$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{system(&quot;mv &quot;$1&quot;.fq &quot;$2&quot;.fq&quot;);}&#39; input_mat # ct@ehbio:~/sxbd$ ls leaf.fq root.fq stem.fq awk 引用系统变量 ct@ehbio:~/sxbd$ echo 1 | awk -v ehbio=&quot;shengxinbaodian&quot; \\ -v ehbio2=&quot;sxbd&quot; &#39;{print ehbio, ehbio2;}&#39; shengxinbaodian sxbd 3.3 SED命令 3.3.1 sed基本参数解释 sed是stream editor的简称，擅长对文件进行各种正则操作、插入操作、替换操作和删除操作，可以全局，可以指定特定范围的行或者特定特征的行。 s/pat/replace/: 正则替换 前插行i, 后插行a, 替换行c, 删除行d, 输出行p N: 读入下一行，同时存储；n:读入下一行，抛弃当前行 3.3.2 常见操作 替换特定的文本 # 空格是我们不太喜欢出现在文件中的一个符号，尤其是作为列名字时 # 列使用TAB键分割 ct@ehbio:~/sxbd$ cat &lt;&lt;END | sed &#39;s/;/\\t/g&#39; mat ID;2 cell;4 cell;8 cell;embryo Pou5f1_1;2;3;4;5 Nanog_1;2;3.2;4.3;5 c-Myc;2;3;4;5 Tet1_3;2;3;4;5 END # 一次替换 ct@ehbio:~/sxbd$ sed &#39;s/ /_/&#39; mat ID 2_cell 4 cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 # 全部替换 ct@ehbio:~/sxbd$ sed &#39;s/ /_/g&#39; mat ID 2_cell 4_cell 8_cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 获得逗号分隔的一组数 ct@ehbio:~/sxbd$ echo `seq 1 10` | sed &#39;s/ /,/g&#39; 1,2,3,4,5,6,7,8,9,10 针对指定行替换 ct@ehbio:~/sxbd$ sed &#39;2,$ s/_[0-9]//g&#39; mat ID 2 cell 4 cell 8 cell embryo Pou5f1 2 3 4 5 Nanog 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1 2 3 4 5 替换特定出现位置 # 替换第一个空格 ct@ehbio:~/sxbd$ sed &#39;s/ /_/1&#39; mat ID 2_cell 4 cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 # 替换第二个空格 ct@ehbio:~/sxbd$ sed &#39;s/ /_/2&#39; mat ID 2 cell 4_cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 # 替换第二个及以后的空格 ct@ehbio:~/sxbd$ sed &#39;s/ /_/2g&#39; mat ID 2 cell 4_cell 8_cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 给序列起名字 ct@ehbio:~/sxbd$ cat seq ACDGTFGGCATGCDTGD ACDGAGCDTAGCDGTA CAGDTAGDCTADTG ct@ehbio:~/sxbd$ sed = seq 1 ACDGTFGGCATGCDTGD 2 ACDGAGCDTAGCDGTA 3 CAGDTAGDCTADTG # 同时缓冲两行，但只对第一行行首操作 ct@ehbio:~/sxbd$ sed = seq | sed &#39;N;s/^/&gt;/;&#39; &gt;1 ACDGTFGGCATGCDTGD &gt;2 ACDGAGCDTAGCDGTA &gt;3 CAGDTAGDCTADTG 给文件增加标题行 ct@ehbio:~/sxbd$ tail -n +2 mat | sort -k2,2n c-Myc 2 3 4 5 Nanog_1 2 3.2 4.3 5 Pou5f1_1 2 3 4 5 Tet1_3 2 3 4 5 # 1 表示第一行 # i 表示插入，在指定行前面插入新行 ct@ehbio:~/sxbd$ tail -n +2 mat | sort -k2,2n | sed &#39;1 i ID\\t2_cell\\t4_cell\\t8_cell\\tembryo&#39; ID 2_cell 4_cell 8_cell embryo c-Myc 2 3 4 5 Nanog_1 2 3.2 4.3 5 Pou5f1_1 2 3 4 5 Tet1_3 2 3 4 5 提取特定或指定范围的行 # -n是必须的，阻止程序自动输出匹配行，不然会导致重复输出 ct@ehbio:~/sxbd$ sed -n &#39;2,4p&#39; mat Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 ct@ehbio:~/sxbd$ sed -n &#39;4p&#39; mat c-Myc 2 3 4 5 提取符合特定模式的行 /pattern/支持普通字符串和正则表达式匹配 ct@ehbio:~/sxbd$ sed -n &#39;/_/ p&#39; mat Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 Tet1_3 2 3 4 5 ct@ehbio:~/sxbd$ sed -n &#39;/-/ p&#39; mat c-Myc 2 3 4 5 去除文件中的空行 ct@ehbio:~/sxbd$ cat mat ID 2 cell 4 cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 # 空行就是只有行首和行尾的行 ct@ehbio:~/sxbd$ sed &#39;/^$/d&#39; mat ID 2 cell 4 cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 原位删除 ct@ehbio:~/sxbd$ cat mat ID 2 cell 4 cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 # -i 参数的使用 ct@ehbio:~/sxbd$ sed -i &#39;/^$/d&#39; mat ct@ehbio:~/sxbd$ cat mat ID 2 cell 4 cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc 2 3 4 5 Tet1_3 2 3 4 5 删除指定范围的行 ct@ehbio:~/sxbd$ cat mat ID 2 cell 4 cell 8 cell embryo Pou5f1_1 2 3 4 5 Nanog_1 2 3.2 4.3 5 c-Myc_2 2 3 4 5 Tet1_3 2 3 4 5 ct@ehbio:~/sxbd$ sed &#39;2,3d&#39; mat ID 2 cell 4 cell 8 cell embryo c-Myc_2 2 3 4 5 Tet1_3 2 3 4 5 记忆匹配 \\(\\)启动记忆匹配；\\1为第一个匹配项，\\2为第二个匹配项；匹配项的计数根据左括号出现的位置来定，第一个(包括起来的为\\1。 ct@ehbio:~/sxbd$ echo &quot;hah ehbio hah&quot; | sed &#39;s/ \\(.*\\) /\\t\\1\\t\\1\\t/&#39; hah ehbio ehbio hah 奇偶数行处理 ct@ehbio:~/sxbd$ echo -e &quot;odd\\neven\\nodd\\neven&quot; odd even odd even # 奇偶数行合并 ct@ehbio:~/sxbd$ echo -e &quot;odd\\neven\\nodd\\neven&quot; | sed &#39;N;s/\\n/\\t/&#39; odd even odd even # 取出偶数行，比较简单 # 注意 n (小写)撇掉了奇数行 ct@ehbio:~/sxbd$ echo -e &quot;odd\\neven\\nodd\\neven&quot; | sed -n &#39;n;p&#39; even even # 取出奇数行 # 先都读进去，然后替换偶数行为空值，再输出 ct@ehbio:~/sxbd$ echo -e &quot;odd\\neven\\nodd\\neven&quot; | sed -n &#39;N;s/\\n.*//;p&#39; odd odd Windows/Linux换行符困境 Windows下的换行符是\\r\\n, Linux下换行符是\\n, MAC下换行符是\\r。所以Windows下的文件拷贝到Linux后，常会出现行尾多一个^M符号的情况，从而引起匹配或其它解析问题。 ^M的输是 ctrl+v+M ctrl+v;ctrl+m，不是简单的输入^,再输入M。 ct@ehbio:~/sxbd$ cat -A windows.txt ID^M$ A^M$ B^M$ C^M$ ct@ehbio:~/sxbd$ sed &#39;s/^M//&#39; windows.txt | cat -A ID$ A$ B$ C$ sed中使用bash变量 # 注意双引号的使用 ct@ehbio:~/sxbd$ bash_variable=&#39;ehbio&#39; ct@ehbio:~/sxbd$ echo &quot;sheng xin bao dan &quot; | sed &quot;s/$/$bash_variable/&quot; sheng xin bao dan ehbio 3.4 VIM的使用 VIM是一款功能强大的文本编辑工具，也是我在Linux，Windows下编辑程序和文本最常用的工具。 3.4.1 初识VIM VIM分多种状态模式，写入模式，正常模式，可视化模式。 正常模式：打开或新建文件默认在正常模式，可以浏览，但不可以写入内容。这个模式也可以称作命令行模式，这个模式下可以使用VIM强大的命令行和快捷键功能。其它模式下按ESC就可以到正常模式。 写入模式：在正常模式下按字母i (光标前插入), o (当前光标的下一行操作), O (当前光标的上一行操作)，a (光标后插入)都可以进入写入模式，就可以输入内容了。 可视化模式：通常用于选择特定的内容。 进入写入模式后，VIM使用起来可以跟记事本一样了。在写入文字时，可以利用组合键CTRL+n和CTRL+p完成写作单词的自动匹配补全，从而加快输入速度，保证输入的前后一致。 正常模式有更强大的快捷键编辑功能，把手从鼠标上解放出来。 dd: 删除一行 3dd: 删除一行 dw: 删除一个单词 d3w: 删除3个单词 yy: 复制一行 3yy: 复制三行 yw: 复制一个单词 p: (小写p)粘贴到下一行 P: (大写P)粘贴到上一行 &gt;&gt;: 当前行右缩进一个TAB 3&gt;&gt;: 当前行及后2行都向右缩进一个TAB &lt;&lt;: 当前行左缩进一个TAB 3&lt;&lt;: 当前行及后2行都向左缩进一个TAB /word: 查找特定单词 u: 撤销上一次操作 .: 重复上一次操作 CTRL+r: 重做撤销的操作 y$: 从当前复制到行尾 d$: 从当前删除到行尾 跳转操作 gg: 跳到文件开头 G: 跳到文件结尾 zt: 当前行作为可视屏幕的第一行 5G: 跳到第5行 正常模式下输入冒号进入更强大的命令行定制功能。 :5d: 删除第5行 :20,24y：复制20到24行 :.,+3y：复制当前行和下面3行 :2,11&gt;: 右缩进 :w: 保存文件 :q: 退出编辑器 :vsplit: 分屏 键盘操作不容易被捕获，看右下角可以得到一点信息。动图请点击查看。 VIM还有不少魔性操作，具体可以看这两个帖子： http://coolshell.cn/articles/5426.html http://coolshell.cn/articles/11312.html 3.4.2 VIM中使用正则表达式 这儿以提取生信宝典公众号中发过的原创文章的HTML代码为例子，获得原创文章的名字和链接，用以制作文章列表。 部分数据如下所示，利用正则表达式的第一步就是找规律。 这段文字是JSON格式，列表和字典的组合，使用json函数可以很容易解析。但我们这通过正则表达式解析。 title后面跟随的文章的题目; url后面跟随的是文章的链接。 {\"和\"}标记每篇文章的信息的开始和结束。 auth_apply_num是目前不关注的信息。 下面的动画展示了如何通过正则表达式，把这段文字只保留题目和链接，并转成Markdown的格式。 :set wrap: 折行显示 :s/\"}, {\"/\\r/g: :开启命令行模式；s: 是替换，之前讲Linux命令时也多次提及；/作为分割符，三个一起出现，前两个/中的内容为被替换内容，后两个/中的内容为替换成的内容；这里没有使用正则表达式，直接是原字符的替换，\\r表示换行符。这样把每篇文章的信息单行显示，方便后续处理。 :%s/auth_apply.*\"title\":\"/[/：%表示对所有行进行操作；被替换的内容是auth_apply和title\":\"及其之间的内容(.*表示，.表示任意字符，*表示其前面的字符出现任意次) :%s/\".*\"url\":\"/](/：从题目到url之间的内容替换掉；第一次替换时忘记了第一行中开头还有引号，结果出现了误操作，后面又退回去，手动删除特殊部分，其它部分继续匹配。 :%s/$/)/：表示在行尾($)加上), 就组成了Markdown中完整的链接形式[context](link)。 :%s/^/* /：表示在行首(^)加上*变成Markdown格式的列表 至此就完成了生信宝典公众号文章到Markdown链接的转换，可以放到菜单栏文章集锦里面方便快速查询了。 一步步的处理也有些麻烦，有没有办法更简单些呢？ 动画可查看链接。 首先也是把每篇文章的信息处理为单行显示，一样的模式更容易操作，去掉第一行行首不一致的部分 使用上下箭头可以回溯之前的命令，类似于Linux终端下的操作 %s/.*title\":\"\\([^\"]*\\).*url\":\"\\(.*\\)/* [\\1](\\2)/c: 这个是记忆匹配，记录下匹配的内容用于替换，\\(和\\)表示记忆匹配的开始和结束，自身不匹配任何字符，只做标记使用；从左只右, 第一个\\(中的内容记录为\\1, 第二个\\(中的内容记录为\\2,以此类推。尤其在存在括号嵌套的情况下，注意匹配位置，左括号出现的顺序为准。在匹配文章题目时使用了[^\"]*而不是.*，是考虑到正则表达式的匹配是贪婪的，会囊括更多的内容进来，就有可能出现非预期情况，所以做这么个限定，匹配所有非\"内容。 正则表达式在数据分析中有很多灵活的应用，可以解决复杂的字符串抽提工作。常用的程序语言或命令如pytho, R, grep, awk, sed都支持正则表达式操作，语法也大体相似。进一步学习可参考一下链接： VIM正则表达式 http://blog.csdn.net/u014015972/article/details/50688837 Pyton正则表达式 https://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html 3.5 有了这些，文件批量重命名还需要求助其它工具吗？ 3.5.1 简单重命名 Linux下文件重命名可以通过两个命令完成，mv和rename。 mv: 直接运行可以进行单个文件的重命名，如 mv old_name.txt new_name.txt rename: 默认支持单个文件或有固定规律的一组文件的批量重命名，示例如下： 3.5.1.1 rename演示 使用touch新建文件，两个样品（分别是易生信a，易生信b），各自双端测序的FASTQ文件 ysx@ehbio:~/test$ touch YSX_a_1.fq.gz YSX_a_2.fq.gz YSX_b_2.fq.gz YSX_b_1.fq.gz ysx@ehbio:~/test$ ls YSX_a_1.fq.gz YSX_a_2.fq.gz YSX_b_1.fq.gz YSX_b_2.fq.gz 把文件名中的 易生信(YSX)改为易汉博 (ehbio) # rename &#39;被替换文字&#39; &#39;要替换成的文字&#39; 操作对象 ysx@ehbio:~/test$ rename &#39;YSX&#39; &#39;ehbio&#39; *.gz ysx@ehbio:~/test$ ls ehbio_a_1.fq.gz ehbio_a_2.fq.gz ehbio_b_1.fq.gz ehbio_b_2.fq.gz 不同操作系统，rename的使用方法略有不同。印象中: 在CentOS都是上面的语法 rename old new file_list 在Ubuntu都是下面的语法 rename s/old/new/ file_list # 在Centos下，该命令未起作用 ysx@ehbio:~/test$ rename &#39;s/ehbio_//&#39; * ysx@ehbio:~/test$ ls ehbio_a_1.fq.gz ehbio_a_2.fq.gz ehbio_b_1.fq.gz ehbio_b_2.fq.gz # 如果写的rename命令没发挥作用，使用man rename查看写看其具体使用方法, 个人经验，无外乎上面提到的两种用法。 ysx@ehbio:~/test$ man rename # NAME # rename - rename files # # SYNOPSIS # rename [options] expression replacement file... 替换后缀 # 替换后缀 ysx@ehbio:~/test$ rename &#39;fq&#39; &#39;fastq&#39; *.gz ysx@ehbio:~/test$ ls ehbio_a_1.fastq.gz ehbio_a_2.fastq.gz ehbio_b_1.fastq.gz ehbio_b_2.fastq.gz 3.5.2 复杂重命名 但有时，需要重命名的文件不像上面那样有很清晰的模式，直接可以替换，需要多几步处理获得对应关系。 3.5.2.1 假如已经有对应关系 如下name.map.txt是自己手动编写的文件，a对应Control, b对应Treatment。 ysx@ehbio:~/test$ ls name.map.txt ehbio_a_1.fastq.gz ehbio_a_2.fastq.gz ehbio_b_1.fastq.gz ehbio_b_2.fastq.gz ysx@ehbio:~/test$ cat name.map.txt a Control b Treatment 3.5.2.1.1 组合文件名，使用mv重命名 首先组合出原名字和最终名字 ysx@ehbio:~/test$ awk &#39;{print &quot;ehbio_&quot;$1&quot;_1.fastq.gz&quot;, &quot;ehbio_&quot;$2&quot;_1.fastq.gz&quot;, &quot;ehbio_&quot;$1&quot;_2.fastq.gz&quot;, &quot;ehbio_&quot;$2&quot;_2.fastq.gz&quot;}&#39; name.map.txt ehbio_a_1.fastq.gz ehbio_Control_1.fastq.gz ehbio_a_2.fastq.gz ehbio_Control_2.fastq.gz ehbio_b_1.fastq.gz ehbio_Treatment_1.fastq.gz ehbio_b_2.fastq.gz ehbio_Treatment_2.fastq.gz 加上mv ysx@ehbio:~/test$ awk &#39;{print &quot;mv ehbio_&quot;$1&quot;_1.fastq.gz ehbio_&quot;$2&quot;_1.fastq.gz&quot;; print &quot;mv ehbio_&quot;$1&quot;_2.fastq.gz ehbio_&quot;$2&quot;_2.fastq.gz&quot;;}&#39; name.map.txt mv ehbio_a_1.fastq.gz ehbio_Control_1.fastq.gz mv ehbio_a_2.fastq.gz ehbio_Control_2.fastq.gz mv ehbio_b_1.fastq.gz ehbio_Treatment_1.fastq.gz mv ehbio_b_2.fastq.gz ehbio_Treatment_2.fastq.gz 可以直接拷贝上面的输出再粘贴运行，或存储为文件运行 ysx@ehbio:~/test$ awk &#39;{print &quot;mv ehbio_&quot;$1&quot;_1.fastq.gz ehbio_&quot;$2&quot;_1.fastq.gz&quot;; print &quot;mv ehbio_&quot;$1&quot;_2.fastq.gz ehbio_&quot;$2&quot;_2.fastq.gz&quot;;}&#39; name.map.txt &gt;rename.sh ysx@ehbio:~/test$ #bash rename.sh 也可以把print改为system直接运行 ysx@ehbio:~/test$ ls ehbio_a_1.fastq.gz ehbio_a_2.fastq.gz ehbio_b_1.fastq.gz ehbio_b_2.fastq.gz name.map.txt rename.sh ysx@ehbio:~/test$ awk &#39;{system(&quot;mv ehbio_&quot;$1&quot;_1.fastq.gz ehbio_&quot;$2&quot;_1.fastq.gz&quot;); system(&quot;mv ehbio_&quot;$1&quot;_2.fastq.gz ehbio_&quot;$2&quot;_2.fastq.gz&quot;);}&#39; name.map.txt ysx@ehbio:~/test$ ls ehbio_Control_1.fastq.gz ehbio_Control_2.fastq.gz ehbio_Treatment_1.fastq.gz ehbio_Treatment_2.fastq.gz name.map.txt rename.sh 3.5.2.1.2 使用rename会不会稍微简单一点？ 一定注意符号匹配和避免误匹配。 # 注意引号和空格 ysx@ehbio:~/test$ awk &#39;{print(&quot;rename &quot;$1&quot; &quot;$2&quot; *.fastq.gz&quot;); }&#39; name.map.txt rename a Control *.fastq.gz rename b Treatment *.fastq.gz # 上面的命令有什么问题吗？ # fastq中也存在a，是否也会被替换 # ehbio中也存在b，是否也会倍替换 ysx@ehbio:~/test$ awk &#39;{system(&quot;rename &quot;$1&quot; &quot;$2&quot; *.fastq.gz&quot;); }&#39; name.map.txt # 执行后，文件名都乱套了 ysx@ehbio:~/test$ ls ehbio_b_1.fControlstq.gz ehbio_b_2.fControlstq.gz ehTreatmentio_Control_1.fastq.gz ehTreatmentio_Control_2.fastq.gz name.map.txt rename.sh # 再重命名回去，再次尝试 ysx@ehbio:~/test$ rename &#39;Control&#39; &#39;a&#39; * ysx@ehbio:~/test$ rename &#39;Treatment&#39; &#39;b&#39; * ysx@ehbio:~/test$ ls ehbio_a_1.fastq.gz ehbio_a_2.fastq.gz ehbio_b_1.fastq.gz ehbio_b_2.fastq.gz name.map.txt rename.sh # 重命名两侧加下划线, 这也是我们做匹配时常需要注意的，尽量限制让匹配更准确 ysx@ehbio:~/test$ awk &#39;{system(&quot;rename _&quot;$1&quot;_ _&quot;$2&quot;_ *.fastq.gz&quot;); }&#39; name.map.txt # 打印出来看下 ysx@ehbio:~/test$ awk &#39;{print(&quot;rename _&quot;$1&quot;_ _&quot;$2&quot;_ *.fastq.gz&quot;); }&#39; name.map.txt # rename _a_ _Control_ *.fastq.gz # rename _b_ _Treatment_ *.fastq.gz # 这次没问题了 ysx@ehbio:~/test$ ls ehbio_Control_1.fastq.gz ehbio_Control_2.fastq.gz ehbio_Treatment_1.fastq.gz ehbio_Treatment_2.fastq.gz name.map.txt rename.sh 3.5.2.2 从原文件名获取对应关系 3.5.2.2.1 基于paste 像上面自己写好对应文件是一个方法，有时也可以从文件名推测规律，生成对应文件。 如下有一堆测序原始数据，选择A组样品来查看: # 如下有一堆测序原始数据，选择A组样品来查看 ysx@ehbio:~/test2# ls A* A1_FRAS192317015-1a_1.fq.gz A2_FRAS192320421-1a_1.fq.gz A3_FRAS192317017-1a_1.fq.gz A1_FRAS192317015-1a_2.fq.gz A2_FRAS192320421-1a_2.fq.gz A3_FRAS192317017-1a_2.fq.gz 中间的那一串字符FRA...-是我们不需要的。 观察规律，按下划线分割(_)，获取第1,3个元素；另外习惯性给生物重复前面也加上下划线（用到了sed的记忆匹配）。 ysx@ehbio:~/test2# ls A*.gz | cut -f 1,3 -d &#39;_&#39; | sed &#39;s/\\([A-E]\\)/\\1_/&#39; A_1_1.fq.gz A_1_2.fq.gz A_2_1.fq.gz A_2_2.fq.gz 把原样品名字与新样品名字对应起来，这里用到了paste和输入重定向 (&lt;): ysx@ehbio:~/test2# paste &lt;(ls A*.gz) &lt;(ls A*.gz | cut -f 1,3 -d &#39;_&#39; | sed &#39;s/\\([A-E]\\)/\\1_/&#39;) A1_FRAS192317015-1a_1.fq.gz A_1_1_fq.gz A1_FRAS192317015-1a_2.fq.gz A_1_2_fq.gz A2_FRAS192320421-1a_1.fq.gz A_2_1_fq.gz A2_FRAS192320421-1a_2.fq.gz A_2_2_fq.gz A3_FRAS192317017-1a_1.fq.gz A_3_1_fq.gz A3_FRAS192317017-1a_2.fq.gz A_3_2_fq.gz 使用mv直接重命名 （还可以把这个脚本保存下来，保留原始名字和新名字的对应关系，万一操作错了，在看到结果异常时也可以方便回溯） ysx@ehbio:~/test2# paste &lt;(ls A*.gz) &lt;(ls A*.gz | cut -f 1,3 -d &#39;_&#39; | sed &#39;s/\\([A-E]\\)/\\1_/&#39;) | sed &#39;s#^#/bin/mv #&#39; /bin/mv A1_FRAS192317015-1a_1.fq.gz A_1_1_fq.gz /bin/mv A1_FRAS192317015-1a_2.fq.gz A_1_2_fq.gz /bin/mv A2_FRAS192320421-1a_1.fq.gz A_2_1_fq.gz /bin/mv A2_FRAS192320421-1a_2.fq.gz A_2_2_fq.gz /bin/mv A3_FRAS192317017-1a_1.fq.gz A_3_1_fq.gz /bin/mv A3_FRAS192317017-1a_2.fq.gz A_3_2_fq.gz 软链接也是常用的 (但一定注意源文件使用全路径) ysx@ehbio:~/test2# paste &lt;(ls *.gz) &lt;(ls *.gz | sed &#39;s/\\./_/&#39; | cut -f 1,3,4 -d &#39;_&#39; | sed &#39;s/\\([A-E]\\)/analysis\\/\\1_/&#39;) | sed &#39;s#^#ln -s `pwd`/#&#39; ln -s `pwd`/A1_FRAS192317015-1a_1.fq.gz analysis/A_1_1_fq.gz ln -s `pwd`/A1_FRAS192317015-1a_2.fq.gz analysis/A_1_2_fq.gz ln -s `pwd`/A2_FRAS192320421-1a_1.fq.gz analysis/A_2_1_fq.gz . . . ln -s `pwd`/E15_FRAS192317028-1a_1.fq.gz analysis/E_15_1_fq.gz ln -s `pwd`/E15_FRAS192317028-1a_2.fq.gz analysis/E_15_2_fq.gz 3.5.2.2.2 基于awk 转换下输入数据的格式，字符处理在awk也可以操作，但我更习惯使用命令组合，每一步都用最简单的操作，不容易出错。 ysx@ehbio:~/test2# ls A*.gz | sed -e &#39;s/\\([A-E]\\)/\\1_/&#39; A_1_FRAS192317015-1a_1.fq.gz A_1_FRAS192317015-1a_2.fq.gz A_2_FRAS192320421-1a_1.fq.gz A_2_FRAS192320421-1a_2.fq.gz A_3_FRAS192317017-1a_1.fq.gz A_3_FRAS192317017-1a_2.fq.gz ysx@ehbio:~/test2# ls A*.gz | sed -e &#39;s/\\([A-E]\\)/\\1_/&#39; -e &#39;s/\\./_./&#39; A_1_FRAS192317015-1a_1_.fq.gz A_1_FRAS192317015-1a_2_.fq.gz A_2_FRAS192320421-1a_1_.fq.gz A_2_FRAS192320421-1a_2_.fq.gz A_3_FRAS192317017-1a_1_.fq.gz A_3_FRAS192317017-1a_2_.fq.gz 采用awk生成对应关系 # 生成样品重复，计数出错了，每行记了一个数，而实际两行是一个样本。 ysx@ehbio:~/test2# ls A*.gz | sed -e &#39;s/\\([A-E]\\)/\\1_/&#39; -e &#39;s/\\./_./&#39; | awk &#39;BEGIN{OFS=&quot; &quot;;FS=&quot;_&quot;}{sum[$1]+=1; print $0, $1&quot;_&quot;sum[$1]&quot;_&quot;$4$5;}&#39; A_1_FRAS192317015-1a_1_.fq.gz A_1_1.fq.gz A_1_FRAS192317015-1a_2_.fq.gz A_2_2.fq.gz A_2_FRAS192320421-1a_1_.fq.gz A_3_1.fq.gz A_2_FRAS192320421-1a_2_.fq.gz A_4_2.fq.gz A_3_FRAS192317017-1a_1_.fq.gz A_5_1.fq.gz A_3_FRAS192317017-1a_2_.fq.gz A_6_2.fq.gz # 稍微改进下 ysx@ehbio:~/test2# ls A*.gz | sed -e &#39;s/\\([A-E]\\)/\\1_/&#39; -e &#39;s/\\./_./&#39; | awk &#39;BEGIN{OFS=&quot; &quot;;FS=&quot;_&quot;}{sum[$1]+=1; print $0, $1&quot;_&quot;sum[$1]&quot;_&quot;$4$5;}&#39; A_1_FRAS192317015-1a_1.fq.gz A_1_1.fq.gz A_1_FRAS192317015-1a_2.fq.gz A_2_2.fq.gz A_2_FRAS192320421-1a_1.fq.gz A_3_1.fq.gz A_2_FRAS192320421-1a_2.fq.gz A_4_2.fq.gz A_3_FRAS192317017-1a_1.fq.gz A_5_1.fq.gz A_3_FRAS192317017-1a_2.fq.gz A_6_2.fq.gz # 记得源文件名字的替换 ysx@ehbio:~/test2# ls A*.gz | sed -e &#39;s/\\([A-E]\\)/\\1_/&#39; -e &#39;s/\\./_./&#39; | awk &#39;BEGIN{OFS=&quot; &quot;;FS=&quot;_&quot;}{sum[$1]+=1; print $0, $1&quot;_&quot;sum[$1]&quot;_&quot;$4$5;}&#39; | sed -e &#39;s/_//&#39; -e &#39;s/_\\././&#39; -e &#39;s#^#ln -s `pwd`/#&#39; |head ln -s `pwd`/A1_FRAS192317015-1a_1.fq.gz A_1_1.fq.gz ln -s `pwd`/A1_FRAS192317015-1a_2.fq.gz A_2_2.fq.gz 好了，重命名就到这了。有了这个思路，关键是如何根据自己的文件名字特征，构造对应的匹配关系。 另外，Window下使用Git for windows应该也可以实现对应的操作。 3.6 耗时很长的程序忘加nohup就运行了怎么办？ 在NGS基础：测序原始数据下载一文中提到可以使用SRA-toolkit中的命令fastq-dump从NCBI下载原始测序数据，命令如下。 nohup fastq-dump -v --split-3 --gzip SRR5908360 &amp; nohup fastq-dump -v --split-3 --gzip SRR5908361 &amp; 这个代码，给我们4个提示： fastq-dump不只可以转换下载好的sra文件为fastq文件，还可以顺带下载sra文件。只需提供SRR号，就可以获得FASTQ序列。不需要先调用prefetch下载，然后再转换。其它参数解释见引用文章。 每一行命令后面&amp;号表示把命令放入后台运行，当前终端可以继续输入其它命令；此处也相当于实现了一个手动并行下载多样本，配合for可以自动并行下载。 nohup表示让程序在终端因人为原因或网络原因断开后不挂断，适用于运行时间比较长的命令，一般与&amp;连用，形式如nohup 你的命令 &amp; (注意空格的存在)。如果程序运行输出错误信息，则会写入当前目录下nohup.out文件里面，供后续查看和调试。 经常会有一些培训班“拿来主义”比较严重，以上推文和生信宝典的其它推文都被发现过直接用于某些培训班的教材，但从未申请过授权，也未引用过出处。更有甚者，盗版易生信早期培训教案和视频，用于自己的课程或在全网发布，希望大家多多举报。 言归正传，通常我们运行程序前，会有个预判，如前面那个例子，运行时间比较长，会使用nohup 我的命令 &amp;的形式进行运行，从而保证程序不受网络或终端异常退出的影响。 但有时也会有误判，如没想到某个程序运行了半个小时还没结束，或数据传输时网太慢，需要传输很久，这时怎么办？中止程序，然后加上nohup再从头运行？还是有更好的办法？ 下面看这个例子：马上要去吃午饭了，把文件同步到另一个服务器，饭后回来继续操作： ysx@ehbio:~/test/Bigwig$ rsync -av * ysx@46.93.19.14:/tmp ysx@46.93.19.14&#39;s password: sending incremental file list test1Y_DK10.bw 输入密码后，发现同步速度太慢了，1分钟只同步了1个文件，后面还有99个文件，待会离开后，如果网断了，终端退出，程序终止怎么办？同步不能完成，饭后怎么愉快的工作？ 还好我们有下面的方案，一步步跟着操作，补救一下。 第一步，按ctrl+z把程序挂起，操作后屏幕会出现如下提示([1]中的1表示命令的作业号，后面会用到)： ^Z [1]+ 已停止 rsync -av * ysx@46.93.19.14:/tmp 第二步（可选），用jobs命令查看下任务状态，跟刚才的屏幕提示一致，程序被暂时终止，作业号还是1： ysx@ehbio:~/test/Bigwig$ jobs [1]+ 已停止 rsync -av * ysx@46.93.19.14:/tmp 第三步，使用bg %1命令把作业号为1的任务放入后台，并从停止状态变为运行状态，相当于加了&amp;后接着运行。再用jobs查看，任务状态变成了运行中，这一步很关键。如果没有运行bg %1则程序处于停止状态，一直不会运行，吃几顿饭都不会运行。 ysx@ehbio:~/test/Bigwig$ bg %1 [1]+ rsync -av * ysx@46.93.19.14:/tmp &amp; ysx@ehbio:~/test/Bigwig$ jobs [1]+ 运行中 rsync -av * ysx@46.93.19.14:/tmp &amp; 第四步，运行disown -h %1，表示在终端关闭时不对作业号为1的程序发送终止信号，外部因素将不影响程序的运行。通过ps命令查看下任务进程 (可选)。 ysx@ehbio:~/test/Bigwig$ disown -h %1 ysx@ehbio:~/test/Bigwig$ ps -auwx | grep &#39;rsync&#39; ysx 18214 0.0 0.0 117844 1720 ? S 09:43 0:01 rsync -av *.bw ysx@46.93.19.14:/tmp ysx 18215 0.1 0.0 182376 8360 ? S 09:43 0:04 ssh -l ysx 46.93.19.14 rsync --server -vlogDtpre.iLsfxC . /tmp ysx 18340 0.0 0.0 112724 984 pts/1 S+ 10:17 0:00 grep --color=auto rsync 通过以上4步就完成了对这次操作的事后补救。以后遇到同类问题，试一试这个新方案吧！ 同时还有5点提示： 例子中使用的是rsync同步，从节省时间来看，不是一个很好的例子。因为把命令停掉再运行一次时，已经同步完整的数据不会再同步，时间损失不会太大。这也是使用同步命令rsync相比于scp的一个好处。更多同步方式见(Linux服务器数据定期同步和备份方式。 例子中的rsync或其它涉及两个服务器交互的命令，都需要我们人为输入登录密码，因此直接加nohup &amp;运行是行不通的，无法接受密码的输入。因此通过上面这个操作先在前台启动运行、输入密码，再放入后台不挂断运行。从这个角度看，是一个不错的例子。当然解决这个问题也有其它方式，具体见ssh免密码登录远程服务器。 如果程序运行时，已加了&amp;号，放入后台了，则只需运行jobs获得作业号，再运行disown不挂断即可。 程序作业号不一定都是1，如果之前就有程序在后台运行，作业号相应的会自加。后面用到作业号时也需要相应修改，不要刻板总用1。 nohup和disown都可以使程序不挂断，可以获得一样的效果，但原理不太一致。nohup可以使程序忽略挂断信号(SIGHUP)或者使程序脱离终端的控制，从而终端不能再对其发送挂断信号(SIGHUP)；disown则是内生于shell，告诉shell在终止时不对对应程序发送挂断信号(SIGHUP)。 3.7 References www.ehbio.com/Training Linux学习 - 常用和不太常用的实用awk命令 Linux-总目录 Linux-文件和目录 Linux-文件操作 Linux文件内容操作 Linux-环境变量和可执行属性 Linux - 管道、标准输入输出 Linux - 命令运行监测和软件安装 Linux-常见错误和快捷操作 Linux-文件列太多，很难识别想要的信息在哪列；别焦急，看这里。 Linux-文件排序和FASTA文件操作 Linux-应用Docker安装软件 Linux服务器数据定期同步和备份方式 VIM的强大文本处理方法 Linux - Conda软件安装方法 查看服务器配置信息 Linux - SED操作，awk的姊妹篇 Linux - 常用和不太常用的实用awk命令 Bash概论 - Linux系列教程补充篇 CIRCOS圈图绘制 - circos安装 CIRCOS圈图绘制 - 最简单绘图和解释 CIRCOS圈图绘制 - 染色体信息展示和调整 CIRCOS增加热图、点图、线图和区块属性 有了这些，文件批量重命名还需要求助其它工具吗？ 耗时很长的程序忘加nohup就运行了怎么办？ "],
["bash-string.html", "4 Bash 字符串处理 4.1 Bash特殊字符 4.2 Bash变量 4.3 Bash操作符 4.4 Shell中条件和test命令 4.5 Shell流控制 4.6 Shell函数 4.7 输入输出 4.8 命令行处理 命令行处理命令: 4.9 进程和作业控制", " 4 Bash 字符串处理 视频课见 http://bioinfo.ke.qq.com。 4.1 Bash特殊字符 通配符: *: 匹配任何字符 **: 匹配任何字符串 *?: 匹配任何单个字符 集合运算符 用一些单个字、一个连续范围或断续的字符集合作为通配符 [a-z]: 用字符集合作通配符匹配单个字符, 如: [aeiou], [a-o], [A-Z], [0-9] [!A-Za-z0-9]: 除了集合外的所有字符组成的集合作通配符 花括号展开式（可以嵌套）: c{a{r,t,n}, b{r,t,n}}s 可以匹配cars cats cans cbrs cbts cbns 其它特殊字符: (): 子shell运行；比如 (cd ehbio; mdkir ysx)进入ehbio目录，新建ysx文件夹，运行完之后还在当前目录。 ': 强引用字符串, 不解释特殊字符 \": 弱引用字符串, 解释所有特殊字符 ;: 命令分隔符（命令终止符）, 运行在一行里执行多条命令;一般在终端直接写判断语句或执行for循环时用。 #: 行注释 $: 变量表达式，变量解析 &amp;: 在后台执行命令，在for循环中也可用作命令分割符，取代done前面的; 4.2 Bash变量 自定义变量 用户自定义的变量由字母、数字和下划线组成, 并且变量名的第一个字符不能为数字, 且变量名大小写敏感。 varname=value 注意bash不能在等号两侧留空格 shell语言是非类型的解释型语言, 给一个变量赋值实际上就是定义了变量, 而且可以赋不同类型的值。引用变量有两种方式, $varname和${varname}, 为防止变量在字符串中产生歧义建议使用第二种方式, 引用未定义的变量其值为空。 ct@ehbio:~$ a=&quot;EHBIO&quot; ct@ehbio:~$ echo ${a} EHBIO ct@ehbio:~$ echo $a EHBIO #出错了 ct@ehbio:~$ echo $agood #引用变量时大括号的作用 ct@ehbio:~$ echo ${a}good EHBIOgood ct@ehbio:~$ echo $a.good EHBIO.good #出错了 ct@ehbio:~$ echo $a_good #引用变量时大括号的作用 ct@ehbio:~$ echo ${a}_good EHBIO_good 为了使变量可以在其它进程中使用, 需要将变量导出: export varname 环境变量 可以用set命令给变量赋值或查看环境变量值, 使用unset命令清除变量值, 使用export导出变量将可以使其它进程访问到该环境变量。可以把设置保存到.bashrc或.bash_profile中, 成为永久的环境变量。 环境变量不限于我们之前讲过的可执行程序的环境变量、动态库、Python模块的环境变量，任何变量都可以的。 位置变量 位置变量对应于命令行参数, 其中$0为脚本名称, $1为第一个参数, 依次类推, 参数超过9个必须使用${}引用变量。shell保留这些变量, 不允许用户以另外的方式定义它们, 传给脚本或函数的位置变量是局部和只读的, 而其余变量为全局的（可以用local关键字声明为局部）。 其它变量 $?: 保存前一个命令的返回码; 0为运行成功，常用来判断上一个程序的退出状态。 $$: 当前shell的进程号 $!: 上一个子进程的进程号 $#: 传给脚本或函数的参数个数, 即位置变量数减1(1代表脚本自身) $*和$@: 传给脚本的所有参数(不包含脚本本身), 每个参数以$IFS分隔（一般内为空格, TAB, 换行）; 两者的不同点是引号括起来时，$*会被作为一个整体，$@还是单个的参数。 ct@ehbio:~$ cat ehbio_testParam.sh #!/bin/bash echo &quot;EHBIO${IFS}great&quot; echo &#39;$*&#39; echo -ne &quot;\\t&quot;; echo $* echo &#39;$@&#39; echo -ne &quot;\\t&quot;; echo $@ echo &#39;Each element in $*:&#39; for i in &quot;$*&quot;; do echo -ne &quot;\\t&quot;; echo $i; done echo &#39;Each element in $@:&#39; for i in &quot;$@&quot;; do echo -ne &quot;\\t&quot;; echo $i; done ct@ehbio:~$ bash ehbio_testParam.sh sheng xin bao dian EHBIO great $* sheng xin bao dian $@ sheng xin bao dian Each element in $*: sheng xin bao dian Each element in $@: sheng xin bao dian 4.3 Bash操作符 字符串操作符（替换操作符） ${var:-word}: 如果var存在且不为空, 返回它的值, 否则返回word ${var:=word}: 如果var存在且不为空, 返回它的值, 否则将word赋给var, 返回它的值 ${var:+word}: 如果var存在且不为空, 返回word, 否则返回空 ${var:?message} 如果var存在且不为空, 返回它的值, 否则显示“-bash: var: message”, 然后退出当前命令或脚本 ${var:offset[:length]} 从offset位置开始返回var的一个长为length的子串, 若没有length, 则默认到var串末尾 ct@ehbio:~$ echo ${var:?message} -bash: var: message ct@ehbio:~$ var=&#39;sheng xin bao dian&#39; ct@ehbio:~$ echo ${var:6:3} xin ct@ehbio:~$ echo ${var:?message} sheng xin bao dian ct@ehbio:~$ echo $? 0 ct@ehbio:~$ unset var ct@ehbio:~$ echo ${var:?message} -bash: var: message ct@ehbio:~$ echo $? 1 ct@ehbio:~$ echo ${var:=ehbio} ehbio ct@ehbio:~$ echo ${var} ehbio 模式匹配操作符 ${var#pattern} 从var头部开始, 删除和pattern匹配的最短模式串, 然后返回 剩余串 ${var##pattern} 从var头部开始, 删除和pattern匹配的最长模式串, 然后返回 剩余串, basename path＝${path##*/} ${var%pattern} 从var尾部开始, 删除和pattern匹配的最短模式串, 然后返回 剩余串, dirname path＝${path%/*} ${var%%pattern} 从var尾部开始, 删除和pattern匹配的最长模式串, 然后返回 剩余串 ${var/pattern/string} 用string替换var中和pattern匹配的最长模式串 个人最常用的是最后一个，常用于for循环中。 ct@ehbio:~$ var=&#39;sheng xin bao dian good&#39; ct@ehbio:~$ ${var/good/great} -bash: sheng: command not found ct@ehbio:~$ echo ${var/good/great} sheng xin bao dian great 比如获取fastq文件的名字部分 for i in `ls *_1.fq.gz`; do j=${i/_1.fq.gz/}; echo &quot;$j&quot;; done 4.4 Shell中条件和test命令 Bash可以使用[ … ]结构或test命令测试复杂条件 格式: [ expression ] 或 test expression 返回一个代码, 表明条件为真还是为假, 返回0为真, 否则为假。 注: 左括号后和右括号前空格是必须的语法要求 文件测试操作符 -d file: file存在并且是一个目录 -e file: file存在 -f file: file存在并且是一个普通文件 -g file: file存在并且是SGID(设置组ID)文件 -r file: 对file有读权限 -s file: file存在并且不为空 -u file: file存在并且是SUID(设置用户ID)文件 -w file: 对file有写权限 -x file: 对file有执行权限, 如果是目录则有查找权限 -O file: 拥有file -G file: 测试是否是file所属组的一个成员 -L file: file为符号链接 file1 –nt file2: file1比file2新 file1 –ot file2: file1比file2旧 举两个例子 ct@ehbio:~$ touch older ct@ehbio:~$ touch newer ct@ehbio:~$ if test -e older; then echo &quot;older esists&quot;; fi older esists ct@ehbio:~$ if test -s older; then echo &quot;older is unempty&quot;; fi ct@ehbio:~$ if [ -s older ]; then echo &quot;older is unempty&quot;; fi ct@ehbio:~$ if [ ! -s older ]; then echo &quot;older is empty&quot;; fi older is empty ct@ehbio:~$ if [ newer -nt older ]; then echo &quot;newer&quot;; fi newer 字符串操作符 str1=str2 str1和str2匹配 str1!=str2 str1和str2不匹配 str1&gt;str2 str1大于str2 -n str str的长度大于0（不为空） -z str str的长度为0（空串），常用于判断必须的命令行参数是否传入 # 字符串的大小比较的是最先遇到的不同的ASCII码的大小 ct@ehbio:~$ if test &quot;10&quot;&gt;&quot;20&quot;; then echo &quot;10&gt;20&quot;; fi 10&gt;20 ct@ehbio:~$ if test 10&gt;20; then echo &quot;10 &lt; 20&quot;; fi 整数操作符 var1 –eq var2 var1等于var2 var1 –ne var2 var1不等于var2 var1 –ge var2 var1大于等于var2 var1 –gt var2 var1大于var2 var1 –le var2 var1小于等于var2 var1 –lt var2 var1小于var2 ge: great equal; gt: great than 需要注意的是常用的数学运算符给了字符串比较，数字比较使用的却是英文缩写 数学表达式也可以 if (( 3&gt;2 )); then echo &#39;TRUE&#39;; fi TRUE 逻辑操作符 !expr 对expr求反 expr1 &amp;&amp; expr2 对expr1与expr2求逻辑与, 当expr1为假时不再执行expr2 expr1 || expr2 对expr1与expr2求逻辑或, 当expr1为真时不再执行expr2 4.5 Shell流控制 条件语句: if if, then, elif, else, fi是关键词，其它的是需要替换掉的。 if conditions; then do sth when conditions are true elif another_conditions; then do sth when another_conditions are true else: do sth when above condiitons are all false fi if test $guanzhu_sxbd == &quot;already&quot;; then echo &quot;Enjoy it&quot; elif test $guanzhu_hjyz == &quot;already&quot;; then echo &quot;Enjoy it&quot; else echo &quot;Guan zhu them&quot; fi Enjoy it 确定性循环: for do done 常用的批量操作方式 遍历一个列表，取出每个元素，针对性操作。 for i in `ls *_1.fq.gz`; do echo &quot;$i&quot;; done 不确定性循环: while和until declare -i a #定义整数变量 a=1 # 初始化变量 while test $a -lt 3; do echo $a a=$a+1 done echo $a 选择结构: case和select (类似getopts) ct@ehbio:~$ cat select_case.sh PS3=&quot;Input the position of selected parameter (1 for exit):&quot; select opts in a b c d do case $opts in a) exit 0; ;; b) echo &quot; Parameters $opts&quot; ;; c) echo &quot; Parameters $opts&quot; ;; d) echo &quot; Parameters $opts&quot; ;; ?) echo &quot;Unknown&quot; ;; esac done ct@ehbio:~$ bash select_case.sh 1) a 2) b 3) c 4) d Input the position of selected parameter (1 for exit):2 Parameters b Input the position of selected parameter (1 for exit):3 Parameters c Input the position of selected parameter (1 for exit):4 Parameters d Input the position of selected parameter (1 for exit):1 命令shift 将存放在位置变量中的命令行参数依次向左传递shift n 命令行参数向左传递n个参数串 ct@ehbio:~$ cat ehbio_testParam.sh #!/bin/bash echo &#39;Each element in $*:&#39; for i in &quot;$*&quot;; do echo -ne &quot;\\t&quot;; echo $i; done echo $1 shift for i in &quot;$*&quot;; do echo -ne &quot;\\t&quot;; echo $i; done ct@ehbio:~$ bash ehbio_testParam.sh sheng xin bao dian Each element in $*: sheng xin bao dian sheng xin bao dian 4.6 Shell函数 function function_name () { function body}定义函数，函数参数的获取同命令行参数获取。 ct@ehbio:~$ cat test_func.sh function show_ehbio () { echo $@ echo $1 } show_ehbio &quot;EHBIO great&quot; &quot;SXBD great&quot; ct@ehbio:~$ bash test_func.sh EHBIO great SXBD great EHBIO great 4.7 输入输出 I/O重定向 管道、标准输入输出之前有过详细介绍。 &lt;: 输入重定向 &gt;: 输出重定向(没有文件则创建, 有则覆盖) &gt;&gt;: 输出重定向(没有则创建, 有则追加到文件尾部) &lt;&lt;: 输入重定向(here文档) command &lt;&lt; label input… label 说明: 使一个命令的输入为一段shell脚本(input…), 直到标号(label)结束 ftp: USER=anonymous PASS=YC@163.com #-i: 非交互模式 -n: 关闭自动登录 ftp –i –n &lt;&lt; END open ftp.163.com user $USER $PASS cd /pub close END #END标记输入结束 字符串I/O操作 字符串输出: echo 命令选项: -e: 启动转义序列 -n: 取消输出后换行 (前面已经用到过) 字符串输入: read 可以用于用户交互输入, 也可以用来一次处理文本文件中的一行 命令选项: ct@ehbio:~$ read -p &quot;Enter the best tutorial: &quot; tutorial Enter the best tutorial: Sheng Xin Bao Dian ct@ehbio:~$ echo $tutorial Sheng Xin Bao Dian # 隐藏输入内容 ct@ehbio:~$ read -s -p &quot;Enter your password: &quot; password Enter your password: ct@ehbio:~$ echo $password haha 4.8 命令行处理 命令行处理命令: getopts 有两个参数, 第一个为字母和冒号组成的选项列表字符串, 第二个为一个变量名 选项列表字符串以冒号开头的选项字母排列组成, 如果一选项需要一个参数则该选项字母后跟一个冒号 getopts分解第一参数, 依次将选项摘取出来赋给第二个参数变量 如果某选项有参数, 则读取参数到内置变量OPTARG中 内置变量OPTIND保存着将被处理的命令行参数（位置参数）的数值选项列表处理完毕getopts返回1, 否则返回0 如: 在我们推出的一步绘图脚本里面，就是使用Bash封装的R脚本，通过修改命令行参数，完成热图、柱状图、线图、Venn图、火山图、泡泡图等图形的绘制和定制。 while getopts &quot;hf:m:a:A:b:I:t:x:l:j:J:d:F:G:H:P:L:y:V:D:c:C:B:X:Y:R:w:u:r:o:O:s:S:p:z:Z:v:e:E:i:&quot; OPTION do case $OPTION in h) usage exit 1 ;; f) file=$OPTARG ;; m) melted=$OPTARG ;; . . . ?) usage exit 1 ;; esac done 4.9 进程和作业控制 命令行运行监测和软件安装文中讲述了部分监测命令。 如果一个命令需要运行比较久，一般使用nohup cmmand &amp;来放入后台不中断运行，这样推出终端也不影响程序。 command &amp;是把程序放入后台。 jobs: 查看后台进程 bg: 显示后台进程, 即用Ctrl+z挂起或‘命令 &amp;’执行的进程 fg job_id: 将后台进程转到前台执行 kill –9 process_id: 强制杀掉某个进程 "],
["bioinfo-tools.html", "5 Bioinfo tools 5.1 寻找Cas9的同源基因并进行进化分析 5.2 如何获取目标基因的转录因子（上）——biomart下载基因和motif位置信息 5.3 如何获取目标基因的转录因子（下）——Linux命令获取目标基因TF 5.4 emboss的使用 5.5 使用samtools计算SNP 5.6 Bedtools使用 5.7 SRA toolkit使用 5.8 生信流程开发 5.9 数据同步和备份 5.10 References", " 5 Bioinfo tools 5.1 寻找Cas9的同源基因并进行进化分析 见PPT 5.2 如何获取目标基因的转录因子（上）——biomart下载基因和motif位置信息 科研过程中我们经常会使用Ensembl(http://asia.ensembl.org/index.html) 网站来获取物种的参考基因组，其中BioMart工具可以获取物种的基因注释信息，以及跨数据库的ID匹配和注释等。 在参考基因组和基因注释文件一文中有详细介绍如何在Ensembel数据库中获取参考基因组和基因注释文件。（点击蓝字即可阅读） 生信分析中，想要找到感兴趣基因的转录因子结合位点，该怎么做呢？ 5.2.1 1. 文件准备 首先需要准备以下3个文件，后面两个文件可以在ensembl网站中下载： 感兴趣基因的名称列表（1列基因名即可） 基因组中各基因位置信息列表（6列的bed文件） 基因组中各转录因子结合位点信息列表（5列的bed文件） 5.2.2 2. 什么是bed文件？ bed格式文件提供了一种灵活的方式来定义数据行，以此描述基因注释的信息。BED行有3个必须的列和9个可选的列。 每行的数据格式要求一致。 关于bed文件格式的介绍，在https://genome.ucsc.edu/FAQ/FAQformat.html#format1中有详细说明。 我们需要下载的基因位置信息列表是一个6列的bed文件，每列信息如下： Chromosome/scaffold name Gene start (bp) Gene end (bp) Gene stable ID Gene name Strand 染色体的名称（例如chr3） Gene起始位点 Gene终止位点 Gene stable ID Gene name 定义基因所在链的方向，+或- 注：起始位置和终止位置以0为起点，前闭后开。 转录因子结合位点列表是一个5列的bed文件，每列信息如下： Chromosome/scaffold name Start (bp) End (bp) Score Feature Type 染色体的名称（例如chr3） TF起始位点 TF终止位点 Score 转录因子的名字 具体内容见后面示例，更方便理解。 5.2.3 3. BioMart数据下载 进入Ensembl主页后点击BioMart BioMart 使用下拉框-CHOOSE DATASET- 选择数据库，我们选则Ensembl Genes 93；这时出现新的下拉框-CHOOSE DATASET- ，选择目的物种，以Human gene GRCh38.p12为例。如果自己实际操作，需要选择自己的数据常用的基因组版本。如果没有历史包袱，建议选择GRCh38最新版。 BioMart 选择数据库后，点击Filters对数据进行筛选，如果是对全基因组进行分析可不用筛选, 略过不填。 BioMart 点击Attributes，在GENE处依次选择1-6列的内容，勾选顺序便是结果矩阵中每列的顺序。 BioMart 如上图中所示，点击results后跳转下载页面，中间展示了部分所选的数据矩阵，确定格式无误后点击GO即可下载。 BioMart 转录因子结合位点矩阵的下载类似上面，不过在下拉框-CHOOSE DATASET- 选择数据库时，我们选则Ensembl Regulation 93，再选择Human Binding Motif (GRCh38.p12) BioMart 在Attributes处选择需要的信息列，点击Results和GO进行数据下载 BioMart BioMart 将上述下载的两个文件分别命名为 GRCh38.gene.bed和 GRCh38.TFmotif_binding.bed ，在Shell中查看一下： 基因组中每个基因所在的染色体、位置和链的信息，以及对应的ENSG编号和Gene symbol。 Chromosome/scaffold name Gene start (bp) Gene end (bp) Gene stable ID Gene 3 124792319 124792562 ENSG00000276626 RF00100 -1 1 92700819 92700934 ENSG00000201317 RNU4-59P -1 14 100951856 100951933 ENSG00000200823 SNORD114-2 1 22 45200954 45201019 ENSG00000221598 MIR1249 -1 1 161699506 161699607 ENSG00000199595 RF00019 1 第五列为人中的转录因子，每一行表示每个转录因子在基因组范围的结合位点分布，即其可能在哪些区域有结合motif。这些区域是与TF的结合motif矩阵相似性比较高的区域，被视为潜在结合位点。有程序MEME-FIMO或Homer-Findmotifs.pl可以完成对应的工作。 Chromosome/scaffold name Start (bp) End (bp) Score Feature Type 14 23034888 23034896 7.391 THAP1 3 10026599 10026607 7.054 THAP1 10 97879355 97879363 6.962 THAP1 3 51385016 51385024 7.382 THAP1 16 20900537 20900545 6.962 THAP1 5.3 如何获取目标基因的转录因子（下）——Linux命令获取目标基因TF 我们知道有很多数据库可以查找启动子、UTR、TSS等区域以及预测转录因子结合位点，但是怎么用Linux命令处理基因信息文件来得到关注基因的启动子和启动子区结合的TF呢？ 5.3.1 1. 基础回顾 转录起始位点（TSS）：转录时，mRNA链第一个核苷酸相对应DNA链上的碱基，通常为一个嘌呤；(不考虑转录启动复合体的预转录情况) 启动子（promoter）：与RNA聚合酶结合并能起始mRNA合成的序列。与传统的核心启动子概念不同，做生信分析时，一般选择转录起始位点上游1 kb，下游 200 nt，也有选上下游各1 kb或者 2 kb的（记住这两个数，之后计算要用到）；总体上生信中选择的启动子更长，范围更广一些。 文件准备：感兴趣的基因列表（命名为targetGene.list）、还有上一期下载的GRCh38.gene.bed和GRCh38.TFmotif_binding.bed 5.3.2 2. 文件格式处理 删除文件GRCh38.gene.bed首行，第六列正负链表示形式改为-和+，并在第一列染色体位置加上chr； sed -i &#39;1d&#39; GRCh38.gene.bed # 如果用sed，注意下面2列的顺序，为什么不能颠倒过来？ sed -i &#39;s/-1$/-/&#39; GRCh38.gene.bed sed -i &#39;s/1$/+/&#39; GRCh38.gene.bed sed -i &#39;s/^/chr/&#39; GRCh38.gene.bed 删除文件GRCh38.TFmotif_binding.bed首行,并在第一列染色体位置加上chr sed -i &#39;1d&#39; GRCh38.TFmotif_binding.bed sed -i &#39;s/^/chr/&#39; GRCh38.TFmotif_binding.bed less -S filename查看一下两个矩阵内容，发现已转换完成 chr3 124792319 124792562 ENSG00000276626 RF00100 - chr1 92700819 92700934 ENSG00000201317 RNU4-59P - chr14 100951856 100951933 ENSG00000200823 SNORD114-2 + chr22 45200954 45201019 ENSG00000221598 MIR1249 - chr1 161699506 161699607 ENSG00000199595 RF00019 + chr14 23034888 23034896 7.391 THAP1 chr3 10026599 10026607 7.054 THAP1 chr10 97879355 97879363 6.962 THAP1 chr3 51385016 51385024 7.382 THAP1 chr16 20900537 20900545 6.962 THAP1 5.3.3 3. 计算基因的启动子区 上面已提过，根据经验一般启动子区域在转录起始位点（TSS）上游1 kb、下游 200 nt处，注意正负链的运算方式是不一样的，切忌出错。 awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{if($6==&quot;+&quot;) {tss=$2; tss_up=tss-1000; tss_dw=tss+200;} else {tss=$3; tss_up=tss-200; tss_dw=tss+1000;} if(tss_up&lt;0) tss_up=0;print $1, tss_up, tss_dw,$4,$5,$6;}&#39; GRCh38.gene.bed &gt; GRCh38.gene.promoter.U1000D200.bed 关于awk命令的使用方法，可以参考Linux学习 - 常用和不太常用的实用awk命令一文。 head GRCh38.gene.bed GRCh38.gene.promoter.U1000D200.bed检查一下计算是否有误。自己选取正链和负链的一个或多个基因做下计算，看看结果是否一致。做分析不是出来结果就完事了，一定谨防程序中因为不注意核查引起的bug。 ==&gt; GRCh38.gene.bed &lt;== chr3 124792319 124792562 ENSG00000276626 RF00100 - chr1 92700819 92700934 ENSG00000201317 RNU4-59P - chr14 100951856 100951933 ENSG00000200823 SNORD114-2 + chr22 45200954 45201019 ENSG00000221598 MIR1249 - chr1 161699506 161699607 ENSG00000199595 RF00019 + ==&gt; GRCh38.gene.promoter.U1000D200.bed &lt;== chr3 124792362 124793562 ENSG00000276626 RF00100 - chr1 92700734 92701934 ENSG00000201317 RNU4-59P - chr14 100950856 100952056 ENSG00000200823 SNORD114-2 + chr22 45200819 45202019 ENSG00000221598 MIR1249 - chr1 161698506 161699706 ENSG00000199595 RF00019 + 5.3.4 4. 取两文件的交集 本条命令我们使用了bedtools程序中的子命令intersect intersect可用来求区域之间的交集，可以用来注释peak，计算reads比对到的基因组区域不同样品的peak之间的peak重叠情况；Bedtools使用简介一文中有关于bedtools的详细介绍； 两文件取完交集后，cut -f取出交集文件的第5列和第11列，sort -u去处重复项，并将这两列内容小写全转变为大写，最终得到一个两列的文件。第一列是基因名，第二列是能与基因结合的TF名字。 程序不细解释，具体看文后的Linux系列教程。Bedtools使用简介 # cut时注意根据自己的文件选择对应的列 # tr转换大小写。 bedtools intersect -a GRCh38.gene.promoter.U1000D200.bed -b GRCh38.TFmotif_binding.bed -wa -wb | cut -f 5,11 | sort -u | tr &#39;a-z&#39; &#39;A-Z&#39; &gt; GRCh38.gene.promoter.U1000D200.TF_binding.txt 5.3.5 5. 提取我们关注的基因 上一步中，我们将GRCh38.gene.promoter.U1000D200.TF_binding.txt文件中的基因名和TF名都转换成了大写。 为了接下来提取目标基因转录因子时不会因大小写差别而漏掉某些基因，我们将targetGene.list中的基因名也全部转换成大写。 # 基因名字转换为大写，方便比较。不同的数据库不同的写法，只有统一了才不会出现不必要的失误 tr &#39;a-z&#39; &#39;A-Z&#39; targetGene.list &gt; GeneUP.list 目标基因列表和基因-TF对应表都好了，内容依次如下： ==&gt; GeneUP.list &lt;== ACAT2 ACTA1 ACTA2 ADM AEBP1 ==&gt; GRCh38.gene.promoter.U1000D200.TF_binding.txt &lt;== A1BG RXRA A2M-AS1 GABP A2M SRF A4GALT GABP AAAS CTCF 用awk命令，根据第一个文件GeneUP.list建立索引，若第二个文件GRCh38.gene.promoter.U1000D200.TF_binding.txt第一列中检索到第一个文件中的基因，则把第二个文件中检索到目标基因的整行存储起来，最终得到了目标基因和基因对应TF的文件targetGene.TF_binding.txt。这也是常用的取子集操作。 awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}ARGIND==1{save[$1]=1;}ARGIND==2{if(save[$1==1]) print $0}&#39; GeneUP.list GRCh38.gene.promoter.U1000D200.TF_binding.txt &gt; targetGene.TF_binding.txt 获取目标基因的转录因子是生信分析中常见的分析，希望如何获取目标基因的转录因子（上）和本文能够帮助到各位小伙伴 5.3.6 重点总结 什么是bed文件 awk命令的使用 bedtools使用 (Bedtools使用简介) 5.4 emboss的使用 EMBOSS是欧洲分子生物学开放软件包，主要做序列比对，数据库搜搜，蛋白motif分析和功能域分析，序列模式搜索，引物设计等。 Table 5.1: Popular applications of EMBOSS. Popular.applications Functions prophet Gapped alignment for profiles. infoseq Displays some simple information about sequences. water Smith-Waterman local alignment. pepstats Protein statistics. showfeat Show features of a sequence. palindrome Looks for inverted repeats in a nucleotide sequence. eprimer3 Picks PCR primers and hybridization oligos. profit Scan a sequence or database with a matrix or profile. extractseq Extract regions from a sequence. marscan Finds MAR/SAR sites in nucleic sequences. tfscan Scans DNA sequences for transcription factors. patmatmotifs Compares a protein sequence to the PROSITE motif database. showdb Displays information on the currently available databases. wossname Finds programs by keywords in their one-line documentation. abiview Reads ABI file and display the trace. tranalign Align nucleic coding regions given the aligned proteins. emboss可以使用源码编译安装或用Conda安装，在前面的基础课中已有过讲述。 下载地址 ftp://emboss.open-bio.org/pub/EMBOSS/emboss-latest.tar.gz。 下载地址 http://primer3.sourceforge.net/。 # Make sure bioconda channel has added # http://blog.genesino.com/2017/09/bioconda/ ct@ehbio:~$ conda install emboss ct@ehbio:~$ url=https://sourceforge.net/projects/primer3/files/primer3/2.3.7/ ct@ehbio:~$ wget ${url}primer3-2.3.7.tar.gz -O primer3-2.3.7.tar.gz ct@ehbio:~$ tar xvzf primer3-2.3.7.tar.gz ct@ehbio:~$ cd primer3-2.3.7/src ct@ehbio:~$ make all # 确保~/bin在环境变量中 ct@ehbio:~$ ln -s `pwd`/primer3_core ~/bin/primer32_core # Error: thermodynamic approach chosen, but path to thermodynamic parameters not specified ct@ehbio:~$ mkdir /opt/primer3_config ct@ehbio:~$ cp -R primer3-2.3.7/src/primer3_config/* /opt/primer3_config 测试数据 ct@ehbio:~$ cat &lt;&lt;END &gt;test.fa &gt;comp24_c0_seq1 TTACTCTCATCCTCCCCTTGTTGAAAGATTGGCTGCAATTGATGAACCCGATAAGAAGGTCAACTAAGAGAAGTGTAC TTTTACGCATGGCATGGCATGGCGAGATATGGCTGTAATATGAGTATTATTTTCCTATGTTGCTACCGATATTTTCTA TTTGCATATGAAAATTCCAAACCCAGAGTTAGGGGCCATATCTAAAGGGAATTTGCTAACGAGTAAATGGGAAAATAG GAAATGTCAGAGGAGAtagcctagcctagcctagcctagccTCGCCTCATGTAACGAAATACAATTTAAATTTTGCTT TACAGCTAATAGTCAGACTTTACATTTTGCTAAAA END 设计引物 ct@ehbio:~$ eprimer32 -sequence test.fa -outfile test.fa.primer \\ -targetregion 0,371 -optsize 20 -numreturn 3 \\ -minsize 15 -maxsize 25 \\ -opttm 50 -mintm 45 -maxtm 55 \\ -psizeopt 200 -prange 100-280 引物结果 # EPRIMER32 RESULTS FOR comp24_c0_seq1 # Start Len Tm GC% Sequence 1 PRODUCT SIZE: 200 FORWARD PRIMER 126 20 50.17 35.00 TATTTTCCTATGTTGCTACC REVERSE PRIMER 306 20 50.01 30.00 ACTATTAGCTGTAAAGCAAA 2 PRODUCT SIZE: 199 FORWARD PRIMER 134 20 49.88 30.00 TATGTTGCTACCGATATTTT REVERSE PRIMER 313 20 50.30 35.00 AAGTCTGACTATTAGCTGTA 3 PRODUCT SIZE: 198 FORWARD PRIMER 134 20 49.88 30.00 TATGTTGCTACCGATATTTT REVERSE PRIMER 312 20 50.30 35.00 AGTCTGACTATTAGCTGTAA 整理引物格式位PrimerSearch需要的格式 ct@ehbio:~$ awk &#39;{if($0~/EPRIMER32/) {seq_name=$5;count=1;} else \\ if($0~/FORWARD PRIMER/) forward=$7; else if ($0~/REVERSE PRIMER/) \\ {reverse=$7; printf(&quot;%s@%d\\t%s\\t%s\\n&quot;, seq_name,count,forward, reverse); \\ count+=1;} }&#39; test.fa.primer &gt;all_primer_file ct@ehbio:~$ cat all_primer_file comp24_c0_seq1@1 TATTTTCCTATGTTGCTACC ACTATTAGCTGTAAAGCAAA comp24_c0_seq1@2 TATGTTGCTACCGATATTTT AAGTCTGACTATTAGCTGTA comp24_c0_seq1@3 TATGTTGCTACCGATATTTT AGTCTGACTATTAGCTGTAA 模拟PCR ct@ehbio:~$ primersearch -seqall test.fa -infile all_primer_file \\ -mismatchpercent 5 -outfile test.database.primerSearch Primer name comp24_c0_seq1@1 Amplimer 1 Sequence: comp24_c0_seq1 TATTTTCCTATGTTGCTACC hits forward strand at 126 with 0 mismatches ACTATTAGCTGTAAAGCAAA hits reverse strand at [23] with 0 mismatches Amplimer length: 200 bp Primer name comp24_c0_seq1@2 Amplimer 1 Sequence: comp24_c0_seq1 TATGTTGCTACCGATATTTT hits forward strand at 134 with 0 mismatches AAGTCTGACTATTAGCTGTA hits reverse strand at [16] with 0 mismatches Amplimer length: 199 bp Primer name comp24_c0_seq1@3 Amplimer 1 Sequence: comp24_c0_seq1 TATGTTGCTACCGATATTTT hits forward strand at 134 with 0 mismatches AGTCTGACTATTAGCTGTAA hits reverse strand at [17] with 0 mismatches Amplimer length: 198 bp needleall 读入两个文件，第一个文件的每个序列都与第二个文件的每个序列进行全局比对，采用Needleman-Wunsch算法。 # 生成测试数据 ct@ehbio:~$ cat &lt;&lt;END &gt;generateRandom.awk BEGIN{srand(seed); seq[0]=&quot;A&quot;; seq[1]=&quot;C&quot;; seq[2]=&quot;G&quot;; seq[3]=&quot;T&quot;} {for(i=1;i&lt;=chrNum;i++) {print &quot;&gt;&quot;label&quot;&quot;i; len=(10-int(rand()*10)%2)/10*expected_len; for(j=0;j&lt;=len;j++) printf(&quot;%s&quot;, seq[int(rand()*10)%4]); print &quot;&quot;; } } END ct@ehbio:~$ echo 1 | awk -v seed=$RANDOM -v label=mm -v chrNum=2 \\ -v expected_len=40 -f generateRandom.awk &gt;test1.fa ct@ehbio:~$ echo 1 | awk -v seed=$RANDOM -v label=hs -v chrNum=2 \\ -v expected_len=40 -f generateRandom.awk &gt;test2.fa ct@ehbio:~$ cat test1.fa &gt;mm1 GTATACATCCGTAATCGGATAAAAGCGTACTATGGCG &gt;mm2 TAATTTCCCATGCACTATCACAACCCCTCGGATCAGACGCC ct@ehbio:~$ cat test2.fa &gt;hs1 GCAAACGATTGGCCGGACGTCATCACTCCCCTCCGCGGATG &gt;hs2 CACAGTCCACGCTTTAAACGTACGAACAGACTTCCTT # 输出格式见： http://emboss.sourceforge.net/docs/themes/AlignFormats.html # Both fa and fq are supported # -auto: 关闭弹出选项 ct@ehbio:~$ needleall -asequence test1.fa -bsequence test2.fa -gapopen 10 -gapextend 0.5 \\ -outfile test12.needle.alignment -auto -aformat3 pair ct@ehbio:~$ cat test12.needle.alignment ######################################## # Program: needleall # Rundate: Fri 30 Mar 2018 13:49:30 # Commandline: needleall # -asequence test1.fa # -bsequence test2.fa # -auto # -aformat3 pair # Align_format: pair # Report_file: test1.needleall ######################################## #======================================= # # Aligned_sequences: 2 # 1: mm1 # 2: hs1 # Matrix: EDNAFULL # Gap_penalty: 10.0 # Extend_penalty: 0.5 # # Length: 62 # Identity: 15/62 (24.2%) # Similarity: 15/62 (24.2%) # Gaps: 46/62 (74.2%) # Score: 27.0 # # #======================================= mm1 1 ------------------GT-ATACA------TCCGTAATCGGATAAAAG 25 || || || |||| |||||. hs1 1 GCAAACGATTGGCCGGACGTCAT-CACTCCCCTCCG----CGGATG---- 41 mm1 26 CGTACTATGGCG 37 hs1 42 ------------ 41 #======================================= # # Aligned_sequences: 2 # 1: mm2 # 2: hs1 # Matrix: EDNAFULL # Gap_penalty: 10.0 # Extend_penalty: 0.5 # # Length: 51 # Identity: 23/51 (45.1%) # Similarity: 23/51 (45.1%) # Gaps: 20/51 (39.2%) # Score: 41.0 # # #======================================= mm2 1 -----TAATTTCCCATGCAC--TATCACAACCCCT---CGGATCAGACGC 40 ..|||..|| |.|| .||||| .||||| |||||. hs1 1 GCAAACGATTGGCC--GGACGTCATCAC-TCCCCTCCGCGGATG------ 41 mm2 41 C 41 hs1 42 - 41 #======================================= # # Aligned_sequences: 2 # 1: mm1 # 2: hs2 # Matrix: EDNAFULL # Gap_penalty: 10.0 # Extend_penalty: 0.5 # # Length: 51 # Identity: 18/51 (35.3%) # Similarity: 18/51 (35.3%) # Gaps: 28/51 (54.9%) # Score: 26.0 # # #======================================= mm1 1 GTATACA-TCCGTAATCGGATAAAAGCGTACTATGGCG------------ 37 .||| ||| .||..|.||| |||| || hs2 1 ---CACAGTCC----ACGCTTTAAA-CGTA------CGAACAGACTTCCT 36 mm1 38 - 37 hs2 37 T 37 #======================================= # # Aligned_sequences: 2 # 1: mm2 # 2: hs2 # Matrix: EDNAFULL # Gap_penalty: 10.0 # Extend_penalty: 0.5 # # Length: 55 # Identity: 18/55 (32.7%) # Similarity: 18/55 (32.7%) # Gaps: 32/55 (58.2%) # Score: 36.0 # # #======================================= mm2 1 TAATTTCCCATGCACTATCACAACCC---CT-----CG---GATCAGACG 39 ||||..|| || || ||.|||||. hs2 1 ------------------CACAGTCCACGCTTTAAACGTACGAACAGACT 32 mm2 40 CC--- 41 .| hs2 33 TCCTT 37 #--------------------------------------- #--------------------------------------- ct@ehbio:~$ needleall -asequence test1.fa -bsequence test2.fa -gapopen 10 -gapextend 0.5 \\ -outfile test12.needle.score -auto # 序列1 序列2 比对长度 比对得分 ct@ehbio:~$ cat test12.needle.score mm1 hs1 62 (27.0) mm2 hs1 51 (41.0) mm1 hs2 51 (26.0) mm2 hs2 55 (36.0) 5.5 使用samtools计算SNP 安装samtools和bedtools ct@ehbio:~$ conda install samtools ct@ehbio:~$ conda install bedtools 产生随机的基因组文件。 # srand: 随机数发生器。设置固定的种子，保证每次出来的结果一致 # rand: 返回[0,1)之间的随机数，包含0不包含1 ct@ehbio:~$ echo 1 | awk -v seed=1 -v label=chr -v chrNum=4 \\ -v expected_len=60000 -f generateRandom.awk &gt;genome.fa # 显示前60个碱基 ct@ehbio:~$ ct@ehbio:~/bio$ head genome.fa | cut -c 1-60 &gt;chr1 GACCCACACTACGAGGCTCCCAACGATCAGGATTCCTATTCCCTCCTCGCTACCGGAAAA &gt;chr2 AGCCCTTACACCATCTGAGTCTGGCACACTTTTAGAACATCTACCCGTCACGAACAAGAA &gt;chr3 GTACAAGGCCCGGGGCTCGGACATTAAGCTCCTCCACTCAGCAGTCAAGTCAAACGAACA &gt;chr4 ACGCCCGTCAATTAGAGGCATTCAAAGACACCCGCCCGTGCTACAATAGGTACTACAACC 产生随机的测序文件 # -N: 获得40K read pairs # mut.txt: 突变位点或区域 ct@ehbio:~$ wgsim -N 40000 genome.fa ehbio_1.fq ehbio_2.fq &gt; mut.txt # FASTQ格式序列，4行一组 # 第一行以@开头，后面为序列名字， # 第二行为序列 # 第三行+开头，后面一般无内容；若有，也是序列名字 # 第四行，质量值，对应序列中每个碱基的测序准确度 ct@ehbio:~$ head ehbio_1.fq @chr1_17674_18124_2:0:0_2:0:0_0/1 TCGTTCAGTGGTGGTTACTCGTAGGGTCTTCCATCTGAGGCGGGCGAGCGGACGCCTTTTCTGCCTCCAG + 2222222222222222222222222222222222222222222222222222222222222222222222 @chr1_29806_30221_2:0:0_0:0:0_1/1 TTAAGTGTGCTTGGACAACGGATATGCAAGTGTCTTTGATATATCGTTAGGGATAGGTTAATTAAGGGTC + 2222222222222222222222222222222222222222222222222222222222222222222222 # 获得的突变文件如下 # Check IUPAC here: http://www.bioinformatics.org/sms/iupac.html Col1: chromosome Col2: position Col3: original base Col4: new base (IUPAC codes indicate heterozygous) Col5: which genomic copy/haplotype ct@ehbio:~$ head mut.txt chr1 6274 T C - chr1 6923 C Y + chr1 7022 C Y + chr1 10426 A W + chr1 11130 C S + chr1 12135 G R + 创建基因组索引 ct@ehbio:~$ bwa index genome.fa # samtools fadix快速获取某区域序列 ct@ehbio:~$ samtools faidx genome.fa 序列比对回基因组 ct@ehbio:~$ bwa mem -t 3 genome.fa ehbio_1.fq ehbio_2.fq | gzip &gt;map.sam.gz 筛选比对上的高质量reads ct@ehbio:~$ samtools view -F4 -q1 -b map.sam.gz -o map.bam # 下面2个排序用法都可以，看使用的samtools版本 ct@ehbio:~$ #samtools sort -@ 2 map.bam map.sortP ct@ehbio:~$ samtools sort -@ 2 -o map.sortP.bam map.bam ct@ehbio:~$ samtools index map.sortP.bam 统计比对reads数 ct@ehbio:~$ samtools view -c map.sortP.bam 79998 统计未比对上的reads数 ct@ehbio:~$ samtools view -c -f 4 map.sam.gz 统计比对到正链的reads数 ct@ehbio:~$ samtools view -c -F 16 map.sam.gz 40001 获取properly-paired的reads数 ct@ehbio:~$ samtools view -f2 -F 256 -c map.sortP.bam 79996 查看每个位置碱基比对或错配情况 # -Q 0: 测试数据使用，默认为-Q 13，表示过滤掉低质量测序碱基 ct@ehbio:~$ samtools mpileup -f genome.fa -Q 0 map.sortP.bam | less # chrName coordinate ref_base coverage reads_base reads_quality chr1 5 C 1 ^]. 2 chr1 6 A 2 .^]. 22 chr1 7 C 2 .. 22 chr1 8 A 2 .. 22 chr1 9 C 2 G. 22 chr1 10 T 3 ..^]. 222 chr1 11 A 3 ... 222 chr1 12 C 4 ...^]. 2222 chr1 13 G 4 .... 2222 chr1 14 A 4 .... 2222 chr1 15 G 4 .... 2222 chr1 16 G 4 .... 2222 mpileup format (http://samtools.sourceforge.net/pileup.shtml) 测序碱基列解释： 点(.)代表匹配正链碱基 逗号(,)代表匹配负链碱基 大写字母(ACGTN)表示正链错配 小写字母(acgtn)表示负链错配 模式\\+[0-9]+[ACGTNacgtn]+表示在当前参考位置和下一个参考位置之间有插入，插入碱基数是+后面的证书，插入碱基是数字后面的字母串。下面展示的是2 bp的插入 seq2 156 A 11 .$……+2AG.+2AG.+2AGGG &lt;975;:&lt;&lt;&lt;&lt;&lt; 模式-[0-9]+[ACGTNacgtn]+'参考基因组存在碱基缺失。下面展示的是4 bp`缺失： seq3 200 A 20 ,,,,,..,.-4CACC.-4CACC….,.,,.^~. ==&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;::&lt;;2&lt;&lt; 符号^表示测序序列起始位置落于此 (A symbol ^' marks the start of a read segment which is a contiguous subsequence on the read separated byN/S/H’ CIGAR operations). 后面跟随的符号的ASCII值减去33表示该位置碱基的质量。符号`$’表示测序序列片段的终止。主要用于从pileup文件中获得原始测序reads。 输出vcf格式 # 获得未压缩的vcf格式，方便查看 ct@ehbio:~$ samtools mpileup -f genome.fa -Q 0 -vu map.sortP.bam &gt;snp.vcf 5.6 Bedtools使用 Bedtools是处理基因组信息分析的强大工具集合。 bedtools: flexible tools for genome arithmetic and DNA sequence analysis. usage: bedtools &lt;subcommand&gt; [options] The bedtools sub-commands include: [ Genome arithmetic ] intersect Find overlapping intervals in various ways. 求区域之间的交集，可以用来注释peak，计算reads比对到的基因组区域 不同样品的peak之间的peak重叠情况。 window Find overlapping intervals within a window around an interval. closest Find the closest, potentially non-overlapping interval. 寻找最近但可能不重叠的区域 coverage Compute the coverage over defined intervals. 计算区域覆盖度 map Apply a function to a column for each overlapping interval. genomecov Compute the coverage over an entire genome. merge Combine overlapping/nearby intervals into a single interval. 合并重叠或相接的区域 cluster Cluster (but don&#39;t merge) overlapping/nearby intervals. complement Extract intervals _not_ represented by an interval file. 获得互补区域 subtract Remove intervals based on overlaps b/w two files. 计算区域差集 slop Adjust the size of intervals. 调整区域大小，如获得转录起始位点上下游3 K的区域 flank Create new intervals from the flanks of existing intervals. sort Order the intervals in a file. 排序，部分命令需要排序过的bed文件 random Generate random intervals in a genome. 获得随机区域，作为背景集 shuffle Randomly redistrubute intervals in a genome. 根据给定的bed文件获得随机区域，作为背景集 sample Sample random records from file using reservoir sampling. spacing Report the gap lengths between intervals in a file. annotate Annotate coverage of features from multiple files. [ Multi-way file comparisons ] multiinter Identifies common intervals among multiple interval files. unionbedg Combines coverage intervals from multiple BEDGRAPH files. [ Paired-end manipulation ] pairtobed Find pairs that overlap intervals in various ways. pairtopair Find pairs that overlap other pairs in various ways. [ Format conversion ] bamtobed Convert BAM alignments to BED (&amp; other) formats. bedtobam Convert intervals to BAM records. bamtofastq Convert BAM records to FASTQ records. bedpetobam Convert BEDPE intervals to BAM records. bed12tobed6 Breaks BED12 intervals into discrete BED6 intervals. [ Fasta manipulation ] getfasta Use intervals to extract sequences from a FASTA file. 提取给定位置的FASTA序列 maskfasta Use intervals to mask sequences from a FASTA file. nuc Profile the nucleotide content of intervals in a FASTA file. [ BAM focused tools ] multicov Counts coverage from multiple BAMs at specific intervals. tag Tag BAM alignments based on overlaps with interval files. [ Statistical relationships ] jaccard Calculate the Jaccard statistic b/w two sets of intervals. 计算数据集相似性 reldist Calculate the distribution of relative distances b/w two files. fisher Calculate Fisher statistic b/w two feature files. [ Miscellaneous tools ] overlap Computes the amount of overlap from two intervals. igv Create an IGV snapshot batch script. 用于生成一个脚本，批量捕获IGV截图 links Create a HTML page of links to UCSC locations. makewindows Make interval &quot;windows&quot; across a genome. 把给定区域划分成指定大小和间隔的小区间 (bin) groupby Group by common cols. &amp; summarize oth. cols. (~ SQL &quot;groupBy&quot;) 分组结算，不只可以用于bed文件。 expand Replicate lines based on lists of values in columns. split Split a file into multiple files with equal records or base pairs. [ General help ] --help Print this help menu. --version What version of bedtools are you using?. --contact Feature requests, bugs, mailing lists, etc. 安装bedtools ct@ehbio:~$ conda install bedtools 获得测试数据集(http://quinlanlab.org/tutorials/bedtools/bedtools.html) ct@ehbio:~$ mkdir bedtools ct@ehbio:~$ cd bedtools ct@ehbio:~$ url=https://s3.amazonaws.com/bedtools-tutorials/web ct@ehbio:~/bedtools$ curl -O ${url}/maurano.dnaseI.tgz ct@ehbio:~/bedtools$ curl -O ${url}/cpg.bed ct@ehbio:~/bedtools$ curl -O ${url}/exons.bed ct@ehbio:~/bedtools$ curl -O ${url}/gwas.bed ct@ehbio:~/bedtools$ curl -O ${url}/genome.txt ct@ehbio:~/bedtools$ curl -O ${url}/hesc.chromHmm.bed 交集 (intersect) Figure 5.1: bedtools intersect 查看输入文件，bed格式，至少三列，分别是染色体，起始位置(0-based, 包括)，终止位置 (1-based，不包括)。第四列一般为区域名字，第五列一般为空，第六列为链的信息。更详细解释见http://www.genome.ucsc.edu/FAQ/FAQformat.html#format1。 自己做研究CpG岛信息可以从UCSC的Table Browser获得，具体操作见http://blog.genesino.com/2013/05/ucsc-usages/。 ct@ehbio:~/bedtools$ head -n 3 cpg.bed exons.bed ==&gt; cpg.bed &lt;== chr1 28735 29810 CpG:_116 chr1 135124 135563 CpG:_30 chr1 327790 328229 CpG:_29 ==&gt; exons.bed &lt;== chr1 11873 12227 NR_046018_exon_0_0_chr1_11874_f 0 + chr1 12612 12721 NR_046018_exon_1_0_chr1_12613_f 0 + chr1 13220 14409 NR_046018_exon_2_0_chr1_13221_f 0 + 获得重叠区域(既是外显子，又是CpG岛的区域) ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed | head -5 chr1 29320 29370 CpG:_116 chr1 135124 135563 CpG:_30 chr1 327790 328229 CpG:_29 chr1 327790 328229 CpG:_29 chr1 327790 328229 CpG:_29 输出重叠区域对应的原始区域(与外显子存在交集的CpG岛) ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed -wa -wb &gt; | head -5 chr1 28735 29810 CpG:_116 chr1 29320 29370 NR_024540_exon_10_0_chr1_29321_r 0 - chr1 135124 135563 CpG:_30 chr1 134772 139696 NR_039983_exon_0_0_chr1_134773_r 0 - chr1 327790 328229 CpG:_29 chr1 324438 328581 NR_028322_exon_2_0_chr1_324439_f 0 + chr1 327790 328229 CpG:_29 chr1 324438 328581 NR_028325_exon_2_0_chr1_324439_f 0 + chr1 327790 328229 CpG:_29 chr1 327035 328581 NR_028327_exon_3_0_chr1_327036_f 0 + 计算重叠碱基数 ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed -wo | head -10 chr1 28735 29810 CpG:_116 chr1 29320 29370 NR_024540_exon_10_0_chr1_29321_r 0 - 50 chr1 135124 135563 CpG:_30 chr1 134772 139696 NR_039983_exon_0_0_chr1_134773_r 0 - 439 chr1 327790 328229 CpG:_29 chr1 324438 328581 NR_028322_exon_2_0_chr1_324439_f 0 + 439 chr1 327790 328229 CpG:_29 chr1 324438 328581 NR_028325_exon_2_0_chr1_324439_f 0 + 439 chr1 327790 328229 CpG:_29 chr1 327035 328581 NR_028327_exon_3_0_chr1_327036_f 0 + 439 chr1 713984 714547 CpG:_60 chr1 713663 714068 NR_033908_exon_6_0_chr1_713664_r 0 - 84 chr1 762416 763445 CpG:_115 chr1 761585 762902 NR_024321_exon_0_0_chr1_761586_r 0 - 486 chr1 762416 763445 CpG:_115 chr1 762970 763155 NR_015368_exon_0_0_chr1_762971_f 0 + 185 chr1 762416 763445 CpG:_115 chr1 762970 763155 NR_047519_exon_0_0_chr1_762971_f 0 + 185 chr1 762416 763445 CpG:_115 chr1 762970 763155 NR_047520_exon_0_0_chr1_762971_f 0 + 185 计算第一个(-a)bed区域有多少个重叠的第二个(-b)bed文件中有多少个区域 ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed -c | head chr1 28735 29810 CpG:_116 1 chr1 135124 135563 CpG:_30 1 chr1 327790 328229 CpG:_29 3 chr1 437151 438164 CpG:_84 0 chr1 449273 450544 CpG:_99 0 chr1 533219 534114 CpG:_94 0 chr1 544738 546649 CpG:_171 0 chr1 713984 714547 CpG:_60 1 chr1 762416 763445 CpG:_115 10 chr1 788863 789211 CpG:_28 9 另外还有-v取出不重叠的区域, -f限定重叠最小比例，-sorted可以对按sort -k1,1 -k2,2n排序好的文件加速操作。 同时对多个区域求交集 (可以用于peak的多维注释) # -names标注注释来源 # -sorted: 如果使用了这个参数，提供的一定是排序好的bed文件 ct@ehbio:~/bedtools$ bedtools intersect -a exons.bed \\ -b cpg.bed gwas.bed hesc.chromHmm.bed -sorted -wa -wb -names cpg gwas chromhmm \\ | head -10000 | tail -10 chr1 27632676 27635124 NM_001276252_exon_15_0_chr1_27632677_chromhmm chr1 27633213 27635013 5_Strong_Enhancer chr1 27632676 27635124 NM_001276252_exon_15_0_chr1_27632677_chromhmm chr1 27635013 27635413 7_Weak_Enhancer chr1 27632676 27635124 NM_015023_exon_15_0_chr1_27632677_f chromhmm chr1 27632613 27632813 6_Weak_Enhancer chr1 27632676 27635124 NM_015023_exon_15_0_chr1_27632677_f chromhmm chr1 27632813 27633213 7_Weak_Enhancer chr1 27632676 27635124 NM_015023_exon_15_0_chr1_27632677_f chromhmm chr1 27633213 27635013 5_Strong_Enhancer chr1 27632676 27635124 NM_015023_exon_15_0_chr1_27632677_f chromhmm chr1 27635013 27635413 7_Weak_Enhancer chr1 27648635 27648882 NM_032125_exon_0_0_chr1_27648636_f cpg chr1 27648453 27649006 CpG:_63 chr1 27648635 27648882 NM_032125_exon_0_0_chr1_27648636_f chromhmm chr1 27648613 27649413 1_Active_Promoter chr1 27648635 27648882 NR_037576_exon_0_0_chr1_27648636_f cpg chr1 27648453 27649006 CpG:_63 chr1 27648635 27648882 NR_037576_exon_0_0_chr1_27648636_f chromhmm chr1 27648613 27649413 1_Active_Promoter 合并区域 Figure 5.2: bedtools merge bedtools merge输入的是按sort -k1,1 -k2,2n排序好的bed文件。 只需要输入一个排序好的bed文件，默认合并重叠或邻接区域。 ct@ehbio:~/bedtools$ bedtools merge -i exons.bed | head -n 5 chr1 11873 12227 chr1 12612 12721 chr1 13220 14829 chr1 14969 15038 chr1 15795 15947 合并区域并输出此合并后区域是由几个区域合并来的 ct@ehbio:~/bedtools$ bedtools merge -i exons.bed -c 1 -o count | head -n 5 chr1 11873 12227 1 chr1 12612 12721 1 chr1 13220 14829 2 chr1 14969 15038 1 chr1 15795 15947 1 合并相距90 nt内的区域，并输出是由哪些区域合并来的 # -c: 指定对哪些列进行操作 # -o: 与-c对应，表示对指定列进行哪些操作 # 这里的用法是对第一列做计数操作，输出这个区域是由几个区域合并来的 # 对第4列做收集操作，记录合并的区域的名字，并逗号分隔显示出来 ct@ehbio:~/bedtools$ bedtools merge -i exons.bed -d 340 -c 1,4 -o count,collapse | head -4 chr1 11873 12227 1 NR_046018_exon_0_0_chr1_11874_f chr1 12612 12721 1 NR_046018_exon_1_0_chr1_12613_f chr1 13220 15038 3 NR_046018_exon_2_0_chr1_13221_f,NR_024540_exon_0_0_chr1_14362_r,NR_024540_exon_1_0_chr1_14970_r chr1 15795 15947 1 NR_024540_exon_2_0_chr1_15796_r 计算互补区域 给定一个全集，再给定一个子集，求另一个子集。比如给定每条染色体长度和外显子区域，求非外显子区域。给定基因区，求非基因区。给定重复序列，求非重复序列等。 重复序列区域的获取也可以用上面提供的链接 http://blog.genesino.com/2013/05/ucsc-usages/。 ct@ehbio:~/bedtools$ head genome.txt chr1 249250621 chr10 135534747 chr11 135006516 chr11_gl000202_random 40103 chr12 133851895 chr13 115169878 chr14 107349540 chr15 102531392 ct@ehbio:~/bedtools$ bedtools complement -i exons.bed -g genome.txt | head -n 5 chr1 0 11873 chr1 12227 12612 chr1 12721 13220 chr1 14829 14969 chr1 15038 15795 基因组覆盖广度和深度 计算基因组某个区域是否被覆盖，覆盖深度多少。有下图多种输出格式，也支持RNA-seq数据，计算junction-reads覆盖。 Figure 5.3: bedtools genomecov genome.txt里面的内容就是染色体及对应的长度。 # 对单行FASTA，可如此计算 # 如果是多行FASTA，则需要累加 ct@ehbio:~/bedtools$ awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{\\ if($0~/&gt;/) {seq_name=$0;sub(&quot;&gt;&quot;,&quot;&quot;,seq_name);} \\ else {print seq_name,length;} }&#39; ../bio/genome.fa | tee ../bio/genome.txt chr1 60001 chr2 54001 chr3 54001 chr4 60001 ct@ehbio:~/bedtools$ bedtools genomecov -ibam ../bio/map.sortP.bam -bga \\ -g ../bio/genome.txt | head # 这个warning很有意思，因为BAM中已经有这个信息了，就不需要提供了 ***** *****WARNING: Genome (-g) files are ignored when BAM input is provided. ***** # bedgraph文件，前3列与bed相同，最后一列表示前3列指定的区域的覆盖度。 chr1 0 11 0 chr1 11 17 1 chr1 17 20 2 chr1 20 31 3 chr1 31 36 4 chr1 36 43 6 chr1 43 44 7 chr1 44 46 8 chr1 46 48 9 chr1 48 54 10 两个思考题： 怎么计算有多少基因组区域被测到了？ 怎么计算平均测序深度是多少？ 数据集相似性 bedtools jaccard计算的是给定的两个bed文件之间交集区域(intersection)占总区域(union-intersection)的比例(jaccard)和交集的数目(n_intersections)。 ct@ehbio:~/bedtools$ bedtools jaccard \\ -a fHeart-DS16621.hotspot.twopass.fdr0.05.merge.bed \\ -b fHeart-DS15839.hotspot.twopass.fdr0.05.merge.bed intersection union-intersection jaccard n_intersections 81269248 160493950 0.50637 130852 小思考：1. 如何用bedtools其它工具算出这个结果？2. 如果需要比较的文件很多，怎么充分利用计算资源？ 一个办法是使用for循环, 双层嵌套。这种用法也很常见，不管是单层还是双层for循环，都有利于简化重复运算。 ct@ehbio:~/bedtools$ for i in *.merge.bed; do \\ for j in *.merge.bed; do \\ bedtools jaccard -a $i -b $j | cut -f3 | tail -n +2 | sed &quot;s/^/$i\\t$j\\t/&quot;; \\ done; done &gt;total.similarity 另一个办法是用parallel，不只可以批量，更可以并行。 root@ehbio:~# yum install parallel.noarch # parallel 后面双引号(&quot;&quot;)内的内容为希望用parallel执行的命令， # 整体写法与Linux下命令写法一致。 # 双引号后面的 三个相邻冒号 (:::)默认用来传递参数的，可多个连写。 # 每个三冒号后面的参数会被循环调用，而在命令中的引用则是根据其出现的位置，分别用{1}, {2} # 表示第一个三冒号后的参数，第二个三冒号后的参数。 # # 这个命令可以替换原文档里面的整合和替换, 相比于原文命令生成多个文件，这里对每个输出结果 # 先进行了比对信息的增加，最后结果可以输入一个文件中。 # ct@ehbio:~/bedtools$ parallel &quot;bedtools jaccard -a {1} -b {2} | awk &#39;NR&gt; | cut -f 3 \\ | sed &#39;s/^/{1}\\t{2}\\t/&#39;&quot; ::: `ls *.merge.bed` ::: `ls *.merge.bed` &gt;totalSimilarity.2 # 上面的命令也有个小隐患，并行计算时的输出冲突问题，可以修改为输出到单个文件,再cat到一起 ct@ehbio:~/bedtools$ parallel &quot;bedtools jaccard -a {1} -b {2} | awk &#39;NR&gt; | cut -f 3 \\ | sed &#39;s/^/{1}\\t{2}\\t/&#39; &gt;{1}.{2}.totalSimilarity_tmp&quot; ::: `ls *.merge.bed` ::: `ls *.merge.bed` ct@ehbio:~/bedtools$ cat *.totalSimilarity_tmp &gt;totalSimilarity.2 # 替换掉无关信息 ct@ehbio:~/bedtools$ sed -i -e &#39;s/.hotspot.twopass.fdr0.05.merge.bed//&#39; \\ -e &#39;s/.hg19//&#39; totalSimilarity.2 原文档的命令，稍微有些复杂，利于学习不同命令的组合。使用时推荐使用上面的命令。 ct@ehbio:~/bedtools$ parallel &quot;bedtools jaccard -a {1} -b {2} \\ | awk &#39;NR&gt;1&#39; | cut -f 3 \\ &gt; {1}.{2}.jaccard&quot; \\ ::: `ls *.merge.bed` ::: `ls *.merge.bed` This command will create a single file containing the pairwise Jaccard measurements from all 400 tests. find . \\ | grep jaccard \\ | xargs grep &quot;&quot; \\ | sed -e s&quot;/\\.\\///&quot; \\ | perl -pi -e &quot;s/.bed./.bed\\t/&quot; \\ | perl -pi -e &quot;s/.jaccard:/\\t/&quot; \\ &gt; pairwise.dnase.txt A bit of cleanup to use more intelligible names for each of the samples. cat pairwise.dnase.txt \\ | sed -e &#39;s/.hotspot.twopass.fdr0.05.merge.bed//g&#39; \\ | sed -e &#39;s/.hg19//g&#39; \\ &gt; pairwise.dnase.shortnames.txt Now let’s make a 20x20 matrix of the Jaccard statistic. This will allow the data to play nicely with R. awk &#39;NF==3&#39; pairwise.dnase.shortnames.txt \\ | awk &#39;$1 ~ /^f/ &amp;&amp; $2 ~ /^f/&#39; \\ | python make-matrix.py \\ &gt; dnase.shortnames.distance.matrix 5.7 SRA toolkit使用 SRA toolkit https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software根据服务器下载对应的二进制编码包。 CentOS下地址：https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.9.0/sratoolkit.2.9.0-centos_linux64.tar.gz。 常用的是fastq-dump，从NCBI的SRA数据库下载测序原始文件并转化为FASTQ格式供后续分析使用。 # --split-3: 若是双端测序则拆分 # --gzip: 拆分后压缩文件 # fastq-dump -v --split-3 --gzip SRR_number fastq-dump -v --split-3 --gzip SRR502564 下面是我写的一个脚本，有3个用途。一是在fastq-dump下载过程中，如果断了可以再次启动下载；二是下载完成之后，给下载的文件进行重命名为方便识别的名字；三是清空下载缓存。 所需要的输入文件是一个2列文件，第一列为SRR号，第二列为样品名字，TAB键分割。 SRR2952884 Y25_root SRR2952883 Y18_root SRR2952882 Y12_root SRR2952881 Y05_root #!/bin/bash set -x set -e set -u usage() { cat &lt;&lt;EOF &gt;&amp;2 ${txtcyn} Usage: $0 options${txtrst} ${bldblu}Function${txtrst}: This script is used to download sra files from a file containing SRA accession numbers and transfer SRA to fastq format. The format of input file: SRR2952884 Y25_root SRR2952883 Y18_root SRR2952882 Y12_root SRR2952881 Y05_root The second column will be treated as the prefix of final fastq files. ${txtbld}OPTIONS${txtrst}: -f Data file with format described above${bldred}[NECESSARY]${txtrst} -z Is there a header[${bldred}Default TRUE${txtrst}] EOF } file= while getopts &quot;hf:z:&quot; OPTION do case $OPTION in h) usage exit 1 ;; f) file=$OPTARG ;; ?) usage exit 1 ;; esac done if [ -z $file ]; then usage exit 1 fi #IFS=&quot;\\t&quot; cat $file | while read -r -a array do sra=&quot;${array[0]}&quot; name=&quot;${array[1]}&quot; #echo $sra, $name #prefetch -v $sra #prefetch -v $sra #prefetch -v $sra #/bin/cp ~/ncbi/public/sra/${sra}.sra ${name}.sra while true do fastq-dump -v --split-3 --gzip ${sra} a=$? if [ &quot;$a&quot; == &quot;0&quot; ]; then break; fi sleep 5m done #/bin/cp ~/ncbi/public/sra/${sra}* . if [ &quot;$a&quot; == &quot;0&quot; ] then rename &quot;${sra}&quot; &quot;${name}&quot; ${sra}* /bin/rm ~/ncbi/public/sra/${sra}.sra fi done 5.8 生信流程开发 最基本的是Bash脚本，把上面call SNP的命令放到一个Bash脚本文件中即可。另外可以使用Makefile和Airflow进行更高级一些的开发。 Airflow使用见 http://blog.genesino.com/2016/05/airflow/。 一篇不错的英文Makefile教程 http://blog.genesino.com/2011/04/introduction-to-making-makefiles/。 5.9 数据同步和备份 5.9.1 scp 最简单的备份方式，就是使用cp (本地硬盘)或 scp (远程硬盘)命令，给自己的结果文件新建一个拷贝；每有更新，再拷贝一份。具体命令如下： cp -fur source_project project_bak scp -r source_project user@remote_server_ip:project_bak 为了实现定期备份，我们可以把上述命令写入crontab程序中，设置每天的晚上23:00执行。对于远程服务器的备份，我们可以配置免密码登录，便于自动备份。后台输入免密码登录服务器，获取免密码登录服务器的方法。 # Crontab format # Minute Hour Day Month Week command # * 表示每分/时/天/月/周 # 每天23:00 执行cp命令 0 23 * * * cp -fur source_project project_bak # */2 表示每隔2分分/时/天/月/周执行命令 # 每隔24小时执行cp命令 0 */24 * * * cp -fur source_project project_bak 0 0 */1 * * scp -r source_project user@remote_server_ip:project_bak # 另外crotab还有个特殊的时间 # @reboot: 开机运行指定命令 @reboot cmd 5.9.2 rsync cp或scp使用简单，但每次执行都会对所有文件进行拷贝，耗时耗力，尤其是需要拷贝的内容很多时，重复拷贝对时间和硬盘都是个损耗。 rsync则是一个增量备份工具，只针对修改过的文件的修改过的部分进行同步备份，大大缩短了传输的文件的数量和传输时间。具体使用如下 ： # 把本地project目录下的东西备份到远程服务器的/backup/project目录下 # 注意第一个project后面的反斜线，表示拷贝目录内的内容，不在目标目录新建project文件夹。注意与第二个命令的比较，两者实现同样的功能。 # -a: archive mode, quals -rlptgoD # -r: 递归同步 # -p: 同步时保留原文件的权限设置 # -u: 若文件在远端做过更新，则不同步，避免覆盖远端的修改 # -L: 同步符号链接链接的文件，防止在远程服务器出现文件路径等不匹配导致的软连接失效 # -t: 保留修改时间 # -v: 显示更新信息 # -z: 传输过程中压缩文件，对于传输速度慢时适用 rsync -aruLptvz --delete project/ user@remoteServer:/backup/project rsync -aruLptvz --delete project user@remoteServer:/backup/ rsync所做的工作为镜像，保证远端服务器与本地文件的统一。如果本地文件没问题，远端也不会有问题。但如果发生误删或因程序运行错误，导致文件出问题，而在同步之前又没有意识到的话，远端的备份也就没了备份的意义，因为它也被损坏了。误删是比较容易发现的，可以及时矫正。但程序运行出问题，则不一定了。 5.9.3 rdiff-backup 这里推荐一个工具rdiff-backup不只可以做增量备份，而且会保留每次备份的状态，新备份和上一次备份的差别，可以轻松回到之前的某个版本。唯一的要求就是，本地服务器和远端服务器需要安装统一版本的rdiff-backup。另外还有2款工具 duplicity和`Rsnapshot也可以做类似工作，但方法不一样，占用的磁盘空间也不一样，具体可查看原文链接中的比较。 具体的rdiff-backup安装和使用见http://mp.weixin.qq.com/s/c2cspK5b4sQScWYMBtG63g。 5.10 References 高通量数据分析必备-基因组浏览器使用介绍 - 1 高通量数据分析必备-基因组浏览器使用介绍 - 2 高通量数据分析必备-基因组浏览器使用介绍 - 3 测序文章数据上传找哪里 GO、GSEA富集分析一网打进 GSEA富集分析 - 界面操作 Bedtools使用简介 OrthoMCL鉴定物种同源基因 （安装+使用） Rfam 12.0+本地使用 （最新版教程） 轻松绘制各种Venn图 ETE构建、绘制进化树 psRobot：植物小RNA分析系统 生信软件系列 - NCBI使用 去东方，最好用的在线GO富集分析工具 2018 升级版Motif数据库Jaspar 一文教会你查找基因的启动子、UTR、TSS等区域以及预测转录因子结合位点 "],
["bioinfo-questions.html", "6 Bioinfo questions", " 6 Bioinfo questions 进入sxbd目录，查看目录下的文件有哪些？ 查看GTF文件的内容和格式 (如果没有，可在ftp://ftp.ensembl.org/pub/release-91/gtf/homo_sapiens/Homo_sapiens.GRCh38.91.gtf.gz下载。) 给每个区域的行首增加chr标签，并去掉#开头的行。 grep -v &#39;^#&#39; GRCh38.gtf | sed &#39;s/^/chr/&#39; &gt;GRCh38.new.gtf 统计GTF文件中染色体数目？ ct@ehbio:~/sxbd$ cut -f1 GRCh38.new.gtf | uniq -c &gt;chrCount.txt ct@ehbio:~/sxbd$ awk &#39;{print $2&quot;\\t&quot;$1}&#39; chrCount.txt chr1 236802 chr2 194223 chr3 160954 chr4 106152 chr5 115953 chr6 116635 chr7 122750 chrX 81525 chr8 95038 chr9 91333 chr11 159595 chr10 94467 chr12 154317 chr13 38817 chr14 93293 chr15 97353 chr16 125435 chr17 166619 chr18 47336 chr20 57175 chr19 163738 chrY 7167 chr22 56380 chr21 28928 chrMT 144 chrKI270728.1 120 chrKI270727.1 88 chrKI270442.1 6 chrGL000225.1 3 chrGL000009.2 8 chrGL000194.1 26 chrGL000205.2 17 chrGL000195.1 27 chrKI270733.1 12 chrGL000219.1 12 chrGL000216.2 3 chrKI270744.1 3 chrKI270734.1 96 chrGL000213.1 52 chrGL000220.1 12 chrGL000218.1 8 chrKI270731.1 11 chrKI270750.1 3 chrKI270721.1 25 chrKI270726.1 11 chrKI270711.1 151 chrKI270713.1 20 ct@ehbio:~/sxbd$ awk &#39;/chr[0-9XYM]/&#39; chrCount.txt 236802 chr1 194223 chr2 160954 chr3 106152 chr4 115953 chr5 116635 chr6 122750 chr7 81525 chrX 95038 chr8 91333 chr9 159595 chr11 94467 chr10 154317 chr12 38817 chr13 93293 chr14 97353 chr15 125435 chr16 166619 chr17 47336 chr18 57175 chr20 163738 chr19 7167 chrY 56380 chr22 28928 chr21 144 chrMT ct@ehbio:~/sxbd$ awk &#39;/chr[0-9XYM]/&#39; chrCount.txt | sed &#39;s/ *\\([0-9]*\\) \\(chr.*\\)/\\2\\t\\1/&#39; chr1 236802 chr2 194223 chr3 160954 chr4 106152 chr5 115953 chr6 116635 chr7 122750 chrX 81525 chr8 95038 chr9 91333 chr11 159595 chr10 94467 chr12 154317 chr13 38817 chr14 93293 chr15 97353 chr16 125435 chr17 166619 chr18 47336 chr20 57175 chr19 163738 chrY 7167 chr22 56380 chr21 28928 chrMT 144 统计GTF文件中基因数目？ ct@ehbio:~/sxbd$ time cut -f 3 GRCh38.new.gtf | sort | uniq -c 712821 CDS 1199851 exon 144659 five_prime_utr 58302 gene 119 Selenocysteine 83743 start_codon 75493 stop_codon 137545 three_prime_utr 200310 transcript real 0m8.314s user 0m8.259s sys 0m0.679s # 更快 ct@ehbio:~/sxbd$ time awk &#39;{a[$3]+=1}END{for(i in a) print i,a[i];}&#39; GRCh38.new.gtf five_prime_utr 144659 exon 1199851 three_prime_utr 137545 CDS 712821 gene 58302 start_codon 83743 Selenocysteine 119 stop_codon 75493 transcript 200310 real 0m1.898s user 0m1.504s sys 0m0.394s ct@ehbio:~/sxbd$ awk &#39;{if(a[$3]==&quot;&quot;) a[$3]=1; else a[$3]=a[$3]+1;}END{for(i in a) print i,a[i];}&#39; GRCh38.new.gtf 计算GTF中外显子总长度？ # 这个是冗余的外显子，后面在计算非冗余外显子 ct@ehbio:~/sxbd$ awk &#39;{if($3==&quot;exon&quot;) sum+=$5-$4+1;}END\\ {print &quot;Total redundant exon length&quot;, sum;}&#39; GRCh38.new.gtf 计算GTF文件中每个基因的转录本数目？ # 第一个办法：基因和对应的转录本是排序好的，直接判断计算就可以 awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;;}{if($3==&quot;gene&quot; &amp;&amp; count&gt;0) {print count; count=0;} else \\ {if($3==&quot;transcript&quot;) count+=1;}}END{print count}&#39; GRCh38.new.gtf # 第二个方法：取出所有基因和转录本名字 sed &#39;s/&quot;/\\t/g&#39; GRCh38.new.gtf | awk &#39;$3==&quot;transcript&quot;&#39; | cut -f 10,14 | cut -f 1 | uniq -c # 第三个方法：与第二个类似，但使用了groupBy sed &#39;s/&quot;/\\t/g&#39; GRCh38.new.gtf | awk &#39;$3==&quot;transcript&quot;&#39; | cut -f 10,14 | \\ bedtools groupby -g 1 -c 1,2 -o count,collapse | head ENSG00000223972 2 ENST00000456328,ENST00000450305 ENSG00000227232 1 ENST00000488147 ENSG00000278267 1 ENST00000619216 ENSG00000243485 2 ENST00000473358,ENST00000469289 ENSG00000284332 1 ENST00000607096 ENSG00000237613 2 ENST00000417324,ENST00000461467 ENSG00000268020 1 ENST00000606857 ENSG00000240361 2 ENST00000642116,ENST00000492842 ENSG00000186092 2 ENST00000641515,ENST00000335137 ENSG00000238009 5 ENST00000466430,ENST00000477740,ENST00000471248,ENST00000610542,ENST00000453576 sed &#39;s/&quot;/\\t/g&#39; GRCh38.new.gtf | awk &#39;$3==&quot;transcript&quot;&#39; | cut -f 10,14 | \\ bedtools groupby -g 1 -c 1,2 -o count,collapse &gt;geneTrCount.txt 计算GTF文件中基因所拥有的平均转录本数目 awk &#39;BEGIN{OFS=FS=&quot;\\t&quot;}{sum+=$2}END{print sum/NR;}&#39; geneTrCount.txt # 3.43573 生成一个多行Fasta测试序列供后续运算 (也可使用我们前面提供的脚本生成) cat &lt;&lt;END &gt;test.fa &gt;id1 ACGCATGGGGGGGGGGGGGGGGG AGTATGGTCCAGTA &gt;id11 AGTGGGGGGGGGGGGGGGGTTCCT cgactaggcagtctgagttga &gt;id21 AGTGGGGGGGGGGGGGGGGTTCCT cgactaggcagtctgagttga END test.fa中的序列全转成大写。 # \\U 转换为大写 # &amp; 表示所有匹配内容 sed -i &#39;/^[^&gt;]/ s/.*/\\U&amp;/&#39; test.fa 计算多行FASTA文件test.fa中每条序列长度，输出类似genome.txt格式的文件(文件有两列，第一列为序列ID，第二列为序列长度) # 计算一个输出一个 awk &#39;BEGIN{OFS=&quot;\\t&quot;; size=0;}{if($0~/&gt;/) {if(size&gt;0) print geneName,size; \\ geneName=$0; sub(&quot;&gt;&quot;,&quot;&quot;,geneName); size=0;} else \\ {size+=length}}END{print geneName,size}&#39; test.fa # 全部计算完存储起来再输出 awk &#39;BEGIN{OFS=&quot;\\t&quot;;}{if($0~/&gt;/) {geneName=$0; sub(&quot;&gt;&quot;,&quot;&quot;,geneName); size[geneName]=0;} \\ else {size[geneName]+=length($0)}}END\\ {for (geneName in size) print geneName,size[geneName]}&#39; test.fa 多行FASTA转单行FASTA序列 # conditions?true_value:false_value 三目运算符，条件为真时，返回冒号前结果，否则冒号后结果 # 对于非第一行的&gt;，输出前先输出一个换行 awk &#39;/^&gt;/&amp;&amp;NR&gt;1{print &quot;&quot;;}{printf &quot;%s&quot;,/^&gt;/?$0&quot;\\n&quot;:$0}&#39; test.fa &gt;singleLine.fa 取出单行FASTA文件中序列长度大于40的序列的名字？ awk &#39;BEGIN{OFS=&quot;\\t&quot;;}{if($0~/&gt;/) {geneName=$0; sub(&quot;&gt;&quot;,&quot;&quot;,geneName); } else \\ {if (length($0)&gt;40) print geneName;}}&#39; singleLine.fa 分别用awk和grep从test.fa中提取给定ID对应的序列。 ID list: id1 id21 利用AWK对基因表达数据进行标准化 cat &lt;&lt;END | sed &#39;s/ */\\t/g&#39; &gt;test.expr ID sampleA sampleB sampleC A 1 2 3 B 4 5 6 C 6 7 8 D 10 11 12 END # 单列 awk &#39;ARGIND==1{if(FNR&gt;1) sum=sum+$2;}\\ ARGIND==2{if(FNR&gt;1) {$3=$2/sum;} print $0;}&#39; test.expr test.expr # 多列 awk &#39;ARGIND==1{if(FNR&gt;1) {for(i=2;i&lt;=NF;i++) sum[i]=sum[i]+$i;}}\\ ARGIND==2{if(FNR&gt;1) for(i=2;i&lt;=NF;i++) {$i=$i/sum[i];} print $0;}&#39; \\ test.expr test.expr 写出3种写法，去掉上一题test.expr矩阵中的第一行？ awk &#39;FNR&gt;1&#39; test.expr tail -n +2 test.expr sed -n &#39;2,$p&#39; test.expr 分别用awk和sed给test.expr矩阵加上标题行？ sed &#39;1 iheaderline&#39; test.expr awk &#39;{if(FNR==1} print &quot;headerline&quot;; print $0&#39; test.expr 给定一个BAM文件，怎么计算有多少基因组区域被测到了？平均测序深度是多少？ bedtools genomecov -ibam ../bio/map.sortP.bam -bga 如何使用bedtools的其它工具或其它Linux命令实现bedtools jaccard子功能？ bedtools jaccard计算的是给定的两个bed文件之间交集区域(intersection)占总区域(union-intersection)的比例(jaccard)和交集的数目(n_intersections)。 ct@localhost:~/bedtools$ cat test1.bed chr1 1 100 chr2 1 50 chr3 20 50 ct@localhost:~/bedtools$ cat test2.bed chr1 50 150 chr3 1 50 chr4 1 50 chr5 1 50 ct@localhost:~/bedtools$ bedtools jaccard -a test1.bed -b test2.bed intersection union-intersection jaccard n_intersections 80 296 0.27027 2 ct@localhost:~/bedtools$ bedtools intersect -a test1.bed -b test2.bed -wao \\ | awk &#39;{sum+=$NF}END{print sum;}&#39; 80 ct@localhost:~/bedtools$ cat test1.bed test2.bed | awk &#39;{sum+=$3-$2}END{print sum;}&#39; 376 "],
["supplemental.html", "7 Supplemental", " 7 Supplemental serverInfo.sh #!/bin/bash echo &quot;This lists the information of this computer.&quot; echo echo &quot;Hostname is $(tput setaf 3)`hostname`$(tput sgr0),\\ Ip address is $(tput setaf 3)\\ `/sbin/ifconfig | sed -n &#39;2p&#39; | cut -d &#39;:&#39; -f 2 | cut -d &#39; &#39; -f 1`. $(tput sgr0)&quot; nuclear=`uname -a | cut -d &#39; &#39; -f 3` bitInfo=`uname -a | cut -d &#39; &#39; -f 12` if test $bitInfo == &quot;x86_64&quot;; then bit=64 else bit=32 fi echo &quot;The $(tput bold)${bit}$(tput sgr0) bit operating \\ system is $(tput bold) `head -n 1 /etc/issue`\\ $(tput sgr0), Nuclear info is $(tput setaf 1)\\ ${nuclear}$(tput sgr0).&quot; echo echo &quot;The CPU is$(tput setaf 4)`sed -n &#39;5p&#39; /proc/cpuinfo \\ | cut -d &#39;:&#39; -f 2 | sed &#39;s/[ ] */ /g&#39;`$(tput sgr0).&quot; echo echo &quot;There are $(tput setaf 5)\\ `cat /proc/cpuinfo | grep &quot;physical id&quot; | sort | uniq \\ | wc -l`$(tput sgr0) physical cpu, \\ each physical \\ cpu has$(tput setaf 5)`sed -n &#39;12p&#39; /proc/cpuinfo | \\ cut -d &#39;:&#39; -f 2`$(tput sgr0) cores,\\ $(tput setaf 5)`sed -n &#39;10p&#39; /proc/cpuinfo | \\ cut -d &#39;:&#39; -f 2`$(tput sgr0) threads.&quot; echo echo &quot;There are $(tput setaf 5)\\ `cat /proc/cpuinfo | grep &quot;cpu cores&quot; | wc -l`$(tput sgr0) logical cpu.&quot; mem=`head -n 1 /proc/meminfo | cut -d &#39;:&#39; -f 2 | sed &#39;s/^ *//g&#39; | cut -d &#39; &#39; -f 1` memInM=$(echo &quot;$mem/1024/1024&quot; | bc -l) echo echo &quot;The memory of this server is $(tput setaf 5)${memInM}$(tput sgr0)G.&quot; echo echo &quot;The disk information is :&quot; echo &quot;`df -h`&quot; "],
["生信教程文章集锦.html", "8 生信教程文章集锦 8.1 生信宝典 8.2 宏基因组", " 8 生信教程文章集锦 8.1 生信宝典 生信的作用越来越大，想学的人越来越多，不管是为了以后发展，还是为了解决眼下的问题。但生信学习不是一朝一夕就可以完成的事情，也许你可以很短时间学会一个交互式软件的操作，却不能看完程序教学视频后就直接写程序。也许你可以跟着一个测序分析流程完成操作，但不懂得背后的原理，不知道什么参数需要修改，结果可以出来，却把我不住对还是错。 学习生信从来就不是一个简单的事，需要做好持久战的心理准备。 在学习时，我们都希望由浅入深的逐步深入，不断地练习和实践，这就是为什么我们需要一本书，因为书很系统。但生信发展的历史短于计算机编程的历史，如果想要一门程序设计的入门数据，每种语言都可以找到几本。但想要一个囊括生信的书，就有些难了。本身生信跨领域，需要多学科的知识，而其内部又有不少分子，都囊括了太大，包括的少又有些隔靴搔痒的感觉。 我们当时都是零基础下自学Linux, 自学Python，自学R，自学高通量测序；这些学习经历，之前都零星地记录在博客里。现在回头去看几年前自己记录的东西，觉得好简单，而当时却费了很大的力气。这些零星的随手记，当时也只是为了自己看，到现在确实只有自己能看得懂，不便惠及更多的人。 因此我们创建了生信宝典，希望从不同的角度传播知识。这个不同有三点含义，一是形式上的不同，摒弃之前主编们单人作战想写啥就写啥，而是有组织有计划的内容聚合，提供一系列的教程，由入门到提高。二是内容的不同，不去用网上现有教程的通用数据做例子，而是拿实际生物数据，讲述如何解释生信中普遍碰到的问题，讲述如何处理自己的数据。三是立足点不同。在写作时，我们回到了当年，在回忆中用整个阶段的学习去指导当初的那个小白，从那些会了的人觉得微不足道而不会的人又迈不过的坎入手，直击痛点。知识点的收录依据不是是否炫酷，是否难，而是是否必要。如果必要，再简单，也要提及；如果不必要，再炫酷，也暂不纳入。 通过大量的生信例子、关键的注释和浓缩的语句形成下面的一系列学习教程。每一篇内容都不多，可以当做小说阅读，也可以跟着去练，反复几遍，每读一次都会有不同的收获和体会。 8.1.1 系列教程 生物信息之程序 如何优雅的提问 生信宝典视频教程 好色之旅-画图三字经 转录组分析的正确姿势 生信的系列教程 生信的系列书籍 文章用图的修改和排版 (1) 文章用图的修改和排版 (2) 简单强大的在线绘图 简单强大的在线绘图-升级版 论文图表基本规范 学术图表的基本配色方法 英语写作常见错误总结和学习视频 教育部推出首批490门“国家精品在线开放课程 8.1.2 NGS分析工具评估 39个转录组分析工具，120种组合评估(转录组分析工具哪家强-导读版) 39个转录组分析工具，120种组合评估(转录组分析工具大比拼 （完整翻译版）) 无参转录组分析工具评估和流程展示 8.1.3 宏基因组教程 微生物组入门必读+宏基因组实操课程 扩增子图表解读-理解文章思路 扩增子分析流程-把握分析细节 扩增子统计绘图-冲击高分文章 宏基因组分析教程 4500元的微生物组培训资料 8.1.4 系列宣传 转录组分析的正确姿势 120分的转录组考题，你能得多少 生物信息作图系列R、Cytoscape及图形排版和Python编程培训研讨班开课了 维密摔倒不可怕，关键时有人搀一把，坚持走下去 生物信息作图系列 - R、网络图及文章图形排版 易生信转录组培训总结和优惠分享 生物信息9天速成班 — 你也可以成为团队不可或缺的人 Python没有捷径，但可以加速，零基础九天你也可以会编程 小学生都学Python了，你还不知道怎么开始-资源帖 一个月学会Python的Quora指南和资料放送 扩增子分析基本流程和结果解读 微生物组——扩增子分析专题实战开课啦 如何入门生信Linux 3分和30分文章差距在哪里？ 8.1.5 生信生物知识 生物研究中不可缺少的数字概念，多少，多大，多快 8.1.6 文献精读 CRISPR-CAS9发展历程小记 一场大病引起的诺贝尔2017年生理学奖角逐 Science搞反狗脑 - 人脑和狗脑一样？ 一篇压根不存在的文献被引用400次？！揭开\" 幽灵文献\" 的真面目 基于人工智能的文献检索，导师查找，更聪明 GeenMedical：文献查询、筛选、引用排序、相似文献、全文下载、杂志分区、影响因子、结果导出、杂志评述、直接投稿，一站服务 YANDEX搜索，不翻墙稳定使用近谷歌搜索 Nature我的研究对后人毫无用途：21%的学术论文自发布后从未被引用 SCI-HUB镜像, SSH隧道访问学校内网 为了速成生物学，一位程序员探索了“爆款”基因背后的秘密 8.1.7 Linux Linux-总目录 Linux-文件和目录 Linux-文件操作 Linux文件内容操作 Linux-环境变量和可执行属性 Linux - 管道、标准输入输出 Linux - 命令运行监测和软件安装 Linux-常见错误和快捷操作 Linux-文件列太多，很难识别想要的信息在哪列；别焦急，看这里。 Linux-文件排序和FASTA文件操作 Linux-应用Docker安装软件 Linux服务器数据定期同步和备份方式 VIM的强大文本处理方法 Linux - Conda软件安装方法 查看服务器配置信息 Linux - SED操作，awk的姊妹篇 Linux - 常用和不太常用的实用awk命令 Bash概论 - Linux系列教程补充篇 8.1.8 CIRCOS系列 CIRCOS圈图绘制 - circos安装 CIRCOS圈图绘制 - 最简单绘图和解释 CIRCOS圈图绘制 - 染色体信息展示和调整 CIRCOS增加热图、点图、线图和区块属性 8.1.9 R统计和作图 在R中赞扬下努力工作的你，奖励一份CheatShet 别人的电子书，你的电子书，都在bookdown R语言 - 入门环境Rstudio R语言 - 热图绘制 (heatmap) R语言 - 基础概念和矩阵操作 R语言 - 热图简化 R语言 - 热图美化 R语言 - 线图绘制 R语言 - 线图一步法 R语言 - 箱线图（小提琴图、抖动图、区域散点图） R语言 - 箱线图一步法 R语言 - 火山图 R语言 - 富集分析泡泡图 （文末有彩蛋） R语言 - 散点图绘制 一文看懂PCA主成分分析 富集分析DotPlot，可以服 R语言 - 韦恩图 R语言 - 柱状图 R语言 - 图形设置中英字体 R语言 - 非参数法生存分析 基因共表达聚类分析和可视化 R中1010个热图绘制方法 还在用PCA降维？快学学大牛最爱的t-SNE算法吧, 附Python/R代码 一个函数抓取代谢组学权威数据库HMDB的所有表格数据 文章用图的修改和排版 network3D: 交互式桑基图 network3D 交互式网络生成 8.1.10 扩增子三步曲 1图表解读-理解文章思路 2分析流程-把握分析细节 扩展1：视频教程-夯实分析思路 扩展2：QIIME2教程-了解分析趋势 3统计绘图-冲击高分文章 8.1.11 宏基因组分析专题 1背景知识-Shell入门与本地blast实战 2数据质控fastqc, Trimmomatic, MultiQC, khmer 3组装拼接MEGAHIT和评估quast 4基因注释Prokka 5基于Kmer比较数据集sourmash 6不比对快速估计基因丰度Salmon 7bwa序列比对, samtools查看, bedtools丰度统计 8分箱宏基因组binning, MaxBin, MetaBin, VizBin 9组装assembly和分箱bin结果可视化—Anvio 10绘制圈图-Circos安装与使用 MetaPhlAn2分析有参宏基因组 8.1.12 NGS基础 NGS基础 - FASTQ格式解释和质量评估 NGS基础 - 高通量测序原理 NGS基础 - 参考基因组和基因注释文件 NGS基础 - GTF/GFF文件格式解读和转换 本地安装UCSC基因组浏览器 测序数据可视化 (一) 测序文章数据上传找哪里 GO、GSEA富集分析一网打进 GSEA富集分析 - 界面操作 去东方，最好用的在线GO富集分析工具 生信软件系列 - NCBI使用 8.1.13 癌症数据库 UCSC XENA - 集大成者(TCGA, ICGC) ICGC数据库使用 TCGA数据库在线使用 8.1.14 Python Python学习 - 可视化变量赋值、循环、程序运行过程 Python极简教程 （一） Python教程（二） Python教程（三） Python教程 （四） Python教程（五） Python教程 （六） Pandas，让Python像R一样处理数据，但快 Python解析psiBlast输出的JSON文件结果 为啥我的Python这么慢 - 项查找 (二) 为啥我的Python这么慢 (一) Python资源 关于Python中的__main__和编程模板 8.1.15 NGS软件 Rfam 12.0+本地使用 （最新版教程） 轻松绘制各种Venn图 ETE构建、绘制进化树 psRobot：植物小RNA分析系统 生信软件系列 - NCBI使用 去东方，最好用的在线GO富集分析工具 8.1.16 Cytoscape网络图 Cytoscape教程1 Cytoscape之操作界面介绍 新出炉的Cytoscape视频教程 8.1.17 分子对接 来一场蛋白和小分子的风花雪月 不是原配也可以-对接非原生配体 简单可视化-送你一双发现美的眼睛 你需要知道的那些前奏 8.1.18 生信宝典之傻瓜式 生信宝典之傻瓜式 (一) 如何提取指定位置的基因组序列 生信宝典之傻瓜式 (二) 如何快速查找指定基因的调控网络 生信宝典之傻瓜式 (三) 我的基因在哪里发光 - 如何查找基因在发表研究中的表达 生信宝典之傻瓜式 (四) 蛋白蛋白互作网络在线搜索 生信宝典之傻瓜式 (五) 文献挖掘查找指定基因调控网络 8.1.19 生信人写程序 生信人写程序1. Perl语言模板及配置 生信人写程序2. Editplus添加Perl, Shell, R, markdown模板和语法高亮 8.1.20 小技巧系列 参考文献中杂志名字格式混乱问题一次解决 8.1.21 招聘 易汉博欢迎您加入 8.2 宏基因组 http://mp.weixin.qq.com/s/5jQspEvH5_4Xmart22gjMA 宏基因组/微生物组是当今世界科研最热门的研究领域之一，为加强本领域的技术交流与传播，推动中国微生物组计划发展，中科院青年科研人员创立“宏基因组”公众号，目标为打造本领域纯干货技术及思想交流平台。 本公众号每日推送，工作日分享宏基因组领域科研思路、实验和分析技术，理论过硬实战强；周末科普和生活专栏，轻松读文看片涨姿势。目前经过近半年发展，分享过百篇原创文章，已有14000+小伙伴在这里一起交流学习，感兴趣的赶快关注吧。 8.2.1 精选文章推荐 5000+ 微生物组入门必读+宏基因组实操课程 你想要的生信知识全在这—生信宝典 生物信息9天速成班—成为团队不可或缺的人 3分和30分文章差距在哪里？ 肠道菌群在人体中的作用 看完此片我想把身上的细菌寄生虫供起来 岛国科普—生命大跃进 我们的未来在哪里？ 论文图表基本规范 DNA提取发Nature 实验vs数据分析，谁对结果影响大? 3000+ 扩增子图表解读-理解文章思路 扩增子分析流程-把握分析细节 扩增子统计绘图-冲击高分文章 宏基因组分析教程 4500元的微生物组培训资料 Co-occurrence网络图在R中的实现 学术图表的基本配色方法 一文读懂进化树 自学生信-biostar handbook 漱口水增加糖尿病，高血压风险 1000+ 微生物组——扩增子分析专题培训开课啦！！！ 最简单漂亮的免费在线生信绘图工具 小学生都学Python了，你还不知道怎么开始 五彩进化树与热图更配-ggtree美颜进化树 扩增子分析还聚OTU就真OUT了 主流非聚类方法dada2,deblur和unoise3介绍与比较 16S预测微生物群落功能 0概述 1KO通路PICRUSt 2元素循环FAPROTAX 3表型bugbase 4KO通路Tax4Fun 一文读懂微生物组 2017年发展简史和十大热文盘点 8.2.2 培训、会议、征稿、招聘 3月10-19日，北京，微生物组——扩增子分析专题培训 5月11-13日，北京，中国肠道大会 8.2.3 科研经验 如何优雅的提问 公众号搜索方法大全 科研团队成长三部曲：1云笔记 2云协作 3公众号 文献阅读 1热心肠 2SemanticScholar 3geenmedical 生信编程模板 Perl Shell R 生物信息之程序学习 Endnote X8云同步：有网随时读文献 论文Figures，你不能不知道的秘密 转录组分析的正确姿势 整个世界都是你的已知条件 8.2.4 软件和数据库使用 SILVAngs:16S/18S在线分析1 2 METAGENassist帮你搞定宏基因分析的所有图形需求 Windows不用虚拟机或双系统，轻松实现linux shell环境：gitforwindows 一条命令轻松绘制CNS顶级配图-ggpubr ggbiplot-最好看的PCA图 LDA分析、作图及添加置信-ggord ggrepel-解决散点图样品标签重叠，方便筛选样品 Alpha多样性稀释曲线rarefraction curve 微生物组间差异分析神器-STAMP 扩增子分析神器USEARCH 微生物扩增子数据库大全 antiSMASH：微生物次生代谢物基因簇预测 微生物网络构建：MENA, LSA, SparCC和CoNet Cytoscape: MCODE增强包的网络模块化分析 FUNGuild：真菌功能注释 在线RaxML构建系统发育树 Genevestigator: 查找基因在发表研究中的表达 psRobot：植物小RNA分析系统 RepeatMasker：基因组重复序列注释 8.2.5 扩增子学习三步曲 8.2.5.1 1图表解读-理解文章思路 8.2.5.2 2分析流程-把握分析细节 扩展1：视频教程-夯实分析思路 扩展2：QIIME2教程-了解分析趋势 8.2.5.3 3统计绘图-冲击高分文章 8.2.6 宏基因组分析专题 1背景知识-Shell入门与本地blast实战 2数据质控fastqc, Trimmomatic, MultiQC, khmer 3组装拼接MEGAHIT和评估quast 4基因注释Prokka 5基于Kmer比较数据集sourmash 6不比对快速估计基因丰度Salmon 7bwa序列比对, samtools查看, bedtools丰度统计 8分箱宏基因组binning, MaxBin, MetaBin, VizBin 9组装assembly和分箱bin结果可视化—Anvi’o 10绘制圈图-Circos安装与使用 MetaPhlAn2分析有参宏基因组 8.2.7 R统计绘图 视频教程：R语言recharts包绘制交互式图形 R语言聚类分析–cluster, factoextra 堆叠柱状图各成分连线画法：突出展示组间物种丰度变化 R相关矩阵可视化包ggcorrplot 8.2.8 实验设计与技术 微生物样本取样及微生物基因组DNA提取建议 样品生物学重复数据选择 1必要性 2需要多少重复？ 样品命名 注意事项 扩增子引物选择 16S结构 16S单V4区是最佳选择? 海洋可培养微生物的鉴定与分类 怎么取粪便样品 Rhizosphere、Rhizoplane根际土如何取 Nat. Biotechnol.扩增子测序革命—用16S及18S rRNA全长进行微生物多样性研究 8.2.9 基础知识 Microbiota, metagenome, microbiome区别 16S测序，不知道OTU你就out了！ 计量宏基因组学数据分析的方法及进展 排序方法比较大全PCA、PCoA、NMDS、CCA LEfSe分析，你真的懂了么 宏基因组基础知识梳理 扩增子SCI套路1微群落结构差异 2组间差异分析 3系统总结 环境因子关联分析——我应该选择CCA还是RDA分析？ “P值”背后那些不可不知的事儿 Adonis和ANOSIM方法组间整体差异评估原理 轻松看懂机器学习十大常用算法 一文读懂“随机森林”在微生态中的应用 你想知道的“ROC曲线” 人体对微生物的管控 简单读懂微生物基因组的泛基因组学 8.2.10 必读综述 Nature：宏基因组关联分析 Nature：肠道菌群如何划分肠型 Nature: 来自细菌的通告——群感效应简介 Nature：呼吸道菌群—呼吸道健康的守门人 Nature: 拥抱未知-解析土壤微生物组的复杂性 Cell：代谢控制中的脑肠轴 研究微生物，只靠多组学根本不够 中国微生物组计划—农作物微生物组 Annu Rev：植物微生物组—系统见解与展望 Annual Reviews|微生物组与人 微生物组学与植物病害微生物防治 组学重建真菌现有分类系统 微生物应用|农业废弃物资源化利用 宏基因组学入门1初识 2进一步 3拼接 肠道微生物与人类密切相关的方方面面 Nature: 测序技术的前世今生 Nature Reviews：全新的益生元定义和范围 原核转录组非编码RNA研究 8.2.11 高分文章套路解读 Nature: 培养组学—高通量细菌分离培养鉴定 SR: 真菌培养组学同揭示人类肠道真菌群落结构 Nature: 地球微生物组计划首发成果—揭示地球多尺度微生物多样性 Nature：如何做一篇肠道菌群免疫的顶级文章 Nat Biotech: 宏表观组—DNA甲基化辅助宏基因组binning Nature: 甘露糖苷选择性抑制致病性大肠杆菌 Nature: 拟南芥根微生物组的结构和组成 Nature: 地球上最古老的热液喷口发现早期生命迹象 Nature Method: 宏基因组软件评估—人工重组宏基因组基准数据集 Nature Genetics：微生物基因组如何适应植物？(news &amp; views) NC：降低微生物群落复杂度突破组装难题 NC：自体免疫水泡皮肤病中鉴定基因与微生物组互作 GigaScience:植物MWAS研究—谷子产量与微生物组关联分析 Microbiome：微生物组研究中你必须注意的细节 Microbiome：HiSeq平台16S扩增子文库构建方法 Microbiome: 简单套路发高分文章–杨树微生物组 Microbiome：肠道菌群失衡促进高血压 Microbiome：重新定义“卫生”概念 ME：网络分析揭示微生物群落应对环境扰动的稳定性机制 SR: 土壤细菌定量方法结合相对丰度分析揭示种群的真实变化 8.2.12 科普视频-寓教于乐 BBC人体奥秘之细胞的暗战 BBC人体奥秘 Inside.the.Human.Body NG人体内旅行Inside.the.Living.Body NG子宫日记 Womb NHK: 再造人类生命的神奇细胞 CCTV9让尸体说话-法医密档 豆瓣8.9，惹哭亿万中国人的纪录片-本草中华 2分钟视频回顾植物学家钟扬的贡献 一顿“寄生虫大餐”，或能治好干净引来的免疫病 只要11天，浓度1000倍的抗生素也无效——超级细菌 致命病毒为何疯狂袭击人类？都怪我们那群会飞的远房亲戚 土豆上的小霉菌引发百万人死亡和逃难，却造就全球7千万后裔 看完这些能控制大脑的寄生虫，你会怀疑人类！ 梅毒狂想曲 8.2.13 友军文章汇总推荐 学习生信的系列教程——纯生信一作发IF&gt;20的大神 "]
]
