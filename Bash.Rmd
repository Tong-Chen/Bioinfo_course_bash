--- 
title: "Linux学习"
author: 
- "易生信"
- "www.ehbio.com/Training"
- "train@ehbio.com"
date: "`r Sys.Date()`"
documentclass: article
site: bookdown::bookdown_site
---

```{r setup, include=FALSE}
library(knitr)
output <- opts_knit$get("rmarkdown.pandoc.to")
html = FALSE
latex = FALSE
opts_chunk$set(echo = FALSE, out.width="100%", fig.align="center", fig.show="hold", warning=FALSE, message=FALSE)
if (output=="html") {
	html = TRUE
}
if (output=="latex") {
	opts_chunk$set(out.width="95%", out.height='0.7\\textheight', out.extra='keepaspectratio=true', fig.pos='H')
	latex = TRUE
}
html = TRUE
knitr::opts_chunk$set(cache=TRUE, autodep=TRUE)
mtime <- function(files){
  lapply(Sys.glob(files), function(x) file.info(x)$mtime)
}
set.seed(0304)
```

```{asis, echo=html}

# EHBIO Gene Technology {-}

```


```{r cover, eval=html, out.width="99%"}
knitr::include_graphics("ehbio/cover.png")

```


<!--chapter:end:index.Rmd-->

# Linux初探，打开新世界的大门 {#linux_basic}

![](http://www.ehbio.com/ehbio_resource/Linux_course.png)

视频课程地址：<https://ke.qq.com/course/288048?tuin=20cd7788>

## Linux系统简介和目录理解 {#basicDir}
 
### 为什么要用Linux系统 {#why_linux}

个人认为，Linux操作系统和类Linux操作系统的命令行界面是最适合进行生物信息分析的操作系统。原因有三点：

* 长期运行的稳定性
* 多数软件只有Linux版本
* 强大的Bash命令简化繁琐的操作，尤其是大大简化重复性工作

但对于初学者来说，接触和理解Linux操作系统需要一些时间和摸索。陡然从可视化点选操作的Windows进入到只有命令行界面的Linux，最大的陌生感是不知道做什么，不知道文件在哪？

我们这篇教程就带大家学习、熟悉、体会Linux系统的使用。

### Linux系统无处不在 {#linux_everywhere}

* Linux是一种多用户、多任务的操作系统。最开始是由Linus Torvalds与1991年发布，后由社区维护，产生了不同的分发版。

* 常见版本有`Centos`, `Ubuntu`, `RedHat`, `Debian`等。服务器多用`Centos`系统，免费，稳定，但更新慢。`Ubuntu`系统更新快，注重界面的体验，适合自己笔记本安装。有面向中国的"麒麟"系统。其它两个没用过，`Centos`与`RedHat`, `Debian`与`Ubuntu`同宗，命令行操作起来很相似。

### 免费的Linux系统来一套 {#free_linux}

* 如果自己的单位有共有服务器，可以尝试申请账号。
* 自己的电脑安装双系统或虚拟机。
* 使用[gitforwindows](http://blog.csdn.net/woodcorpse/article/details/79313846)在windows下模拟使用Linux命令。
* 购买一块云服务器
* 试验下在线学习平台实验楼 <https://www.shiyanlou.com> (里面也有不少Linux教程，任意点一个进去，双击桌面的`Xfce`图标，都可以启动Linux终端)
* [这里有2个免费Linux系统等你来用](https://mp.weixin.qq.com/s/rXjQfyEX2FnuW9HTM_Uc8Q)

### Linux系统登录-联系远方的她 {#linux_login}

登录服务器的IP是：192.168.1.107; 端口是：22；用户名是每个人的姓名全拼，如陈同为chentong (全小写，无空格)；密码是 yishengxin。

```{r, fig.cap="配置Xshell登录服务器1。"}
knitr::include_graphics(c("image/Linux_xshell1.png"))
```

```{r, fig.cap="配置Xshell登录服务器2。"}
knitr::include_graphics(c("image/Linux_xshell2.png"))
```

### 初识Linux系统 - 黑夜中的闪烁是你的落脚点 {#linux_cmd}

既然用Linux，我们就摒弃界面操作，体验其命令行的魅力和庞大。后续操作都是在命令行下进行的，主要靠键盘，少数靠鼠标。

登录Linux系统后，呈现在眼前的是这样一个界面:

```{bash eval=F}
Last login: Mon Jun  5 16:56:56 2017 from 239.241.208.209

Welcome to aliyun Elastic Compute Service!

ct@ehbio:~$ 

```

首先解释下出现的这几个字母和符号:

* `ct`: 用户名
* `ehbio`：如果是登录的远程服务器，则为宿主机的名字；若是本地电脑，则为自己电脑的名字。
* `~`: 代表家目录, 在我们进入新的目录后，这个地方会跟着改变
* `$`: 用来指示普通用户输入命令的地方；对根用户来说一般是`#`
* <http://bashrcgenerator.com/>可视化定制不同的显示方式。
* 个人习惯的展示：`PS1=\[\e]0;\u@\h: \w\a\]${debian_chroot:+($debian_chroot)}\u@\h:\w\$`
* 闪烁的光标处是你敲打键盘体验威力的地方 - 输入命令并按回车。

### 我的电脑在哪？ {#my_computer}

打开Windows，首先看到的是桌面；不爱整理文件的我，桌面的东西已经多到需要2个屏幕才能显示的完。另外一个常用的就是我的电脑，然后打开D盘，依次点开对应的文件夹，然后点开文件。

Linux的文件系统组织方式与Windows略有不同，登录进去就是家目录，可视为Windows下的桌面[^Linux的家目录严格来说可能类似于Windows下的`C:\\Users\\ct`]。在这个目录下，我们可以新建文件、新建文件夹，就像在桌面上的操作一样。

而Linux的完整目录结构如下：


```{r, fig.cap="Linux目录层级结构。"}
knitr::include_graphics("image/Linux_dir.png")
```

```{bash eval=F}
# 若提示命令找不到，运行下面语句安装tree
# 需要有根用户权限
# yum install tree.x86_64
ct@ehbio:~$ tree -d -L 2 /

```

```{r}
directory = "Path;Description
/;根目录
/bin;常用软件如ls, mkdir, top等的存放地
/dev;硬件相关
/etc;存放系统管理和配置相关文件
/etc/cron*;与定时任务相关的文件夹，可执行程序放置到对应文件夹就可以定时执行
/etc/profile.d;目录下存放Bash相关的配置文件，相当于全局的.bashrc
/etc/profile.d/custom.sh;我在配置全局环境时，一般写入这个文件；如果不存在，可以新建。
/home;家目录，默认新建用户的个人家目录都在此文件夹下
/home/ct;用户名为ct的用户的家目录
/lib -> usr/lib;存放动态库的目录 (library)，安装软件时碰到依赖的动态库一般存储于此
/lib64 -> usr/lib64;64位软件动态库，-> 表示软连接，等同于快捷方式
/mnt;文件系统挂载，一般插入U盘会显示在这。
/opt;部分额外安装的软件会置于此
/root;根用户的家目录
/sbin -> usr/sbin;根用户的管理命令
/tmp;临时目录，会定时清空，常用于存放中间文件
/usr;存放系统应用的目录，前面有几个目录都是该目录下子目录的软链
/usr/bin;大部分应用程序安装于此
/usr/sbin;根用户的管理命令
/usr/lib;存放动态库的目录 (library)，安装软件时碰到依赖的动态库一般存储于此
/usr/lib64;64位软件动态库
/usr/local/bin;存放本地安装的命令
/usr/local/lib;存放本地安装的库
/var;存放各服务的日志文件。若装有网络服务，一般在/var/www/html下。
"

directory = read.table(text=directory, header=T,row.names=NULL,sep=";")

knitr::kable(directory, booktabs=T,caption="Linux下目录简介")
```

作为一个普通用户，通常只在`/home/usr`, `/tmp`下有**可写**的权限，其它目录最多是**可读、可执行**，部分目录连读的权限都没有。这种权限管理方式是Linux能成为真正多用户系统的一个原因。后面我们会讲解如何查看并修改这些权限。

### 系统配置怎样？来看看256M硬盘的服务器 {#linux_system_hardware}

看完目录结构了，来看一下硬盘有多大，有多少可用空间，只需要运行`df -h`命令。

```{bash eval=F}
ct@ehbio:~$ df -h
Filesystem            Size  Used Avail Use% Mounted on
/dev/sda2             193G   61G  122G  34% /
tmpfs                 127G  344K  127G   1% /dev/shm
/dev/sda1             190M   77M  103M  43% /boot
/dev/mapper/a          37T   12T   25T  32% /ehbio1
/dev/mapper/b          37T   28T  8.8T  76% /ehbio2
/dev/mapper/c          37T   15T   23T  40% /ehbio3
```

除了看硬盘，还想看下CPU、内存、操作系统呢？

```{bash eval=F}
# serverInfo.sh是我写的一个脚本，这个脚本怎么实现的会是一个考核题目。
ct@ehbio:~$ serverInfo.sh
```

```
Hostname is localhost.localdomain,Ip address is 192.168.1.30.

The 64 bit operating system is  CentOS release 6.9 (Final), 
	
Nuclear info is 2.6.32-696.10.1.el6.x86_64.

The CPU is Intel(R) Xeon(R) CPU E9-5799 v2 @ 3.90GHz.

There are 8 physical cpu, each physical cpu has 0 cores, 0 threads.

There are 96 logical cpu.

The memory of this server is 252G.
```

### 看下目录下都有什么 {#directpry_show}

通常登陆后直接进入家目录，下面大部分操作也是在家目录下完成的。如果想查看当前目录下都有什么内容，输入命令 `ls`，回车即可 (ls可以理解为单词list的缩写)。当前目录下什么也没有，所以没有任何输出。

```{bash eval=F}
ct@ehbio:~$ ls

```

如果错把`l`看成了`i`，输入了`is`，则会出现下面的提示`未找到命令`。如果输入的是Linux基本命令，出现这个提示，基本可以判定是命令输入错了，瞪大眼睛仔细看就是了。 **在敲完命令回车后，注意查看终端的输出，以判断是否有问题。**

```{bash eval=F}
ct@ehbio:~$ is
-bash: is: 未找到命令
# 大小写敏感
ct@ehbio:~$ lS
-bash: lS: 未找到命令
```

当前目录下只有一个文件，看不出效果，我们可以新建几个文件和文件夹。

### 新建一个目录 {#mkdir}

`mkdir`是新建一个目录 (`m`a`k`e a `dir`ectory)；`data`是目录的名字。
如果目录存在，则会出现提示，"无法创建已存在的目录"。这时可以使用参数`-p`忽略这个错误。

```{bash eval=F}
ct@ehbio:~$ mkdir data
ct@ehbio:~$ ls
data
ct@ehbio:~$ mkdir data
mkdir: 无法创建目录"data" : 文件已存在

# -p: no error if existing, make parent directories as needed
ct@ehbio:~$ mkdir -p data
```

`cat`是一个命令，主要用来查看文件；在这与`<<END`连用用于读入大段数据。输入`cat <<END`之后，回车，会看到终端出现一个大于号，大于号后面可以输入内容，再回车，继续输入内容，直到我们输入`END` (大写的，与上面一致)，输入过程结束，我们输入的内容都显示在了屏幕上。

```{bash eval=F}
ct@ehbio:~$ mkdir data
ct@ehbio:~$ cat <<END
a
bc
END
a
bc
```

如果我们想把这些内容写入文件，就需要使用 `command > filename`格式。

`>`是一个重定向符号，即把前面命令的输出写入到`>`后面的文件中。如下所示，新建了一个`Fasta`格式的文件。

`ls -l`列出文件的详细信息；`-l`表示命令行参数，是程序预留的一些选项，保证在不更改程序的情况下获得更灵活的操作。可使用`man ls`查看`ls`所有的命令行参数, **上下箭头翻页**，按`q`退出查看。(man: manual, 手册)

```{bash eval=F}
ct@ehbio:~$ cat <<END >data/test.fa
>SOX2
ACGTCGGCGGAGGGTGGSCGGGGGGGGAGAGGT
ACGATGAGGAGTAGGAGAGAGGAGG
>OCT4
ACGTAGGATGGAGGAGAGGGAGGGGGGAGGAGAGGAA
AGAGTAGAGAGA
>NANOG
ACGATGCGATGCAGCGTTTTTTTTTGGTTGGATCT
CAGGTAGGAGCGAGGAGGCAGCGGCGGATGCAGGCA
ACGGTAGCGAGTC
>mYC HAHA
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
END

## 注意命令和参数之间的空格
ct@ehbio:~/data$ ls-l
-bash: ls-l: 未找到命令

ct@ehbio:~$ ls -l
总用量 4
## d: dir; 表示data是个目录
## rwx：表示目录的权限，暂时忽略，或自己在线搜索
drwxrwxr-x 2 ct ct 4096 6月   8 14:52 data

ct@ehbio:~$ ls -l data
总用量 4
## 开头的`-`表示test.fa是个文件
-rw-rw-r-- 1 ct ct 284 6月   8 14:48 test.fa
```

### 访问文件 {#cat_file}

查看写入的文件的内容，`cat 文件名`；需要注意的是文件所在的目录，默认是当前目录；如下面第一个命令，会提示`cat: test.fa: 没有那个文件或目录`，是因为当前目录下不存在文件`test.fa`。(注意文件末尾的end)


```{bash eval=F}
# 这个应该是最常见的错误之一，程序不可能知道你的输入文件在什么地方，
# 需要人为指定。
# 如果未指定路径，表示当前目录
ct@ehbio:~$ cat test.fa
cat: test.fa: 没有那个文件或目录

ct@ehbio:~$ cat data/test.fa 
>SOX2
ACGTCGGCGGAGGGTGGSCGGGGGGGGAGAGGT
ACGATGAGGAGTAGGAGAGAGGAGG
>OCT4
ACGTAGGATGGAGGAGAGGGAGGGGGGAGGAGAGGAA
AGAGTAGAGAGA
>NANOG
ACGATGCGATGCAGCGTTTTTTTTTGGTTGGATCT
CAGGTAGGAGCGAGGAGGCAGCGGCGGATGCAGGCA
ACGGTAGCGAGTC
>mYC HAHA
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
```

`test.fa`在目录`data`下，可以先进入`data`目录，然后再查看文件。类比于Windows下先点开一个文件夹，再点开下面的文件。

这个例子中文件`test.fa`在当前目录的子目录`data`里面，在当前目录下直接查看`test.fa`就像在`我的电脑`里面不进入C盘，就像打开`Program file`文件夹。这属于**隔空打牛**的境界，不是一般人能练就的。起码Linux下不可以。

提到目录，Linux下有**绝对路径**和**相对路径**的概念。

* 绝对路径：以`/`开头的路径为绝对路径，如`/home/ct`, `/usr/bin`, `/home/ct/data`等。需要注意的是`~/data`等同于`/home/ct/data`, 多数情况下可以等同于绝对路径，但在一个情况下例外，软件安装时用于`--prefix`后的路径必须是`/`开头的绝对路径。

* 相对路径: 不以`/`和`~`开头的路径都是相对路径，如`data`表示当前目录下的data目录，等同于`./data` (`.`为当前目录), `../data`表示当前目录的上一层目录下的data目录 (`../`表示上层目录)。


`pwd` (print working directory) 获取当前工作目录。

`cd` (change dir)切换目录。若`cd`后没有指定切换到那个目录，则调回家目录。特别地，`cd -`表示返回到最近的`cd`操作前所在目录，相当于回撤到上一个工作目录。

`head`查看文件最开始的几行，默认为10行，可使用`-n 6`指定查看前6行。

```{bash eval=F}
# 记住输出
ct@ehbio:~$ pwd
/home/ct

ct@ehbio:~$ cd data

# 注意输出变化
ct@ehbio:~$ pwd
/home/ct/data
ct@ehbio:~/data$ head -n 6 test.fa 
>SOX2
ACGTCGGCGGAGGGTGGSCGGGGGGGGAGAGGT
ACGATGAGGAGTAGGAGAGAGGAGG
>OCT4
ACGTAGGATGGAGGAGAGGGAGGGGGGAGGAGAGGAA
AGAGTAGAGAGA
```

另外`less`和`more`也可以用来查看文件，尤其是文件内容特别多的时候。

```{bash eval=F}
ct@ehbio:~/data$ less test.fa 
# q: 退出
# 上下箭头、空格翻页
```

### 查看帮助，获取可用命令行参数 {#com_parameter_help}

前面使用的命令，有几个用到了参数如`ls -l`, `head -n 6`等，需要注意的是命令跟参数之间要有**空格**。

终端运行`man ls`可以查看`ls`所有可用的参数，上下箭头翻页，按`q`退出查看。(man: manual, 手册)

```{bash eval=F}
ct@ehbio:~/data$ man ls
NAME
 ls - list directory contents

SYNOPSIS
 ls [OPTION]... [FILE]...

DESCRIPTION
 List  information  about  the  FILEs  (the current directory by default).
 Sort entries alphabetically if none of -cftuvSUX nor --sort is specified.

 Mandatory arguments to long options are mandatory for short options too.

 -a, --all
  do not ignore entries starting with .

 -A, --almost-all
  do not list implied . and ..

 --author
  with -l, print the author of each file

 -b, --escape
  print C-style escapes for nongraphic characters
 ....
	
```

### 小结 {#first_summary}

1. Linux是多用户操作系统。这一点可以从我们每个人能同时登录到同一台Linux电脑各自进行操作而不相互干扰可以体会出来。大家可以尝试下是否可以看到其它人家目录下的东西。我们后期在**权限管理**部分会涉及如何开放或限制自己的文件被他人访问。

2. Linux下所有目录都在**根目录**下。根目录某种程度上可类比于Windows的我的电脑，第一级子目录类比于`C盘`，`D盘`等 (等我们熟练了，就忘记这个拙劣的类比吧)。

3. 使用`mkdir`新建目录，`cd`切换目录，`pwd`获取当前工作目录，`ls`查看目录下的内容, `cat`查看文件，`man ls`查看ls命令的使用。

4. 访问一个文件需要指定这个文件的路径，当前目录下的文件可省略其路径`./`，其它目录下则需要指定全路径 (可以是相对路径，也可以是绝对路径)。

### 做个小测试 {#first_exercise}

1. 在家目录下新建文件夹`bin`和`soft`。
2. 在`bin`和`soft`目录下各自新建一个文件，名字都是`README`。
3. 在`bin/README`文件中写入内容：This folder is used to save executable files。
4. 在`soft/README`文件中写入内容：This folder is used to save software source files。
5. 查看两个`README`文件的大小。

## Linux下文件操作 {#fileoperation}

### 文件按行翻转和按列翻转 {#tac_rev}

两个有意思的命令，`tac`: 文件翻转，第一行变为最后一行，第二行变为倒数第二行；`rev`每列反转，第一个字符变为最后一个字符，第二个字符变为倒数第二个字符。

```{bash eval=F}
ct@ehbio:~/data$ cat <<END | tac
> first
> second
> third
> END
third
second
first

ct@ehbio:~/data$ cat <<END | rev
> abcde
> xyz
> END
edcba
zyx
```

### 新建文件的n种方式 {#new_file}

`nano`类似于Windows下记事本的功能，`nano filename`就可以新建一个文件，并在里面写内容；`ctrl+x`退出，根据提示按`Y`保存。

`vim` 功能更强大的文本编辑器。`vim filename`就可以新建一个文件, 敲击键盘字母`i`，进入写作模式。写完后，敲击键盘`Esc`, 退出写作模式，然后输入`:w` (会显示在屏幕左下角)，回车保存。`vim`的常用方法，后面会有单独介绍。


### 文件拷贝、移动、重命名、软链 {#file_cp_mv_rename_link}

常用的文件操作有移动文件到另一个文件夹、复制文件到另一个文件夹、文件重命名等。

`cp` (copy): 拷贝文件或文件夹 (`cp -r` 拷贝文件夹时的参数，递归拷贝).

`cp source1 source2 ... target_dir` 将一个或多个源文件或者目录复制到已经存在的目标目录。

`cp`常用参数

> -r: 递归拷贝

> -f: 强制覆盖

> -i: 覆盖前先询问

> -p: 保留文件或目录的属性，主要是时间戳

> -b: 备份复制，若目标文件存在，先备份之前的，再把新的覆盖过去

> -u: 更新复制，若源文件和目标文件都存在，只在源文件的修改时间比较新时才复制


```{bash eval=F}
# 列出当前目录下有的文件和文件夹
ct@ehbio:~$ ls
data

# 新建一个文件夹
ct@ehbio:~$ mkdir ehbio_project

# 列出当前目录下有的文件和文件夹, 及其子文件夹的内容
# data目录下有一个文件，ehbio_project目录下无文件
ct@ehbio:~$ ls *
data:
test.fa

ehbio_project:

# 拷贝data目录下的文件test.fa到ehbio_project目录下
ct@ehbio:~$ cp data/test.fa ehbio_project/

# 列出当前目录下有的文件和文件夹, 及其子文件夹的内容
# data目录下有一个文件，ehbio_project目录下无文件
ct@ehbio:~$ ls *
data:
test.fa

ehbio_project:
test.fa
```

`mv` (move): 移动文件或文件夹

`mv source target`, 常用参数有

> -f: 强制覆盖

> -i: 覆盖前询问

> -u: 更新移动

```{bash eval=F}
# 重命名data目录下的文件test.fa为first.fa
# mv除了可以移动文件，也可以做单个文件的重命名
ct@ehbio:~$ mv data/test.fa data/first.fa

# 列出当前目录下有的文件和文件夹,  及其子文件夹的内容
ct@ehbio:~$ ls *
data:
first.fa

ehbio_project:
test.fa
```

`rename`: 文件重命名 (常用于批量重命名，不同的系统可能用法略有不同，使用前先`man rename`查看使用方法)

```{bash eval=F}
# 进入另一个目录
ct@ehbio:~$ cd ehbio_project/
ct@ehbio:~/ehbio_project$ ls
test.fa

# 给文件做一份拷贝
ct@ehbio:~/ehbio_project$ cp test.fa second.fa
ct@ehbio:~/ehbio_project$ ls
second.fa  test.fa

# 给文件多拷贝几次，无聊的操作，就是为了给rename提供发挥作用的机会
ct@ehbio:~/ehbio_project$ cp test.fa test2.fa
ct@ehbio:~/ehbio_project$ cp test.fa test3.fa
ct@ehbio:~/ehbio_project$ cp test.fa test4.fa

# cp 后面需要2个参数，被拷贝的文件和要被拷贝到的目录或文件
# 出现下面的错误，表示缺少目标路径或文件
ct@ehbio:~/ehbio_project$ cp ehbio.fa 
cp: 在" ehbio.fa"  后缺少了要操作的目标文件
Try 'cp --help' for more information.

ct@ehbio:~/ehbio_project$ ls
second.fa  test2.fa  test3.fa  test4.fa  test.fa

# 用rename进行文件批量重命名
ct@ehbio:~/ehbio_project$ rename 'test' 'ehbio' test*.fa
ct@ehbio:~/ehbio_project$ ls
ehbio2.fa  ehbio3.fa  ehbio4.fa  ehbio.fa  second.fa
```

`ln` (link): 给文件建立快捷方式 (`ln -s source_file target` 创建软连接)。

在建立软连接时，原文件要使用全路径。全路径指以`/`开头的路径。如果希望软链可以让不同的用户访问，不要使用`~`。

建立软连接，是为了在不增加硬盘存储的情况下，简化文件访问方式的一个办法。把其它文件夹下的文件链接到当前目录，使用时只需要写文件的名字就可以了，不需要再写长串的目录了。  

`ln`命令常用参数

> -s: 软连接

> -f: 强制创建

`../`: 表示上一层目录；`../../`: 表示上面两层目录

`pwd` (print current/working directory): 输出当前所在的目录 


`\``为键盘`Esc`下第一个按键 (与家目录`~`符号同一个键)，写在反引号内的命令会被运行，运行结果会放置在反引号所在的位置


```{bash eval=F}
# 建立软连接，把当前目录下的ehbio2.fa，链接到上一层目录的data下面

# 这是一个无效的软连接，
ct@ehbio:~/ehbio_project$ ln -s ehbio2.fa ../data

# 在使用ls查看时，无效的软连接的文件名下面是黑色的背景。
# 不同的终端配色方案会有不同，一般一直闪烁表示是失效的链接，
# 另外是否失效以能否使用为最终判断标准。
ct@ehbio:~/ehbio_project$ ls -l ../data/
总用量 4
lrwxrwxrwx 1 ct ct   9 6月   9 17:55 ehbio2.fa -> ehbio2.fa
-rw-rw-r-- 1 ct ct 284 6月   8 14:48 first.fa

ct@ehbio:~/ehbio_project$ less ../data/ehbio2.fa
xxxxx 符号连接的层数过多

# 输出当前所在的目录
ct@ehbio:~/ehbio_project$ pwd
/home/ct/ehbio_project

# 建立软连接时，原始文件一定使用全路径。全路径指以/开头的路径。
ct@ehbio:~/ehbio_project$ ln -s /home/ct/ehbio_project/ehbio2.fa ../data
ln: 无法创建符号链接" ../data/ehbio2.fa" : 文件已存在

# 上面的错误信息时，已经存在这么一个链接了（虽然是无效的），但再建新的链接时还会提示
# 使用`-f` (force)强制覆盖已有的链接
ct@ehbio:~/ehbio_project$ ln -fs /home/ct/ehbio_project/ehbio2.fa ../data

# 再次查看时，就正常了。文件名下面没有了恐怖的背景色，并且有个右箭头指向原始文件
# `lrwxrwxrwx`中的`l`表示软连接。
ct@ehbio:~/ehbio_project$ ls -l ../data/
总用量 4
lrwxrwxrwx 1 ct ct  32 6月   9 17:56 ehbio2.fa -> /home/ct/ehbio_project/ehbio2.fa
-rw-rw-r-- 1 ct ct 284 6月   8 14:48 first.fa

# 通常为了简化写法，使用`pwd`代替全路径
# `为键盘Esc下面的按键，写在反引号内的命令会被运行，运行结果会放置在反引号所在的位置
ct@ehbio:~/ehbio_project$ ln -s `pwd`/ehbio2.fa ../data
ln: 无法创建符号链接" ../data/ehbio2.fa" : 文件已存在
ct@ehbio:~/ehbio_project$ ln -fs `pwd`/ehbio2.fa ../data
ct@ehbio:~/ehbio_project$ ls -l ../data/
总用量 4
lrwxrwxrwx 1 ct ct  32 6月   9 17:56 ehbio2.fa -> /home/ct/ehbio_project/ehbio2.fa
-rw-rw-r-- 1 ct ct 284 6月   8 14:48 first.fa
```


使用全路径名，尤其使用家目录 `~` 符号时，只限操作用户自身有效。另外不同用户之间建立软连接，需要考虑**访问权限**问题，任意一层目录都需要可读权限 (目录的可读为`rx`都有)。

复制、移动或创建软连接时，如果目标已存在，除了使用`-f`强制覆盖外，还可以使用`rm`命令删除。

`rm`可以删除一个或多个文件和目录，也可以递归删除所有子目录，使用时一定要慎重。`rm`命令删除的文件很难恢复。

`rm -rf *`: 可以删除当前目录下所有文件和文件夹，慎用。

`rm`命令常见参数：

> -f：强制删除

> -i: 删除前询问是否删除

> -r: 递归删除

```{bash eval=F}
ct@ehbio:~/ehbio_project$ ln -s `pwd`/ehbio2.fa ../data
ln: 无法创建符号链接" ../data/ehbio2.fa" : 文件已存在

# 删除之前的软连接，源文件不会被删除
ct@ehbio:~/ehbio_project$ rm -f ../data/ehbio2.fa

# 再次新建软连接
ct@ehbio:~/ehbio_project$ ln -s `pwd`/ehbio2.fa ../data
ct@ehbio:~/ehbio_project$ ls -l ../data/
总用量 4
lrwxrwxrwx 1 ct ct  32 6月   9 17:56 ehbio2.fa -> /home/ct/ehbio_project/ehbio2.fa
-rw-rw-r-- 1 ct ct 284 6月   8 14:48 first.fa

# 
ct@ehbio:~/ehbio_project$ mkdir tmp

# touch filename: 如果文件不存在，则新建一个文件
#                 若存在，则更新其修改和访问时间
#                 在后面的搜索讲解中会有touch的一个妙用
ct@ehbio:~/ehbio_project$ touch tmp/a
ct@ehbio:~/ehbio_project$ touch tmp/b

# -r: 递归删除，主要用于删除目录和子目录时
# -f: 强制删除
ct@ehbio:~/ehbio_project$ rm -rf tmp
```

### Linux下命令的一些突发事故 {#linux_abnormal}

**命令不全**：在命令没有输入完 (引号或括号没有配对)，就不小心按下了`Enter`键，终端会提示出一个`>`代表命令不完整，这是可以继续输入，也可以`ctrl+c`终止输入，重新再来。(下面sed命令使用时，还有另外一种命令不全的问题)

```{bash eval=F}
ct@ehbio:~/ehbio_project$ rename 'ehbio2
>'
ct@ehbio:~/ehbio_project$ rename 'ehbio2
> ^C
ct@ehbio:~/ehbio_project$
```

**文件名输入错误**: 多一个字母、少一个字母、大小写问题

```{bash eval=F}
ct@ehbio:~/ehbio_project$ls
ehbio2.fa  ehbio3.fa  ehbio4.fa  ehbio.fa  second.fa

# 重命名没有生效
ct@ehbio:~/ehbio_project$ rename 'ehbio2' 'ehbio5' ebio2.fa
ct@ehbio:~/ehbio_project$ ls
ehbio2.fa  ehbio3.fa  ehbio4.fa  ehbio.fa  second.fa

# 仔细看是ehbio2.fa写成了ebio2.fa，更正后即可。
Z8vb3e9jtel4m99ss6e7eZ:~/ehbio_project$ rename 'ehbio2' 'ehbio5' ehbio2.fa
ct@ehbio:~/ehbio_project$ ls
ehbio3.fa  ehbio4.fa  ehbio5.fa  ehbio.fa  second.fa
```


**所在目录不对**: 访问的文件不存在于当前目录，而又没有提供绝对路径, 或软连接失效

```{bash eval=F}
ct@ehbio:~/ehbio_project$ ls
ehbio3.fa  ehbio4.fa  ehbio5.fa  ehbio6.fa  ehbio.fa  second.fa
ct@ehbio:~/ehbio_project$ ls ../data
ehbio2.fa  first.fa

# 当前目录没有ehbio2.fa
ct@ehbio:~/ehbio_project$ less ehbio2.fa
ehbio2.fa: 没有那个文件或目录

# ehbio2.fa在上一层目录的data目录下
ct@ehbio:~/ehbio_project$ ls ../data/ehbio2.fa 
../data/ehbio2.fa

# 加上路径依然访问不了 
ct@ehbio:~/ehbio_project$ less ../data/ehbio2.fa 
../data/ehbio2.fa: 没有那个文件或目录

# 上面的问题是软连接失效，在之前的操作中删掉了原始的ehbio2.fa，所以快捷方式失效

# 正确的访问
ct@ehbio:~/ehbio_project$ tail -n 3 ../data/first.fa 
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
```

### 了解和操作你的文件 {#file_op_gzip_wc}

常用的文件内容操作有文件压缩解压缩、文件大小行数统计、文件内容查询等。

`gzip`: 压缩文件; `gunzip`: 解压缩文件

```{bash eval=F}
# gzip -c 把压缩的文件输出到标准输出 (一般是屏幕)
# '>' 输出重定向，输出写入文件

ct@ehbio:~/ehbio_project$ gzip -c ehbio.fa >ehbio.fa.gz

# 多了一个.gz文件
ct@ehbio:~/ehbio_project$ ls
ehbio3.fa  ehbio4.fa  ehbio5.fa  ehbio.fa  ehbio.fa.gz  second.fa

# 解压缩
ct@ehbio:~/ehbio_project$ gunzip ehbio.fa.gz
gzip: ehbio.fa already exists; do you wish to overwrite (y or n)? y

ct@ehbio:~/ehbio_project$ ls
ehbio3.fa  ehbio4.fa  ehbio5.fa  ehbio.fa  second.fa
```

`wc` (word count): 一般使用`wc -l`获取文件的行数。

```{bash eval=F}
# 输出文件有14行
ct@ehbio:~/ehbio_project$ wc -l ehbio.fa
14 ehbio.fa
```

获取文件中包含大于号 (`>`)的行, `grep` (print lines matching a pattern，对每一行进行模式匹配)。

`grep`的用法很多，支持正则表达式匹配，这个后面我们会详细讲解。

```{bash eval=F}
ct@ehbio:~/ehbio_project$ grep '>' ehbio.fa
>SOX2
>OCT4
>NANOG
>mYC HAHA

# 获取包含>的行的行数 (-c: count lines)
ct@ehbio:~/ehbio_project$ grep -c '>' ehbio.fa
4

# 是不是还记得当时新建文件时，末尾多了一行end，删除end所在行
ct@ehbio:~/ehbio_project$ less ehbio.fa 

# -v: 不输出匹配上的行
ct@ehbio:~/ehbio_project$ grep -v 'end' ehbio.fa >ehbio6.fa
ct@ehbio:~/ehbio_project$ cat ehbio6.fa 
>SOX2
ACGTCGGCGGAGGGTGGSCGGGGGGGGAGAGGT
ACGATGAGGAGTAGGAGAGAGGAGG
>OCT4
ACGTAGGATGGAGGAGAGGGAGGGGGGAGGAGAGGAA
AGAGTAGAGAGA
>NANOG
ACGATGCGATGCAGCGTTTTTTTTTGGTTGGATCT
CAGGTAGGAGCGAGGAGGCAGCGGCGGATGCAGGCA
ACGGTAGCGAGTC
>mYC HAHA
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
```

替换文件中的字符: `sed`是一个功能强大的文件内容编辑工具，常用于替换、取得行号等操作。现在先有个认识，后面会详细介绍。


`|` 为管道符，在相邻命令之间传递数据流，表示把上一个命令的输出作为下一个命令的输入。

```{bash eval=F}
# 第一个错误，漏掉了文件名
# 程序静止在这，等待用户的进一步输入
# ctrl+c杀掉当前命令
ct@ehbio:~/ehbio_project$ sed 's/ HAHA//' | tail -n 3

^C

# 第二个错误，文件名和单引号之间没有空格，使得sed判断命令错误

ct@ehbio:~/ehbio_project$ sed 's/ HAHA//'ehbio.fa  | tail -n 3
sed：-e 表达式 #1，字符 11：“s”的未知选项

# 正确操作，

ct@ehbio:~/ehbio_project$ sed 's/ HAHA//' ehbio.fa  | tail -n 4
>mYC
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
```

另外一个方式，去除`HAHA`，使用`cut`命令。cut更适合于矩阵操作，去除其中的一列或者多列。但在处理FASTA格式文件时有这么一个妙用。FASTA文件中序列里面是没有任何符号的，而如果名字比较长，则可以指定相应分隔符就行`cut`，这样既处理了名字，又保留了序列。

`-f`: 指定取出哪一列，使用方法为`-f 2` (取出第2列)，`-f 2-5` (取出第2-5列)，`-f 2,5` (取出第2和第5列)。**注意不同符号之间的区别。**

`-d`: 设定分隔符, 默认为TAB键。如果某一行没有指定的分隔符，整行都为第一列。

```{bash eval=F}
ct@ehbio:~/ehbio_project$ cut -f 1 -d ' ' ehbio.fa | tail -n 4
>mYC
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
```

### 小结和练习 {#second_exercise}

1. Linux下文件拷贝、移动、重命名、软连接、压缩、替换等操作。
2. Linux下常见问题
   * `ehbio2.fa: 没有那个文件或目录`：这个错误通常由什么引起，应该怎么解决？
   * 若文件`a`存在，运行`ln a data/b`能否成功给`a`建立软连接？
   * `grep '> ehbio.fa`的输出是什么？
3. 若目标文件存在时，再运行`cp`, `mv`或`ln`会有什么提示？
4. 计算某一个Fasta序列中序列的个数。
   
## Linux终端常用快捷操作 {#shortcut}

* 命令或文件名自动补全：在输入命令或文件名的前几个字母后，按`Tab`键，系统会自动补全或提示补全
* 上下箭头：使用上下箭头可以回溯之前的命令，增加命令的重用，减少输入工作量
* `!`加之前输入过的命令的前几个字母，快速获取前面的命令

```{bash eval=F}
ct@ehbio:~/ehbio_project$ cut -f 1 -d ' ' ehbio.fa | tail -n 4
>mYC
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
ct@ehbio:~/ehbio_project$ man cut
# 直接跳到上面运行的cut命令，再执行一次
ct@ehbio:~/ehbio_project$ !cut
cut -f 1 -d ' ' ehbio.fa | tail -n 4
>mYC
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
```

* `ctrl+a`回到命令的行首，`ctrl+e`到命令行尾，(`home`和`end`也有类似功能)，用于修改命令或注释掉命令

```{bash eval=F}
# 写完下面的命令，突然不想运行了，又不想一个个删掉
ct@ehbio:~/ehbio_project$ cut -f 1 -d ' ' ehbio.fa | tail -n 4

# 按ctrl+a, 回到行首，再输入`#`号，回车，命令即被注释掉。
ct@ehbio:~/ehbio_project$ #cut -f 1 -d ' ' ehbio.fa | tail -n 4
```

* `!!` 表示上一条命令。

```{bash eval=F}
ct@ehbio:~/ehbio_project$ ls
ehbio3.fa  ehbio4.fa  ehbio5.fa  ehbio6.fa  ehbio.fa  second.fa
ct@ehbio:~/ehbio_project$ !!
ls
ehbio3.fa  ehbio4.fa  ehbio5.fa  ehbio6.fa  ehbio.fa  second.fa
```

* 替换上一个命令中的字符，再运行一遍命令，用于需要对多个文件执行同样的命令，又不想写循环的情况

```{bash eval=F}
# 输入一个命令
ct@ehbio:~/ehbio_project$ #cut -f 1 -d ' ' ehbio.fa | tail -n 4

# !!表示上一条命令
# :gs表示替换，把上一个命令中全部的ehbio替换为ehbio3; g: global; s: substitute
ct@ehbio:~/ehbio_project$ !!:gs/ehbio/ehbio3
#cut -f 1 -d ' ' ehbio3.fa | tail -n 4

# 替换后效果如上

# 去掉命令前的#号
ct@ehbio:~/ehbio_project$ cut -f 1 -d ' ' ehbio3.fa | tail -n 4
>mYC
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end

## 替换ehbio3为ehbio4，直接运行命令
ct@ehbio:~/ehbio_project$ !!:gs/ehbio3/ehbio4
cut -f 1 -d ' ' ehbio4.fa | tail -n 4
>mYC
ACGGAGCGAGCTAGTGCAGCGAGGAGCTGAGTCGAGC
CAGGACAGGAGCTA
end
```


## Linux下的标准输入、输出、重定向、管道 {#stdinoutpipe}

在Linux系统中，有4个特殊的符号，`<`, `>`, `|`, `-`，在我们处理输入和输出时存在重要但具有迷惑性的作用。

默认Linux的命令的结果都是输出到标准输出，错误信息 (比如命令未找到或文件格式识别错误等) 输出到标准错误，而标准输出和标准错误默认都会显示到屏幕上。

`>`表示重定向标准输出，`> filename`就是把标准输出存储到文件filename里面。标准错误还是会显示在屏幕上。

`2 >&1` 表示把标准错误重定向到标准输出。Linux终端用`2`表示标准错误，`1`表示标准输出。

`-` (短横线)：表示标准输入，一般用于1个程序需要多个输入的时候。

`<` 标准输入，后面可以跟可以产生输出的命令，一般用于1个程序需要多个输入的时候。相比`-`适用范围更广。

`|`管道符，表示把前一个命令的输出作为后一个命令的输入，前面也有一些展示例子。用于数据在不同的命令之间传输，用途是减少硬盘存取损耗。

下面我们通过一个程序`stdout_error.sh`来解释上面的文字 (Bash脚本写作，后面会有专门介绍)，内容如下

```{bash eval=F}
#!/bin/bash

echo "I am std output" 
# 下面是随便写的一个理论上不存在的命令, 理论上会报错的。
unexisted_command
```

运行这个脚本

```{bash eval=F}
# 标准输出和标准错误默认都会显示到屏幕上
ct@ehbio:~$ bash stdout_error.sh 
I am std output
stdout_error.sh: line 5: unexisted_command: command not found
# 上一行的line 5 表示是第5行命令出错了，通常用来调试程序。
# 在这个例子中，bash脚本第5行是故意输入的一个错误命令，用来展示什么是标准错误

# >把结果输入到了文件；标准错误还显示在屏幕上
ct@ehbio:~$ bash stdout_error.sh >stdout_error.stdout
stdout_error.sh: line 5: unexisted_command: command not found
ct@ehbio:~$ cat stdout_error.stdout
I am std output

# >把结果输入到了文件; 2>把标准错误输入到了另一个文件
ct@ehbio:~$ bash stdout_error.sh >stdout_error.stdout 2>stdout_error.stderr
ct@ehbio:~$ cat stdout_error.stderr
stdout_error.sh: line 5: unexisted_command: command not found

# 标准输出和标准错误写入同一个文件
ct@ehbio:~$ bash stdout_error.sh >stdout_error.stdout 2>&1
ct@ehbio:~$ cat stdout_error.stdout
I am std output
stdout_error.sh: line 5: unexisted_command: command not found
```

下面看管道符和标准输入的使用。

```{bash eval=F}
# 管道符的使用
# 第一个命令的输出作为第二个的输入
# 前面的例子中也有使用
# tr: 是用于替换字符的，把空格替换为换行，文字就从一行变为了一列
ct@ehbio:~$ echo "1 2 3" | tr ' ' '\n'
1
2
3

# cat命令之前也用过，输出一段文字
# diff是比较2个文件的差异的，需要2个参数
# - (短横线)表示上一个命令的输出，传递给diff
# < 表示其后的命令的输出，也重定向给diff
ct@ehbio:~$ cat <<END | diff - <(echo "1 2 3" | tr ' ' '\n')
> 2
> 3
> 4
> END
0a1
> 1
3d3
< 4

# 如果不使用管道和重定向标准输入，程序是这么写的

# 先把第一部分存储为1个文件
ct@ehbio:~$ cat <<END >firstfile
2
3
> 4
> END
ct@ehbio:~$ less firstfile 

# 再把第二部分存储为1个文件
ct@ehbio:~$ echo "1 2 3" | tr ' ' '\n' >secondfile

# 然后比较
ct@ehbio:~$ diff firstfile secondfile 
0a1
> 1
3d3
< 4

```

管道符的更多应用

```{bash eval=F}
ct@ehbio:~$ echo  "actg aaaaa cccccg" | tr ' ' '\n' | wc -l
3

# sed =：先输出行号，再输出每行的内容
ct@ehbio:~$ echo  "a b c" | tr ' ' '\n' | sed =  
1
a
2
b
3
c

# 后面这个命令会略微难理解些
# sed = 同时输出行号
# N: 表示读入下一行；sed命令每次只读一行，加上N之后就是缓存了第2行，所有的操作都针对第一行；
# s: 替换；把换行符替换为\t
ct@ehbio:~$ echo  "a b c" | tr ' ' '\n' | sed = | sed 'N;s/\n/\t/' 
1	a
2	b
3	c

# 后面这个命令不太好解释
# sed = 同时输出行号
# N: 表示读入下一行；sed命令每次只读一行，加上N之后就是缓存了第2行，所有的操作都针对第一行；
# s: 替换；把读取的奇数行行首加一个'>'（偶数行相当于被隐藏了）
ct@ehbio:~$ echo  "a b c" | tr ' ' '\n' | sed = | sed 'N;s/^/>/' 
>1
a
>2
b
>3
c

# 把多条序列转成FATSA格式
# sed = 同时输出行号
# N: 表示读入下一行；sed命令每次只读一行，加上N之后就是缓存了第2行，所有的操作都针对第一行；
# s: 替换；把读取的奇数行行首加一个'>'（偶数行相当于被隐藏了）
# 于是FASTA格式序列就出来了
ct@ehbio:~$ echo  "actg aaaaa cccccg" | tr ' ' '\n' | sed = | sed 'N;s/^/>/' 
>1
actg
>2
aaaaa
>3
cccccg
```


## Linux文件内容操作 {#filecontent}

### 命令组合生成文件 {#generate_file_seq}

`seq`: 产生一系列的数字; `man seq`查看其具体使用。我们这使用`seq`产生下游分析所用到的输入文件。

```{bash eval=F}
# 产生从1到10的数，步长为1
ct@ehbio:~$ seq 1 10
1
2
3
4
5
6
7
8
9
10

# 产生从1到10的数，步长为1，用空格分割
ct@ehbio:~$ seq -s ' ' 1 10
1 2 3 4 5 6 7 8 9 10

# 产生从1到10的数，步长为2
# 如果有3个数，中间的数为步长，最后一个始终为最大值
ct@ehbio:~$ seq -s ' ' 1 2 10
1 3 5 7 9

# 还记得前面提到的标准输入和标准输出吧
ct@ehbio:~$ cat <(seq 0 3 17) <(seq 3 6 18) >test
ct@ehbio:~$ cat test 
0
3
6
9
12
15
3
9
15
```

### 文件排序原来有暗仓 {#sort_par}

`sort`: 排序，默认按字符编码排序。如果想按数字大小排序，需添加`-n`参数。


`sort`常用参数

> -n: 数值排序

> -h: 人类刻度的数值排序 (2K 1G等)

> -r: reverse, 逆序

> -c: check, 不排序，查看文件是否已排序好

> -k: 指定使用哪列或哪几列排序

> -m: 合并已经排序好的文件

> -S: 缓冲区大小，用于排序大文件时的分割排序中每次分割的文件大小

> -u: 重复行只保留一次

```{bash eval=F}
# 系统默认按ASCII码排序，首先排0，然后排1, 3, 6, 9
ct@ehbio:~$ sort test
0
12
15
15
3
3
6
9
9

# 按数值大小排序
ct@ehbio:~$ sort -n test
0
3
3
6
9
9
12
15
15
```

`sort -u`: 去除重复的行，等同于`sort | uniq`。

```{bash eval=F}
ct@ehbio:~$ sort -nu test
0
3
6
9
12
15
```

`sort file | uniq -d`: 获得重复的行。(`d`=`duplication`)

```{bash eval=F}
ct@ehbio:~$ sort -n test | uniq -d
3
9
15
```

`sort file | uniq -c`: 获得每行重复的次数。

```{bash eval=F}
# 第一列为每行出现的次数，第二列为原始的行
ct@ehbio:~$ sort -n test | uniq -c
  1 0
  2 3
  1 6
  2 9
  1 12
  2 15

# 换一个文件看的更清楚
ct@ehbio:~$ cat <<END >test2
a
b
c
b
a
e
d
a
END

# 第一列为每行出现的次数，第二列为原始的行
ct@ehbio:~$ sort test2 | uniq -c
3 a
2 b
1 c
1 d
1 e

# 在执行uniq操作前，文件要先排序，不然结果很诡异
ct@ehbio:~$ cat test2 | uniq -c
1 a
1 b
1 c
1 b
1 a
1 e
1 d
1 a
```

整理下`uniq -c`的结果，使得原始行在前，每行的计数在后。

`awk`是一个强大的文本处理工具，其处理数据模式为按行处理。每次读入一行，进行操作。

* `OFS`: 输出文件的列分隔符 (output file column separtor)；
* `FS`为输入文件的列分隔符 (默认为空白字符)；
* `awk`中的列从第1到n列，分别记录为`$1`, `$2` ... `$n`；
* `BEGIN`表示在文件读取前先设置基本参数；与之相对应的是`END`，只文件读取完成之后进行操作；
* 不以`BEGIN`, `END`开头的`{}`就是文件读取、处理的部分。每次对一行进行处理。后面会详细讲解。

```{bash eval=F}
# 管道符还记得吧
# awk的操作就是读入上一步的结果，去除多余的空白，然后调换2列
#
ct@ehbio:~$ sort test2 | uniq -c | awk 'BEGIN{OFS="\t";}{print $2, $1}'
a	3
b	2
c	1
d	1
e	1
```

对两列文件，按照第二列进行排序, `sort -k2,2n`。

```{bash eval=F}
# 第二列按数值大小排序
ct@ehbio:~$ sort test2 | uniq -c | awk 'BEGIN{OFS="\t";}{print $2, $1}' | sort -k2, 2n
c	1
d	1
e	1
b	2
a	3

# 第二列按数值大小排序
# 第二列相同的再按第一列的字母顺序的逆序排序 (-r)
# 注意看前3行的顺序与上一步结果的差异
ct@ehbio:~$ sort test2 | uniq -c | awk 'BEGIN{OFS="\t";}{print $2,$1}' | sort -k2,2n -k1,1r
e	1
d	1
c	1
b	2
a	3

```

两个暗仓：

1. sort默认文件列分隔符是所有空字符，若同时存在<tab>和<space>会有非预期结果。
2. `sort -t '\t'`是错误用法，TAB键的正确输入方式是：先按<ctrl+v>再按<tab>。

### 实战FASTA序列提取 [#fasta_extract}

生成单行序列FASTA文件，提取特定基因的序列，最简单的是使用`grep`命令。

`grep`在前面也提到过，以后还会经常提到，主要用途是匹配文件中的字符串，以此为基础，进行一系列的操作。如果会使用正则表达式，将会非常强大。正则表达式版本很多，几乎每种语言都有自己的规则，后面会详细展开。

```{bash eval=F}
# 生成单行序列FASTA文件
# 开头的大于号是为了还原命令的输入过程，可以复制下面cat出来的结果，方便输入。
ct@ehbio:~$ cat <<END >test.fasta
> >SOX2
> ACGAGGGACGCATCGGACGACTGCAGGACTGTC
> >POU5F1
> ACGAGGGACGCATCGGACGACTGCAGGACTGTC
> >NANOG
> CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGT
> END
ct@ehbio:~$ cat test.fasta 
>SOX2
ACGAGGGACGCATCGGACGACTGCAGGACTGTC
>POU5F1
ACGAGGGACGCATCGGACGACTGCAGGACTGTC
>NANOG
CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGT

# grep匹配含有SOX2的行
# -A 1 表示输出的行中，包含匹配行的下一行 (A: after)
ct@ehbio:~$ grep -A 1 'SOX2' test.fasta 
>SOX2
ACGAGGGACGCATCGGACGACTGCAGGACTGTC

# 也可以使用AWK
# 先判断当前行是不是 > 开头，如果是，表示是序列名字行，替换掉大于号，取出名字。
# sub 替换, sub(被替换的部分，要替换成的，待替换字符串)
# 如果不以大于号开头，则为序列行，存储起来。
# seq[name]: 相当于建一个字典，name为key，序列为值。然后就可以使用name调取序列。
# 若命令太长，可在末尾加一个 \, 换行书写
#
# awk中$0 ~ />/ 里面的 ~ 不表示家目录，而是一个运算符，用来做模式匹配的
# /pattern/ 则表示与什么模式进行匹配，pattern代表的是匹配模式
#
# awk对文件是按行操作的，{}里面的语句会对文件的每一行都进行判断或操作，循环执行
# $0: 表示当前行所有内容；$1, $2, $3 表示当前行第1,2,3列
#
# 关于引号，如果最外层用的是单引号，那么里面最好不要再出现单引号
# 如果最外面用的是双引号，则里面最好不要再出现单引号
# 命令会寻找最近的同样引号进行匹配。
ct@ehbio:~$ awk 'BEGIN{OFS=FS="\t"}{if($0~/>/) {name=$0; sub(">", "", name);} \
	else seq[name]=$0;}END{print ">SOX2"; print seq["SOX2"]}' test.fasta
>SOX2
ACGAGGGACGCATCGGACGACTGCAGGACTGTC

```

多行FASTA序列提取要麻烦些，一个办法就是转成单行序列，用上面的方式处理。

`sed`和`tr`都为最常用的字符替换工具。

```{bash eval=F}
ct@ehbio:~$ cat <<END >test.fasta
> >SOX2
> ACGAGGGACGCATCGGACGACTGCAGGACTGTC
> ACGAGGGACGCATCGGACGACTGCAGGACTGTC
> ACGAGGGACGCATCGGACGACTGCAGGAC
> >POU5F1
> CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGT
> CGGAAGGTAGTCGTCAGTGCAGCGAGTCC
> >NANOG
> ACGAGGGACGCATCGGACGACTGCAGGACTGTC
> ACGAGGGACGCATCGGACGACTGCAGG
> ACGAGGGACGCATCGGACGACTGCAGGACTGTC
> ACGAGGGACGCATCGGACGACTGCAGGACTGT
> END

# 新解法，更简单
ct@ehbio:~$ cat test.fasta | tr '\n' '\t' | sed 's/\t>/\n>/g' \
		| sed 's/\t/\n/' | sed 's/\t//g' >test.oneline.fa
# 分解来看
# 第一步所有行变为一行
#
# 这一步使用tr是因为tr里面可以直接识别换行符，而sed不可以
# 其它的替换都使用sed
ct@ehbio:~$ cat test.fasta | tr '\n' '\t'
```

> `>`SOX2	 ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGAC >POU5F1	 CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGT CGGAAGGTAGTCGTCAGTGCAGCGAGTCC >NANOG	 ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGG ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGT 

```
# >号前面加换行符
ct@ehbio:~$ cat test.fasta | tr '\n' '\t' | sed 's/\t>/\n>/g'
```

> `>`SOX2	 ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGAC

> `>`POU5F1	 CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGT CGGAAGGTAGTCGTCAGTGCAGCGAGTCC

> `>`NANOG	 ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGG ACGAGGGACGCATCGGACGACTGCAGGACTGTC ACGAGGGACGCATCGGACGACTGCAGGACTGT


```
# 先把第一个TAB键变为换行符，实现序列名字和序列的分离
# 再去掉序列中所有的TAB键
ct@ehbio:~$ cat test.fasta | tr '\n' '\t' | sed 's/\t>/\n>/g' \
		| sed 's/\t/\n/' | sed 's/\t//g' >test.oneline.fa
```


> `>`SOX2

> ACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGAC

> `>`POU5F1

> CGGAAGGTAGTCGTCAGTGCAGCGAGTCCGTCGGAAGGTAGTCGTCAGTGCAGCGAGTCC

> `>`NANOG

> ACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGACTGT

或者简单点，直接用前面的`awk`略微做下修改。

```{bash eval=F}
# 差别只在一点
# 对于单行fasta文件，只需要记录一行，seq[name]=$0
# 对于多好fasta文件，需要把每一行序列都加到前面的序列上，seq[name]=seq[name]$0
ct@ehbio:~$ awk 'BEGIN{OFS=FS="\t"}{if($0~/>/) {name=$0; sub(">", "", name);} \
	else seq[name]=seq[name]$0;}END{print ">SOX2"; print seq["SOX2"]}' test.fasta
>SOX2
ACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGACTGTCACGAGGGACGCATCGGACGACTGCAGGAC
```

## Linux下的查找命令 - 文件哪里跑 {#linux_search}

查找是我们每天都在做的事情，早上醒来找下手机，出门之前查下公交，坐下之后查下资料，分析数据查下模式。

查找文件，查找信息，查找错误是应用起来更为具体的一些工作，而Linux命令行为我们提供了很多快捷强大的查找方式。

### 命令/可执行程序查找 - 定位脚本的位置 {#seach_cmmand}

`whereis program_name`: 会在系统默认安装目录(一般是有root权限时默认安装的软件)和`$PATH`, `$MANPATH`指定的目录中查找二进制文件、源码、文档中包含给定查询关键词的文件。(默认目录有 `/bin`, `/sbin`, `/usr/bin`, `/usr/lib`, `/usr/local/man`等类似路径)

`which program_name`: 会给出所有在[环境变量](http://mp.weixin.qq.com/s/poFpNHQgHDr0qr2wqfVNdw)中的程序的路径，一来方便知道运行的程序在哪，二来方便修改。比如[vim \`which sp_pheatmap.sh\`](https://mp.weixin.qq.com/s/_9LKs6t6rcjzokF_0gneSA)就可以直接修改绘制热图的脚本，`cp \`which sp_pheatmap.sh\` .`可以直接把源码拷贝到当前目录，省去了写全路径的麻烦。

如果运行`which bwa`，系统返回是 `/usr/bin/which: no bwa in (/home/usr/bin:/bin)`则说明bwa没有安装或安装后没有放置在环境变量中，不可以直接写名字调用。

```{bash eval=F}
# 列出了所有的R
ct@ehbio:~$ whereis R
R: /usr/bin/R /usr/local/bin/R /bin/R/4.0.2/bin/R /soft/R.sys /soft/R

# 列出我们默认调用的R
ct@ehbio:~$ which R
/bin/R/4.0.2/bin/R

ct@ehbio:~$ which bwa
/soft/bin/bwa

ct@ehbio:~$ which bwa2
/usr/bin/which: no bwa2 in (/home/usr/bin:/bin:/soft/bin/)
```

### locate普通文件快速定位 {#locate}

`locate`是快速查找定位文件的好方法，但其依赖于`updatedb`建立的索引。而`updatedb`一般是每天运行一次，所以当天新建的文件是索引不到的。如果有根用户权限，可以手动运行`updatedb`做个更新，然后再`locate bwa`。(个人用户也可以构建自己的`updatedb`, 使用`locate`在局部环境中查找。)

```
ct@ehbio:~$ locate R.sys
/soft/R.sys
```

### find让文件无处可逃 find {#find}

`find / -name bwa`可以搜索根目录下所有名字为bwa的文件

运行上面的命令时会输出很多`Permission denied`，是因为 作为普通用户，无权限访问一些目录，因此会有提示输出，可以使用`find / -name bwa 2>/dev/null`重定向标准错误到空设备，报错信息就被扔掉了，还不影响正常输出。

```
ct@ehbio:~$ find / -name R 2>/dev/null
/usr/bin/R
/usr/lib/rstudio-server/R
/usr/share/groff/1.22.2/font/devascii/R
/usr/share/groff/1.22.2/font/devhtml/R
/usr/share/groff/1.22.2/font/devlatin1/R
/usr/share/groff/1.22.2/font/devutf8/R
/usr/local/bin/R
/usr/local/lib64/R
/usr/local/lib64/R/share/R
/usr/local/lib64/R/bin/R
```

#### 按时间查找 {#find_by_time}

我们开发的在线画图网站 ([www.ehbio.com/ImageGP](http://mp.weixin.qq.com/s/pTHHqxuf0y1MCCCBaZjt9A))，为了追踪每天用户使用时碰到了什么问题，需要每天定时去查看日志。

这个命令`find . -name *.log -mmin  -60`可以查看当前目录下(包括所有子目录)一小时内修改的日志文件。再配合`head`就可以查看每个日志文件的内容，以方便查看使用过程中出现了哪些错误，如何增加提示或修改画图程序。

正是有了这个利器，前台的错误提示中才出现了这么一句话，**如果您核对后数据和参数没问题，请过1天再进行尝试。若是程序问题，我们通常会在1天内修复。**

当然后台数据都是用时间戳存储的，而且若无报错，数据会直接删掉，有报错的才会保留日志，不会泄露用户信息，这点大家不用担心。

现在画图网站越来越稳定，出现的问题越来越少，前台提示也越来越完善，希望大家使用时多看下提示，查看日志的频率也少了，就使用`find . -name *.log -mtime -1`查看从现在起24小时内的日志了。

```{bash, eval=F}
ct@ehbio:/log# find . -name *.log -mtime -1 | head
./upsetView/1597502345.upsetView.log
./upsetView/1597502776.upsetView.log
./Scatter/1597485169.Scatter.log
./Scatter/1597484912.Scatter.log
./Scatter/1597495448.Scatter.log
./Scatter/1597485405.Scatter.log
./Scatter/1597485338.Scatter.log
./Scatter/1597485526.Scatter.log
```

这个也有个问题，每次查看的时间可能不一致，会漏查或有重叠，于是在某次查看完日志后，使用`touch check`在当前目录下新建了个空文件。以后再查日志文件时，只要使用`find . -name *.log -newer check`就可以获得所有上次查看过之后的新日志。每次查看完之后，都做个书签，就方便多了。

慢慢发现有空日志文件, 使用`find . -name *.log -newer check -size +0`过滤掉, 只保留大小大于0的文件。就这样在小伙伴聪明勤奋地维持下，我们绘图网站为**7万**多用户提供了近**100万**次服务 ([画图手册 | ImageGP：今天你“plot”了吗？](https://mp.weixin.qq.com/s/ekTLcXSJh14Bm3PtVc9Mpg))。


#### 按类型和大小查找 {$find_by_type_size}

如果我想得到当前目录下所有`png`和`jpg`照片呢？ 

使用 `find . \( -name "*.png" -o -name "*.jpg" \) | less`

或 `find . -regex ".*\(\.png\|\.jpg\)$"`  


`find . -type f -size +100G`可以获取大小超过100G的文件。

#### 限制查找深度 {#find_maxdepth}

只看当前目录2层子目录内的文件`find . -maxdepth 2 -name *.log`。

查看不是`log`结尾的文件`find . -not -name *.log`。还有更多组合操作，详见find文档。

### 按文件内容查找 grep {#grep_file}

find可以查找包含某句话的文件吗？ 还是拿我们的日志说事吧，`find . -name *.log -exec grep -l 'Error' {} \;`就可以返回所有包含`Error`单词的文件名。

`find . -name *.log | xargs grep -l 'Error'`也可以。

`grep -rl 'Error' *`也可以，不加`-l`还可以顺便返回匹配的行。

**匹配行的前后行**

`grep -A 5 -B 1 'Bioinfo' ehbio.log`可以查看匹配行的前1行(B, before)和后5行(A, after)。

**匹配次数**

`grep -c 'Bioinfo' ehbio.log`可以统计包含Bioinfo的行数

`grep -ci 'Bioinfo' ehbio.log`则会在匹配时忽略大小写。

统计FASTA序列中的序列数 `grep '^>' ehbio.fa`

统计FASTQ序列中的序列数 `grep '^+$' ehbio.fq`。(^表示以什么开头，$表示以什么结尾)。

**获取未匹配行**

`grep -v 'Bioinfo' ehbio.log`，读读手册(`man grep`)，可以看到更多参数使用。

**序列提取**

假设有个基因列表文件 (ID)，有个单行序列的FASTA文件 (ehbio.fa)， 运行如下命令`grep -A 1 -Fw -f id ehbio.fa | grep -v -- '--'`就可以批量提取序列了。

`-f id`表示把id文件中的每一行作为一个匹配模式。`-F`表示匹配模式作为原始字符串，而非正则表达式，这是以防有特殊字符被解析。`-w`则表示作为一个单词匹配，即假如id中有`Sox2`，那么它会匹配`Sox2`，也会匹配`Sox21`；如果加了`-w`，则不会匹配`Sox21`。

更好的序列批量提取见 [awk的使用](http://mp.weixin.qq.com/s/R1OHRhZoDJuAdyVdJr2xHg)。

**模式匹配**

grep强大的功能是支持正则匹配，默认使用基本正则表达式，`-E`使用扩展的正则表达式，`-P`使用perl格式的正则表达式。

比如想去掉文件中所有的空行`grep -v '^$' ehbio.fa >ehbio.clean.fa`;

从公众号文章中搜索跟文章写作相关的文章 `grep 'writ.*' *.md` (可以匹配write, writing等字)；

正则表达式就比较多了，具体可以看<http://mp.weixin.qq.com/s/4lUiZ60-aXLilRk9--iQhA>。



## 一句话加速grep近30倍 {#grep_faster}

最近做一个项目，需要从表达矩阵中提取单个特定基因的表达值。最开始时文件比较小，使用`awk`单个读取处理也很快，但后来数据多了，从一个`1.2 G`的文件中提取单个基因的表达需要`30 s`，用`grep`来写需要`25 S`，这在平时写程序是可以接受的，但在网站上是接受不了的。所以就想着如何优化一下。

探索下来优化也很简单，把`grep`换为`LC_ALL=C grep`再加其它参数速度就快了近**30**倍，把时间控制在`1 s`左右。

下面是整个探索过程 （写这篇总结文章是在早晨，服务器不繁忙，所以下面的示例中只能看出来快了`5`倍左右。这也表明不加`LC_All=C`时`grep`受服务器负载影响较大，加了之后则几乎不受影响。）

### 获取单基因表达量 {#grep_single_gene}

查看下文件大小

```
ls -sh 334d41a7-e34a-4bab-841c-eb07bd84513f.txt

# 1.2G 334d41a7-e34a-4bab-841c-eb07bd84513f.txt
```

查看下文件内容

```
head 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | cut -f 1,2

# Rnu2-1	-0.52
# Tmsb4Xp6	11.81
# S100A14	1.99
# Krt17	1.26
# Aldh1A1	6.92
# Fxyd3	0.56
# Rnu2-2P	0.35
# Rarres1	6.03
# Rnvu1-7	9.53
# Lcn2	3.44
```


假设基因名字大小写一致时使用`awk`提取其表达信息，用时`14 s`。

```
time awk '{if($1=="Tmsb4Xp6") print $2;}' 334d41a7-e34a-4bab-841c-eb07bd84513f.txt >1

real	0m14.569s
user	0m12.943s
sys	0m0.626s
```

实际上大小写可能不一致而需要转换，耗时`17 s`。

```
time awk '{if(tolower($1)=="tmsb4xp6") print $2;}' 334d41a7-e34a-4bab-841c-eb07bd84513f.txt >2

real	0m17.638s
user	0m17.031s
sys	0m0.595s
```


采用`grep`命令提取 (`-i`忽略大小写)，用时`5 s`。

```
time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | grep -i 'Tmsb4Xp6' >4

real	0m5.454s
user	0m5.134s
sys	0m1.272s
```

上面的`grep`是全句匹配，想着加上`^`匹配行首是否会减少匹配量，速度能快一些，效果不明显，用时`4 s`。

```
time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | grep -iP '^Tmsb4Xp6' >5

real	0m4.262s
user	0m3.984s
sys	0m1.233s
```

`grep`是处理匹配关系，获得的是包含关键词但不一定全等于关键词，加一个`-w`参数，匹配更精确些，耗时`6.7 s`。

```
time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | grep -iPw '^Tmsb4Xp6' >6

real	0m6.723s
user	0m6.390s
sys	0m1.348s
```

从上面来看，采用正则限定并不能提速，还是采用固定字符串方式提取，速度也差不多，耗时`5 s`。(`fgrep`等同于`grep -F`)

```
time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | fgrep -i 'Tmsb4Xp6' >7

real	0m5.496s
user	0m5.128s
sys	0m1.366s
```

主角出场，加上`LC_ALL=C`后，速度明显提升了，只需要`1 s`时间。

```
time LC_ALL=C fgrep -i '^Tmsb4Xp6' 334d41a7-e34a-4bab-841c-eb07bd84513f.txt >8

real	0m1.027s
user	0m0.671s
sys	0m0.355s
```

多次测试下来，发现添加`LC_ALL=C`后`grep`命令快了很多，而且多次测试速度都很稳定 (不论服务器是繁忙还是空闲)。这里面的原理是涉及字符搜索空间的问题，我们操作的文件只包含字母、字符、数字，没有中文或其它复杂符号时都是适用的，具体原理和更多评估可查看文末的两篇参考链接，了解更多信息。

为了简化应用，我们可以`alias grep='LC_ALL=C grep'` (把这句话放到`~/.bashrc`或`~/.bahs_profile`里面)，后续再使用`grep`时就可以直接得到速度提升了。

```
time grep -F -i '^Tmsb4Xp6' 334d41a7-e34a-4bab-841c-eb07bd84513f.txt 

real	0m1.013s
user	0m0.679s
sys	0m0.334s
```

### 那如果获取多个基因怎么操作呢？{#grep_multiple_gene}

一个方式是使用正则表达式，多个基因一起传递过去，分别匹配，耗时`4.6 s`。

```
time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | LC_ALL=C grep -iP 'Tmsb4Xp6|Sox1|Sox2|Sox3'

real	0m4.654s
user	0m4.366s
sys	0m1.227s
```

或者还是使用固定字符串查找模式，把所有基因每行一个写入文件`a`，然后再去匹配，耗时`2.5 s`，且测试发现在基因数目少于`10`时（这是通常的应用场景），基因多少影响不大 (这也说明能用固定字符串查找时最好显示指定)。

```
time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | LC_ALL=C fgrep -i -f a >11

real	0m2.539s
user	0m2.191s
sys	0m1.249s
```

这里还比较了另外2个号称比`grep`快的命令`ag`和`rg`在这个应用场景没体现出性能优势。

```
time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | LC_ALL=C ag -i '^Tmsb4Xp6|Sox1|Sox2|Sox3' >10

real	0m11.281s
user	0m9.713s
sys	0m5.326s

time cat 334d41a7-e34a-4bab-841c-eb07bd84513f.txt | rg -iF -f a >12

real	0m4.337s
user	0m3.444s
sys	0m2.787s
```



* https://www.inmotionhosting.com/support/website/speed-up-grep-searches-with-lc-all/
* https://stackoverflow.com/questions/42239179/fastest-way-to-find-lines-of-a-file-from-another-larger-file-in-bash#

## 监控程序的运行时间和资源占用 {#top}

1. 监测命令的运行时间 `time command`

```
ct@ehbio:~$ time sleep 5

real	0m5.003s # 程序开始至结束的时间，包括其它进程占用的时间片和IO时间
user	0m0.001s # 进程真正执行占用CPU的时间, 
sys	0m0.002s     # 进程在内核中调用所消耗的CPU时间
user+sys是进程实际的CPU时间。如果多线程执行，这个时间可能大于Real。如果IO是瓶颈，则real会大于user+sys (单线程)。
```

2. 查看正在运行的命令和其资源使用 `top`

* top输出界面第一行主要信息是负载显示，分别是1分钟、5分钟、15分钟前到现在的任务队列的平均长度。
* 一般与CPU数目相当为好，过大系统负载超额，反应慢。
* 在top输出界面输入 `u`, 会提示输入用户名，以查看某个用户的进程。
* 重点关注的是%MEM列，查看系统占用的内存是否超出。

```
ct@ehbio:~$ top -a #按内存排序显示

top - 09:02:11 up 224 days,  8:34,  30 users,  load average: 40, 33, 28
Tasks: 1561 total,   1 running, 1550 sleeping,   0 stopped,  10 zombie
Cpu(s):  0.6%us,  0.2%sy,  0.0%ni, 99.2%id,  0.0%wa,  0.0%hi,  0.0%si,  0.0%st
Mem:  2642768880k total, 2094619800k used, 548149080k free,   4310240k buffers
Swap: 86472700k total, 73226016k used, 13246684k free, 193383748k cached

  PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND                                  
32527 ct        20   0 2631m 1.7g 1332 S  0.0  0.7 100:34.87 rsem-run-em 
29273 ct        20   0 4094m 692m 3396 S  0.0  0.3  45:18.83 java -Xmx1000m
40148 mysql     20   0 21.9g 606m 6116 S  1.3  0.2   2536:06 /usr/sbin/mysqld
31040 ct        20   0 1887m  77m 2604 S  0.3  0.0 180:43.16 [celeryd: 
```

3. 查看系统进程 `ps auwx | grep  'process_name'`




## References

* 原文链接 <http://blog.genesino.com//2017/06/bash1/>
* 微信公众号 <http://mp.weixin.qq.com/s/yKP1Kboji9N4p2Sl1Ovj0Q>
* [Linux-总目录](http://mp.weixin.qq.com/s/hEYU80fPf1eD5OWL3fO4Bg)
* [Linux-文件和目录](http://mp.weixin.qq.com/s/yKP1Kboji9N4p2Sl1Ovj0Q)
* [Linux-文件操作](http://mp.weixin.qq.com/s/4bYMzJclf_xHpqdrlbvAdA)
* [Linux文件内容操作](http://mp.weixin.qq.com/s/QFgINAYcQA9kYYSA28wK-Q)
* [Linux-环境变量和可执行属性](http://mp.weixin.qq.com/s/poFpNHQgHDr0qr2wqfVNdw)
* [Linux - 管道、标准输入输出](http://mp.weixin.qq.com/s/zL9Mw_2ig48gHrIjKM0CMw)
* [Linux - 命令运行监测和软件安装](http://mp.weixin.qq.com/s/TNU7X2mhfVVffaJ7NRBuNA)
* [Linux-常见错误和快捷操作](http://mp.weixin.qq.com/s/cDIN4_R4nETEB5irmIGFAQ)
* [Linux-文件列太多，很难识别想要的信息在哪列；别焦急，看这里。](http://mp.weixin.qq.com/s/1QaroFE7AH1pREuq-k2YAw)
* [Linux-文件排序和FASTA文件操作](http://mp.weixin.qq.com/s/R1OHRhZoDJuAdyVdJr2xHg)
* [Linux-应用Docker安装软件](http://mp.weixin.qq.com/s/HLHiWMLaWtB7SOJe_jP3mA)
* [Linux服务器数据定期同步和备份方式](http://mp.weixin.qq.com/s/c2cspK5b4sQScWYMBtG63g)
* [VIM的强大文本处理方法](https://mp.weixin.qq.com/s/4lUiZ60-aXLilRk9--iQhA)
* [Linux - Conda软件安装方法](http://mp.weixin.qq.com/s/A4_j8ZbyprMr1TT_wgisQQ)
* [查看服务器配置信息](http://mp.weixin.qq.com/s/xq0JfkHJJeHQk1acjOAJUQ)
* [Linux - SED操作，awk的姊妹篇](http://mp.weixin.qq.com/s/cywkIeRbhkYTZvkwTeIVSA)
* [Linux - 常用和不太常用的实用awk命令](http://mp.weixin.qq.com/s/8wD14FXt7fLDo1BjJyT0ew)
* [Bash概论 - Linux系列教程补充篇](http://mp.weixin.qq.com/s/lWNp_6W_jLiogmtlk9nO2A)
* [原来你是这样的软连接 ](https://mp.weixin.qq.com/s/q3ic5WSfLdAnqIhFQX-bUQ)
* [一网打进Linux下那些查找命令](https://mp.weixin.qq.com/s/xWwj04h4W6yEqQLOfuQ8qA?)
* [有了这些，文件批量重命名还需要求助其它工具吗？](https://mp.weixin.qq.com/s/hyiGxm0jx6xEc90nHLN4dQ)

<!--chapter:end:01.Basic.Rmd-->

# Linux下软件安装相关 {#softinstall}

视频课见 <http://bioinfo.ke.qq.com>。

软件安装的几个概念：环境变量、可执行属性、编译安装、Conda安装。

## 文件属性和可执行属性 {#fileattributeplusX}

### 文件属性 {#fileattribute}

文件属性`rwx`中`r`表示`read` (数字表示为4)、`w`表示`write` (数字表示为2)、`x`表示执行 (数字表示为1)。三个为一组，连续出现三次(如下面命令行中所示), 第一组表示文件的所有者拥有的权限，第二组为文件所有者所在的用户组所拥有的权限，组内所有成员都具有的权限，第三组为其它用户的权限。

`chmod`可以修改文件或文件夹属性。

```{bash eval=F}
ct@ehbio:~$ ls -l /home
-rwxr-xr-x 1 ct ct 26 12月  7 2016  ct

# 让自己的家目录只自己可见
ct@ehbio:~$ chmod go-rwx /home/ct
ct@ehbio:~$ ls -l /home
-rwx------ 1 ct ct 26 12月  7 2016  ct

# 同组人增加可读和可执行属性
ct@ehbio:~$ chmod g+rx /home/ct
ct@ehbio:~$ ls -l /home
-rwxr-x--- 1 ct ct 26 12月  7 2016  ct

# 所有人增加可读和可执行属性
ct@ehbio:~$ chmod a+rx /home/ct
ct@ehbio:~$ ls -l /home
-rwxr-xr-x 1 ct ct 26 12月  7 2016  ct
```

### 可执行属性 {#executable}

Linux下文件有一个特殊的属性即可执行属性，用来指示这个文件是一个可执行的脚本或可以运行的二进制文件。前面所提到的这些命令，都具有可执行属性。

`which`: 表示查看命令的路径。一般用于当我们想知道使用的命令来源于什么地方时，比如安装了多个R或多个python，但又分不清用的是哪个时，`which`一下，立即明了。在这儿我们用which获取的是可执行的命令所在的路径，进而查看其属性。

```{bash eval=F}
ct@ehbio:~$ ls -l "`which cd`"
#rwx: 文件所有者可读、可写、可执行
#r-x: 文件所有者所在组其它成员可读、可执行，不可修改
#r-x: 其它人可读、可执行，不可修改
-rwxr-xr-x 1 root root 26 12月  7 2016 /usr/bin/cd

ct@ehbio:~$ ls -l "`which mkdir`"
-rwxr-xr-x. 1 root root 79768 11月  6 2016 /usr/bin/mkdir

ct@ehbio:~$ ls -l "`which python`"
#l: 代表软连接
#软连接自身是所有人可读可写，但具体的权限依赖于其链接的文件
lrwxrwxrwx. 1 root root 7 3月  22 15:04 /usr/bin/python -> python2

ct@ehbio:~$ ls -l "`which python2`"
#第二层链接
lrwxrwxrwx. 1 root root 9 3月  22 15:04 /usr/bin/python2 -> python2.7

#链接的原始文件

ct@ehbio:~$ ls -l "`which python2.7`"
-rwxr-xr-x. 1 root root 7136 11月  6 2016 /usr/bin/python2.7
```


`chmod a+x file`: 表示给文件增加所有人(a)可执行权限 (+x)

`chmod u+x file`: 表示给文件增加所有者(u，user，)可执行权限 (+x)

`chmod g+x`, `chmod o+X`: 表示给文件增加组内人或其它人可执行权限

`chmod 755 file`: 表示拥有者有可读写执行权限，其它人有可读执行权限。(`7=4+2+1`; `5=4+1`)

具体使用`man chmod`查看其它参数使用。

```{bash eval=F}
# 新建个文件
ct@ehbio:~$ cat <<END >run.sh
> echo " I am a script created by ehbio." 
> END

# 查看其权限值
ct@ehbio:~$ ls -l run.sh 
-rw-rw-r-- 1 ct ct 39 6月  14 23:12 run.sh

# 更改权限值
ct@ehbio:~$ chmod 755 run.sh

# 查看其权限值
# 注意多了3个x
ct@ehbio:~$ ls -l run.sh 
-rwxr-xr-x 1 ct ct 39 6月  14 23:12 run.sh

# 去除其它用户的可执行权限
ct@ehbio:~$ chmod o-x run.sh 

# 注意看少了个x
ct@ehbio:~$ ls -l run.sh 
-rwxr-xr-- 1 ct ct 39 6月  14 23:12 run.sh

# 去除同组的可执行权限
ct@ehbio:~$ chmod g-x run.sh

# 注意看又少了个x
ct@ehbio:~$ ls -l run.sh 
-rwxr--r-- 1 ct ct 39 6月  14 23:12 run.sh

# 去除所有人的可执行权限
ct@ehbio:~$ chmod a-x run.sh
ct@ehbio:~$ ls -l run.sh 
-rw-r--r-- 1 ct ct 39 6月  14 23:12 run.sh

# 给所有人增加可执行权限
ct@ehbio:~$ chmod a+x run.sh
ct@ehbio:~$ ls -l run.sh 
-rwxr-xr-x 1 ct ct 39 6月  14 23:12 run.sh
```

如果一个文件有了可执行权限，是不是就可以执行了，我们来检测下。

```{bash eval=F}
ct@ehbio:~$ run.sh
-bash: run.sh: 未找到命令
```

事实上并非如此，输入命令，回车后，提示命令未找打，这是为什么呢？

这就涉及到**环境变量**的概念，通俗的讲，环境变量就是告诉电脑 (实际是操作系统)几个目录。这几个目录下存储又可执行文件，如前面显示的`/usr/bin`目录，大部分的系统命令都在这个目录下。

## PATH和path，傻傻分不清 {#PATH_path_which}

习惯了Windows电脑下的所见即所得，找到程序或文件双击即可运行或打开；于是我们被惯得以为电脑会像人一样聪明，给他一个名字就可以运行程序或打开文件；于是在命令行下或程序里不断碰壁，为啥这个命令不运行了呢？

我们不能太高估电脑（或操作系统），不要以为只要输入一个程序名或文件名，电脑（或操作系统）就可以满硬盘的去找这个文件在哪；这一来效率太低了，二来重名了怎么办？比如有2个文件都叫“子房.txt”，一个存储汉初三杰之张良，一个存储被子植物生长种子的器官；可能打开前我们自己也不知道要开哪个吧。

想一下，我们在Windows下寻找文件时，是不是先打开`我的电脑`，然后打开`D盘`，打开`学习`目录，再打开`学习计划.docx`这个文件。即便我们从来没有执行过这个计划，每天我们还是不厌其烦的一层层打开然后制定新的计划。只是，我们忽略了这个`一层层`打开。

`path`我们一般指文件的路径，也就是`一层层`打开的过程。以Linux为例：

我们要查看一个在自己家目录下的文件 `I_am_home.txt`，那登录后，直接可见：

```
YSX@ehbio:~$ tree
.
├── I_am_home.txt
└── train
    ├── amplicon
    │   └── pipeline_amplicon.sh
    ├── metagenome
    │   └── pipeline_metagenome.sh
    ├── population_genomics
    │   └── pipeline_gatk.sh
    ├── single_cell
    │   ├── Scanpy.ipynb
    │   └── Seurat.Rmd
    └── transcriptome
        └── pipeline_salmon.sh
YSX@ehbio:~$ head I_am_home.txt
I am home!
```

那如果想看`Seurat.Rmd`，怎么查看？一步步找下去就对了。

```
YSX@ehbio:~$ less Seurat.Rmd
Seurat.Rmd: 没有那个文件或目录
YSX@ehbio:~$ less train/Seurat.Rmd
train/Seurat.Rmd: 没有那个文件或目录
YSX@ehbio:~$ less train/single_cell/Seurat.Rmd
```

也可以一步步先做目录切换，然后再查看

```
YSX@ehbio:~$ cd train
YSX@ehbio:~/train$ cd single_cell/
YSX@ehbio:~/train/single_cell$ less Seurat.Rmd
```

那如果你这时你想运行`pipeline_metagenome.sh`快速分析宏基因组数据怎么办？


```
YSX@ehbio:~/train/single_cell$ pipeline_metagenome.sh
-bash: pipeline_metagenome.sh: 未找到命令
```

`pipeline_metagenome.sh`命令去哪儿了？上面我们都看到了，就在`metagenome`目录下，为啥电脑（操作系统）这么笨却找不到？另外为什么运行`head`就可以找到？难道有一些黑魔法在里面？

确实是有一些黑魔法的，不过我们一般称之为**规则**。

操作系统为了便捷性和安全性，定义了一系列环境变量，存储常用信息，`PATH` (注意全是大写字母)是其中一个。

`PATH`: 是存放有(可执行)命令和程序的目录集合；在操作系统接到用户输入的命令时，会对PATH**存储的目录**进行查找，看下是否有与用户输入的命令同名的文件存在，而且是**从前到后**一个个查找，而且是**查到就停**，最后查不到就报错。（从这几个加粗的文字，可以看到操作系统很懒，当然懒是好的程序员的必备属性。）

我们先看下`PATH`里面存了哪些目录？

```
YSX@ehbio:~/train/single_cell$ echo $PATH
/usr/bin:/usr/local/bin
```

在我们前面输入`head`命令时，操作系统收到`回车`指令后，先去看下`$PATH`里面有哪些目录，然后从第一个`/usr/bin`开始寻找，很幸运，一下找到了`/usr/bin/head`文件，尝试运行，成功。所以在这个情况下，我们输入`head`等同于输入`/usr/bin/head`。那这个会不会给我们一些启发呢？

我们只要提供`pipeline_metagenome.sh`的路径就可以运行了。

```
# 相对路径
YSX@ehbio:~/train/single_cell$ ../metagenome/pipeline_metagenome.sh
# 绝对路径
YSX@ehbio:~/train/single_cell$ ~/train/metagenome/pipeline_metagenome.sh
# 再绝对一些
YSX@ehbio:~/train/single_cell$ /home/YSX/train/metagenome/pipeline_metagenome.sh
```

程序可以运行了，但是不是写起来太麻烦了？既然`head`可以只写命令，系统就可以帮着我们去找，那么我们是否也可以把`/home/YSX/train/metagenome/`放到`PATH`里面。这就是如何去设置环境变量了。

```
# 加到环境变量的路径必须是全路径，全路径指以/开头或已~开头的路径
# 注意第一个PATH不含$, 第二个PATH有$符号
# 我们后面会讲什么时候用$, 什么时候不用$

# 给原变量PATH后面加一个路径（绝对路径），冒号(:)分割
YSX@ehbio:~/train/single_cell$ PATH=$PATH:/home/YSX/train/metagenome/
# 导出变量，使其对系统（Shell）可见
YSX@ehbio:~/train/single_cell$ export PATH
# 上面两句可以合并为一句，如下：
YSX@ehbio:~/train/single_cell$ export PATH=$PATH:/home/YSX/train/metagenome/
# 再次运行，可以运行了
YSX@ehbio:~/train/single_cell$ pipeline_metagenome.sh
# 看下PATH存储的目录，多了我们的新增
YSX@ehbio:~/train/single_cell$ echo $PATH
/usr/bin:/usr/local/bin:/home/YSX/train/metagenome/
```

这样就新增一个目录到环境变量里面了，可以依次继续增加更多目录。

```
YSX@ehbio:~/train/single_cell$ export PATH=$PATH:/home/YSX/train/metagenome/:/home/YSX/train/amplicon/
```

加到环境变量的路径必须是全路径，全路径指以`/`开头或以`~`或`${HOME}`开头的路径 (注意：`~`开头的路径只能个人用户有效)。

有时我们也会看的这样的写法：`export PATH=my_path:$PATH`，这与`export PATH=$PATH:my_path`有什么区别呢？


回顾下这几个关键字：**从前到后**，**查到就停**。写出官话就是：PATH中越靠前的路径优先级越高。这有什么用处呢？

比如，一般的操作系统都会有系统的`python`和`R`，通常版本比较老，我们作为普通用户也没权限修改。

那怎么办？自己装一份新的`python`和`R`，然后用自己的，这时就涉及到优先级问题了。

假如我在`/home/YSX/soft/anaconda/bin`下安装了一个`python`，那么我需要设置优先调用我自己的`python`，设置环境变量时，我就得把`/home/YSX/soft/anaconda/bin`放到前面，如`export PATH=/home/YSX/soft/anaconda/bin:$PATH`。如果反过来写，那么`/usr/bin/python`就会优先被调用了。

```
# which 常用工具，查看当前调用的程序的具体来源
YSX@ehbio:~/train/single_cell$ which python
/usr/bin/python
# 优先调用自己的python
YSX@ehbio:~/train/single_cell$ export PATH=/home/YSX/soft/anaconda/bin:$PATH
YSX@ehbio:~/train/single_cell$ which python
/home/YSX/soft/anaconda/bin/python
```

环境变量学会怎么设置了，关机，下班，睡觉。

第二天早上起来，打开电脑，再运行程序

```
YSX@ehbio:~/train/single_cell$ which python
/usr/bin/python
YSX@ehbio:~/train/single_cell$ pipeline_metagenome.sh
-bash: pipeline_metagenome.sh: 未找到命令
```

结果发现昨天的设置都无效了，去生信宝典群里提问 "有谁对Linux比较精通？"。半晌，无人响应，敢说自己精通的不多。提问还是不能这么问，应该怎么问，具体见：[如何优雅的提问](https://mp.weixin.qq.com/s/B8JO4GjvzZP5BUMoaKPrZw)。

后来，有好心人回复“你遇到什么问题，具体描述下？”

经过半个小时的沟通，理清了，关键点：*环境变量设置后失效了，怎么长期有效？*

如果早这么问，估计程序都运行完了。

这时需要用到另一个规则: 登录远程服务器时，系统会自动运行`~/.bash_profile`里面的命令，所以把前面写的这句话`export PATH=/home/YSX/soft/anaconda/bin:$PATH:/home/YSX/train/metagenome/:/home/YSX/train/amplicon/`放到文件`~/.bash_profile`里面就好了。

```{bash, eval=F}
# 这是我的~/.bash_profile中的内容，主要是最好一行。可以连续的加入多个路径。
if [ -f ~/.bashrc ]; then
	. ~/.bashrc
fi
	
if [ -f ~/.bash_aliases ]; then
	. ~/.bash_aliases
fi
		
export PATH=/home/YSX/soft/anaconda/bin:$PATH:/home/YSX/train/metagenome/:/home/YSX/train/amplicon/
```

文件输入后，不要忘记`source ~/.bash_profile`使设置生效（当然，关掉登录窗口，再次登录也可以）。

### 小事也不能忽略 {#last_but_not_least}

2. 其它环境变量 
   * 环境变量PATH：定义可执行程序的目录
   * LD_LIBRARY_PATH：定义动态库的目录
   * PYTHONPATH：定义Python包的目录
   * PERL5LIB：定义Perl模块的目录
3. .bashrc和.bash_profile
   * ~/.bashrc本地登录时读取 （文件若无，可新建）
   * ~/.bash_profile远程登录时读取（文件若无，可新建）
4. 如果想在系统层面设置环境变量，应该写到`/etc/profile.d/custom.sh`里面（文件若无，可新建）。
5. 设置环境变量要注意2点：1. 设置新的环境变量时一般要包含原始的环境变量，不能覆盖；2. 注意自己的目录和系统环境变量的目录的顺序，想让哪个先被找到，就先放哪个。
6. 每次安装一个软件都设置一次环境变量有些麻烦，假如我们已经把`/home/ct/bin`目录放在环境变量中了，以后新安装的软件，只要把可执行命令软连到`/home/ct/bin`目录下就好了，简单方便，即时生效 (操作可见下面`NCBI-blast`的安装)。


## 软件安装的几种传统方式 {#softInstallways}

不同于windows，Linux下软件安装的方式比较多样，有些也比较复杂。每种安装方式都有自己的优点和局限，也都有可能遇到问题。在我们理解了原理之后，借助谷歌，可以更好地帮助解决问题。

### 系统包管理器安装 {#system_package}

软件安装最方便的、一般也不容易出问题的是利用系统自带的包管理工具，可以解决大部分的依赖问题。

```
# centos
# 如果长时间没更新，先运行下update
yum update
# 如果不知道软件具体名字，可以先用一个关键字search一下, 选择正式的名字
# 需要注意的是一般的服务器都是64 bit，需要选x86_64版本
yum search soft_name or soft_description
yum search soft_official_name
```

但也有一些不足，主要3点：

1. 需要根用户的权限。
2. 如果系统版本老，安装的软件版本也会比较老。使用新版本有时又会发生冲突。
3. 生物信息学中不少软件不在系统的安装源里面。

### 下载二进制文件 {#binary}

解决这些问题，就需要自己去软件官网查找最新的分发包，又有两种可能，一种是分发包直接就是编译好的软件，下载下来设置下可执行属性并放入环境变量就可以运行了，如于`blast`或`bowtie`这样的工具。

blast的链接为<ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.7.1+-x64-linux.tar.gz>。

```{bash eval=F}
wget ftp://ftp.ncbi.nlm.nih.gov/blast/executables/blast+/LATEST/ncbi-blast-2.7.1+-x64-linux.tar.gz
tar xvzf ncbi-blast-2.7.1+-x64-linux.tar.gz
cd ncbi*
cd bin
# 直接进入bin目录，找到对应可执行文件，链接到在环境变量的目录中去。
# 具体可看视频的操作  http://bioinfo.ke.qq.com
ln -s `pwd`/* ~/bin
```

另一种则是需要从源码编译安装，下面主要讲解下这个。

### 源码编译安装 {#configure_make_install}

源码编译经典的三部曲`configure`, `make`, `make install`。如果不出问题，一步步执行下来就安装好了，也不一定要知其所以然。但出了问题，就不是比较容易解决的。如果知道这背后的机制，还是会有帮助的。

* `configure`是检查系统的库文件、类文件、依赖软件是否存在以及它们的版本是否满足需求，并根据实际检测结果生成`Makefile`的工具。一般是一堆bash命令的组合。通常也需要在这一步配置一些参数。最常用的就是指定软件的安装目录`--prefix=/home/ct/soft/specific_name`。

* `make`则是具体的编译过程。编译的语句都写在了`Makefile`中。`make`默认编译Makefile中出现的第一个`target`，也可以指定`target`编译，并根据Makefile的设置方式依次编译所有依赖的东西。

有些软件的安装，在执行完`make`后就获得了可执行程序，可以跳过`make install`的过程，只需要把可执行程序放入环境变量就可以运行了。但部分软件还需要一些依赖关系，所以需要执行`make install`才算完成了完整的安装。

* `make install`通常是拷贝`make`编译出来的可执行文件或者依赖的库文件(如果有的话)到`configure`时的`--prefix`指定的目录下。

* 安装好的软件放入环境变量, 就可以快乐的运行了。

两条注意:

* 从源码编译最难解决的问题就是依赖的库文件、头文件、其它软件的缺失或版本不匹配，没有统一的解决办法，原则就是`缺啥补啥`。

* 三部曲每一步的执行，屏幕上都会输出比较多的信息，一定仔细看最后有没有`ERROR`类的字样，对判断软件有无安装成功和下一步要怎么做会很有帮助。

举一个例子，编译安装`samtools`。具体看视频解释<http://bioinfo.ke.qq.com>。

```{bash eval=F}
wget https://jaist.dl.sourceforge.net/project/samtools/samtools/1.7/samtools-1.7.tar.bz2
tar xvzf samtools-1.7.tar.bz2
cd samtoo*
./configure --prefix=/home/ct/soft/samtools
make
make install
cd /home/ct/soft/samtools/bin
ln -s `pwd`/* ~/bin
```

**小练习**： 尝试源码安装`EMBOSS`, 下载地址 <ftp://emboss.open-bio.org/pub/EMBOSS/emboss-latest.tar.gz>.

`EMBOSS`是欧洲分子生物学开放软件包，主要做序列比对，数据库搜搜，蛋白motif分析和功能域分析，序列模式搜索，引物设计等。

```{r}
emboss= "Popular applications;Functions
prophet;Gapped alignment for profiles.
infoseq;Displays some simple information about sequences.
water;Smith-Waterman local alignment.
pepstats;Protein statistics.
showfeat;Show features of a sequence.
palindrome;Looks for inverted repeats in a nucleotide sequence.
eprimer3;Picks PCR primers and hybridization oligos.
profit;Scan a sequence or database with a matrix or profile.
extractseq;Extract regions from a sequence.
marscan;Finds MAR/SAR sites in nucleic sequences.
tfscan;Scans DNA sequences for transcription factors.
patmatmotifs;Compares a protein sequence to the PROSITE motif database.
showdb;Displays information on the currently available databases.
wossname;Finds programs by keywords in their one-line documentation.
abiview;Reads ABI file and display the trace.
tranalign;Align nucleic coding regions given the aligned proteins."

emboss = read.table(text=emboss,sep=";",row.names=NULL,header=T)
knitr::kable(emboss, booktabs=T, caption="Popular applications of EMBOSS.")
```

### Python包的安装 {#pythonpac}

在没有`Anaconda`(或其前身canopy)出现之前，Python包以其管理混乱、安装困难著称。有了`Anaconda`后，不只python包的安装简单了，其它软件的安装也都方便了 (详见后面Anaconda的两个福利)。

* 首先下载Anaconda的安装包 https://www.continuum.io/downloads。
* Anaconda的安装包做的很人性化，一个bash脚本，只要运行`bash Anacond*x86_64.sh`，然后按照提示操作就可以了。
* 安装好后，设置或刷新下环境变量就可以使用了。
* 此后再安装python的包只需要执行`pip install pakcage_name`或`conda install pakckage_name`就可以了。
* 这里唯一需要注意的就是确认使用的`python`或`pip`确实是Anaconda安装的`python`或`pip`。
	* `which python`查看使用的python命令。
	* 如果使用的还是系统默认的python，则需要检查下环境变量的设置，尤其前面提到的环境变量里面不同目录放置的顺序。


### Anaconda的两个福利 {#anaconda_fear}

1. 头文件和库文件库

这是Anaconda安装后的目录结构

```
bin   envs  Examples  imports  lib    LICENSE.txt  pkgs     share  var
conda-meta  etc   gcc include  lib64  mkspecsplugins  ssl
```

其中lib目录下，一部分是依赖的动态链接库, `.so`文件；这也是在源码编译时最常见的拦路虎。通常，只需要把这个目录放入环境变量`LD_LIBRARY_PATH`里面比如`export LD_LIBARY_PATH=${LD_LIBARY_PATH}:anaconda_path/lib`就可以解决问题。

```
cairo                    libitm.a              libQtScript.so.4
cmake                    libitm.la             libQtScript.so.4.8
engines                  libitm.so             libQtScript.so.4.8.7
gcc                      libitm.so.1           libQtScriptTools.la
gcj-4.8.5-14             libitm.so.1.0.0       libQtScriptTools.prl
glib-2.0                 libitm.spec           libQtScriptTools.so
libargtable2.a           libjpeg.a             libQtScriptTools.so.4
libargtable2.la          libjpeg.la            libQtScriptTools.so.4.8
libargtable2.so          libjpeg.so            libQtScriptTools.so.4.8.7
libargtable2.so.0        libjpeg.so.8          libQtSql.la
libargtable2.so.0.1.8    libjpeg.so.8.4.0      libQtSql.prl
libasan.a                libmkl_avx2.so        libQtSql.so
libasan.la               libmkl_avx512_mic.so  libQtSql.so.4
libasan_preinit.o        libmkl_avx512.so      libQtSql.so.4.8
libasan.so               libmkl_avx.so         libQtSql.so.4.8.7
```

2. bioconda

bioconda生物分析软件安装的通道，后面专门介绍。


### R和R包的安装 {#R_install}

见[R系列教程](http://www.ehbio.com/Bioinfo_R_course)。

### Perl包的安装 {#perl_package}

```
# 假设~/bin已在环境变量中
cd ~/bin
curl -L https://cpanmin.us/ -o cpanm
chmod +x cpanm
cpanm List::MoreUtils Bio::Perl
```


## Conda安装配置生物信息软件 {#condaInstall}

Conda是一种通用包管理系统，旨在构建和管理任何语言的任何类型的软件。通常与Anaconda (集成了更多软件包，[https://www.anaconda.com/products/individual](https://www.anaconda.com/products/individual))和Miniconda (只包含基本功能软件包, [https://conda.io/miniconda.html](https://conda.io/miniconda.html))一起分发。

最初接触到Anaconda是用于Python包的安装。Anaconda囊括了100多个常用的Python包，一键式安装，解决Python包安装的痛苦。但后来发现，其还有更多的功能，尤其是其增加了`bionconda` ([https://bioconda.github.io/index.html](https://bioconda.github.io/index.html))通道后，生物信息分析的7925多个软件都可以一键安装了 (具体列表在：<https://anaconda.org/bioconda/repo>)，免去了编译时间浪费和解决库文件安装的问题。另外其最有吸引力的是它的`虚拟软件环境`概念，可以简单的配置不同Python版本的环境、不同Python包的环境、不同R环境和R包的环境，对于生物信息软件繁杂的应用和频繁的更新提供了很大的便利。

![](image/conda.png)

### Conda安装和配置 {#condaInstallConfig}

在链接<https://www.anaconda.com/products/individual>下载`Anaconda`或`Miniconda`对应版本的分发包之后，安装就是运行下面的命令，根据提示一步步操作，主要是修改安装路径 (如果是根用户，可以安装到`/anaconda`下，其它任意目录都可以，但路径短还是有好处的；普通用户安装到自己有权限的目录下，如`~/miniconda2`)。


```
# soft目录为conda安装的目录，可自己修改
soft=~/miniconda2
echo 'export PATH="'${soft}'/bin:$PATH"' >>~/.bash_profile
export PATH="${soft}/bin:$PATH"
wget -c https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
bash Miniconda2-latest-Linux-x86_64.sh -b -f -p ${soft}
```

安装完成之后，记得把安装路径下的`bin`文件夹加入到环境变量中 (上面命令中我们已经帮您加进去了)。


### Conda基本使用 {#conda_basic}

在Conda安装配置好之后，就可以使用了。

```
conda list # 列出安装的软件包
# conda所有软件名都是小写
conda search <package ambigious name> # 搜索需要安装的软件包，获取其完成名字
```

以搜索`numpy`为例：

```
conda search numpy  # * 表示对于版本的包已安装
```

```
Fetching package metadata ...............
numpy                        1.7.2           py27_blas_openblas_201  conda-forge     [blas_openblas]
                             1.7.2           py27_blas_openblas_202  conda-forge     [blas_openblas]
                             1.12.0                   py36_0  defaults        
                             1.12.0             py36_nomkl_0  defaults        [nomkl]
                          *  1.12.1                   py27_0  defaults        
                             1.12.1             py27_nomkl_0  defaults        [nomkl]
                             1.13.1                   py36_0  defaults        
                             1.13.1             py36_nomkl_0  defaults        [nomkl]
numpy-indexed                0.3.2                    py27_0  conda-forge                
                             1.0.47                   py35_0  conda-forge     
                             1.0.47                   py36_0  conda-forge     
numpy_groupies               0.9.6                    py27_0  conda-forge     
                             0.9.6                    py35_0  conda-forge     
                             0.9.6                    py36_0  conda-forge     
numpy_sugar                  1.0.6                    py27_0  conda-forge     
                             1.0.6                    py34_0  conda-forge        
numpydoc                     0.6.0                    py27_0  conda-forge     
                             0.6.0                    py34_0  conda-forge             
xnumpy                       0.0.1                    py27_0  conda-forge           
```

安装包

```
conda install <package name> # 安装软件包
# -y是同意安装，不写的话会弹出提示，需要再次确认
conda install numpy=1.7.2 -y # 安装特定版本的软件包
conda remove <package name> # 移除软件包
```


安装R

```
# 具体见下面
# 安装R,及80多个常用的数据分析包, 包括idplyr, shiny, ggplot2, tidyr, caret 和 nnet
conda install -c r r-base=4.0.2 r-essentials 
# 安装单个包
# conda install -c https://conda.binstar.org/bokeh ggplot 
```

更新包

```
# 更新基础conda，新版本conda使用起来更快
conda update -n base -c defaults conda

conda update r-base
```

获取帮助信息

```
conda -h # 查看conda可用的命令
conda install -h #查看install子命令的帮助
```

只是这些命令就可以省去不少安装的麻烦了，但是如果软件没搜索到呢？

### Conda的channel {#conda_channel}

Conda默认的源访问速度有些慢，可以增加国内的源；另外还可以增加几个源，以便于安装更多的软件，尤其是`bioconda`安装生信类工具。`conda-forge`通道是Conda社区维护的包含很多不在默认通道里面的通用型软件。`r`通道是向后兼容性通道，尤其是使用`R3.3.1`版本时会用到，现在则不需要单独添加了。后加的通道优先级更高，因此一般用下面列出的顺序添加。清华镜像具体见<https://mirrors.tuna.tsinghua.edu.cn/help/anaconda/> (有时清华镜像也不稳定，不稳定时直接用官方镜像，早上下载速度还是好的)。

```
conda config --add channels r # Optional # Lowest priority
conda config --add channels defaults
conda config --add channels conda-forge 
conda config --add channels bioconda 
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
# Anocanda清华镜像
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ 
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/ 
conda config --add channels  https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/cond-forge
# 清华通道, 最高优先级
conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/ 
conda config --set show_channel_urls yes
```

注意通道的顺序是会影响`solving environment`和软件包下载的速度的。

```
# 显示已有的通道
conda config --get channels
```

conda通道的配置文件一般在`~/.condarc`里面，内容如下。全局控制conda的安装在`conda_path/.condarc`，具体操作见[https://conda.io/docs/user-guide/configuration/admin-multi-user-install.html](https://conda.io/docs/user-guide/configuration/admin-multi-user-install.html)。

```
channels:
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/bioconda/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/cond-forge
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/ # Anocanda清华镜像
  - https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/msys2/
  - bioconda
  - conda-forge
  - r
```

### 创建不同的软件运行环境 {#conda_environment}

这是`Conda`最有特色的地方，可以通过创建不同的环境，同时运行不同软件的多个版本。

新创建的软件环境的目录为`anaconda_path/envs/enrironment_name`，具体见下面的3个例子。

* 创建一个环境`transcriptome`安装常用转录组分析软件

```
# 新建一个环境，命名为transcriptome
# 环境名字为 transcriptome
# 环境中安装 samtools multiqc rseqc
conda create -n transcriptome samtools multiqc rseqc

# 如果还想继续安装
conda install -n transcriptome fastqc salmon star stringtie sra-tools trimmomatic rmats rmats2sashimiplot

# 启动新环境
source activate transcriptome
salmon -h

# 默认安装到了anaconda_path下面的envs/transcriptome目录下（在屏幕输出也会有显示）
# 这个目录下存在bin文件夹，一般使用全路径就可以调用，如下
# anaconda_path/envs/transcriptome/bin/salmon -h # 但有时会因为依赖关系而失败

source deactivate transcriptome
```

不少软件不激活环境也可以使用全路径调用，比如`anaconda_path/envs/transcriptome/bin/salmon`就可以直接使用`salmon`程序，这样我们就可以根据前面的`PATH`介绍，把目录`anaconda_path/envs/transcriptome/bin/`放入环境变量，就可以直接调用这个环境中的大部分程序了。

新版的`conda`默认会使用`conda activate transcriptome`激活环境。

初次使用时会弹出一个提示，需要运行`conda init`：

```
conda activate qiime2-2020.6

CommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.
To initialize your shell, run

    $ conda init <SHELL_NAME>

Currently supported shells are:
  - bash
  - fish
  - tcsh
  - xonsh
  - zsh
  - powershell

See 'conda init --help' for more information and options.

IMPORTANT: You may need to close and restart your shell after running 'conda init'.
```

不过，个人更喜欢用`source anaconda_path/bin/activate transcriptome`激活环境，用起来更灵活一些。而且如果是根用户安装时，**不建议把`conda`环境默认加到环境变量中**，会引起不必要的系统冲突。可以给个用户自己使用是自己配置对应的环境变量。 

激活环境后，会看到命令行提示前多了一个环境名字，比如下面激活`qiime2-2020.6`环境后的展示。

```
ct@ehbio:~# source /anaconda3/bin/activate qiime2-2020.6
(qiime2-2020.6) ct@ehbio:~# which python
/anaconda3/envs/qiime2-2020.6/bin/python
(qiime2-2020.6) ct@ehbio:~# source /anaconda3/bin/deactivate
DeprecationWarning: 'source deactivate' is deprecated. Use 'conda deactivate'.
ct@ehbio:~# which python
/usr/bin/python
```


* 在环境`phylo`中安装`ete3`

起因是使用官方的推荐命令安装时出了问题，py3.5的包装到了py2.7环境下。解决办法，新建一个`py2.7`的环境，然后安装。

```
# 新建一个环境，命名为phylo，指定其内安装的python版本为2.7
conda create -n phylo python=2.7

# 在phylo环境中安装 ete3 
# ete3存在于2个通道中，官方推荐使用自己的通道，但没有成功
# -n 指定安装环境  -c 指定下载通道
# conda install -n phylo -c etetoolkit ete3 ete3_external_apps

# bioconda通道里面也有ete3, 下面的安装未指定具体通道，
# 将在前面设定的几个通道里面按先后顺序查找安装
conda install -n phylo ete3 ete3_external_apps

# 默认安装到了anaconda_path下面的envs/phylo目录下（在屏幕输出也会有显示）
# 这个目录下存在bin文件夹，一般使用全路径就可以调用，如下
# anaconda_path/envs/phylo/bin/ete3 -h # 但有时会因为依赖关系而失败

# 所以激活本次安装环境是比较不容易出问题的使用方式
source activate phylo

# 在新环境里面执行命令操作
ete3 -h
# 其它操作

# 退出新环境
source deactivate phylo
```


* 创建R环境 [Reference1](https://samrelton.wordpress.com/2015/07/02/rconda/)

```
# Create a new conda environment called r,并且在里面安装anaconda
conda create -n r anaconda

# Switch to r environment
source activate r

# 在新环境里面安装R Installs R
conda install -c r r

# Install R kernel for IPython notebook
conda install -c r r-irkernel

# Install ggplot
conda install -c https://conda.binstar.org/bokeh ggplot

# 最后退出新环境
source deactivate r
```

列出所有的环境

```
conda env list

# conda environments:
#
                         /anaconda2
                         /anaconda2/envs/lefse
                         /anaconda2/envs/metagenome_env
                         /anaconda2/envs/metawrap
                         /anaconda2/envs/prokka_env
                         /anaconda2/envs/py3
                         /anaconda2/envs/r-environment
                         /anaconda2/envs/reseq
                         /anaconda2/envs/sourmash_env
                         /anaconda3/envs/qiime2-2020.6
```

### 移除某个conda环境 {#remove_conda}

如果环境不需要了，或出了错，则可以移除。比如需要移除`phylo`环境，执行`conda remove -n phylo --all`。

### Conda配置R {#conda-R}

在添加了不同的源之后，有些源更新快，有些更新慢，经常会碰到版本不一的问题。而且软件版本的优先级，低于源的优先级。保险期间，先做下搜索，获得合适的版本号，然后再选择安装。

```
conda search r-essentials

r-essentials                 1.0                    r3.2.1_0  r               
                             1.0                   r3.2.1_0a  r               
                             1.1                    r3.2.1_0  r               
                             1.1                    r3.2.2_0  r               
                             1.1                   r3.2.1_0a  r               
                             1.1                   r3.2.2_0a  r               
                             1.1                    r3.2.2_1  r               
                             1.1                   r3.2.2_1a  r               
                             1.4                           0  r               
                             1.4.1                  r3.3.1_0  r               
                             1.4.2                         0  r               
                             1.4.2                  r3.3.1_0  r               
                             1.4.3                  r3.3.1_0  r               
                             1.5.0                         0  r               
                             1.5.1                         0  r               
                             1.5.2                  r3.3.2_0  r               
                             1.5.2                  r3.4.1_0  r               
                             1.6.0                  r3.4.1_0  r               
                             1.0                    r3.2.1_0  defaults        
                             1.0                   r3.2.1_0a  defaults        
                             1.1                    r3.2.1_0  defaults        
                             1.1                    r3.2.2_0  defaults        
                             1.1                   r3.2.1_0a  defaults        
                             1.1                   r3.2.2_0a  defaults        
                             1.1                    r3.2.2_1  defaults        
                             1.1                   r3.2.2_1a  defaults        
                             1.4                           0  defaults        
                             1.4.1                  r3.3.1_0  defaults        
                             1.4.2                         0  defaults        
                             1.4.2                  r3.3.1_0  defaults        
                             1.4.3                  r3.3.1_0  defaults        
                             1.5.0                         0  defaults        
                             1.5.1                         0  defaults        
                             1.5.2                  r3.3.2_0  defaults        
                             1.5.2                  r3.4.1_0  defaults        
                             1.6.0                  r3.4.1_0  defaults        
                             1.5.2                  r3.3.2_0  conda-forge     
                             1.5.2                  r3.3.2_0  https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge 

```

从上面可以看到清华的源版本同步于`conda-forge`, 都比较老，还是指定`r`通道安装。

```
conda install -c r -n r r-essentials=1.6.0
```

`R`会安装于`conda_path/envs/r/bin`中，软链到位于环境变量的目录中即可正常使用。这就是环境变量的活学活用。


### Conda环境简化运行 {#conda_simple}

为了方便不同环境里面程序的运行，我写了一个shell脚本 (`conda_env_run.sh`)，具体运行如下：

```
# -c: 表示实际需要运行的命令
# -e: 表示需要启动的软件环境，也就是上面conda create建立的环境
# -b：一般不需要指定，如果conda没在环境变量中需要给出conda的安装路径
conda_env_run.sh -c  'ete3 -h mod' -e phylo

conda_env_run.sh -c  'bwa mem -h' -e aligner -b "/usr/local/anaconda2/bin"
```

`conda_env_run.sh`内容如下

```{bash eval=F}
#!/bin/bash

#set -x

usage()
{
cat <<EOF
${txtcyn}

***CREATED BY Chen Tong (chentong_biology@163.com)***

Usage:

$0 options${txtrst}

${bldblu}Function${txtrst}:

This is designed to run conda program in given environment. 
It will automatically activate the environment, run the program and 
deactivate the environment.

Thress commands from conda, 'activate', 'conda', 'deactivate' must 
be in PATH or you should spcify <-b> parameter.

${txtbld}OPTIONS${txtrst}:
	-c	Full command to be run ${bldred}[NECESSARY]${txtrst}
	-e	Environment name${bldred}[NECESSARY]${txtrst}
	-b	Conda path${bldred}[NECESSARY]${txtrst}
EOF
}

command_cmd=''
environment=''
conda_path=''

while getopts "hc:e:b:" OPTION
do
	case $OPTION in
		h)
			echo "Help mesage"
			usage
			exit 1
			;;
		c)
			command_cmd=$OPTARG
			;;
		e)
			environment=$OPTARG
			;;
		b)
			conda_path=$OPTARG
			;;
		?)
			usage
			echo "Unknown parameters"
			exit 1
			;;
	esac
done


if [ -z ${environment} ]; then
	echo 1>&2 "Please give command and environment."
	usage
	exit 1
fi

if ! [ -z ${conda_path} ]; then
	export PATH=${conda_path}:${PATH}
fi

source activate ${environment}
${command_cmd}
source deactivate ${environment}
```

### Conda环境备份 {#conda_bak}

有的时候会出现装一个新包，装着装着就把当前环境搞装崩了的情况，所以备份一个环境还是必要的，`conda create -n python35copy --clone python35`，把`python35`备份为`python35copy`。

### Conda环境导出和导入 {#conda_import}

做培训时需要给参加培训的老师提供配置环境的脚本，之前都是提供一个`Bash`文件全部运行下来就可以完成整个环境的配置，更简单的方式是可以导出环境，自己配置时再导入就好了。

```
# 假设我们有一个环境叫 ehbio，可以导出为一个yml文件
conda env export --file ehbio_env.yml --name ehbio

# 然后换一台电脑，就可以完全重现这个环境了
# 这么做的另一个优势是yml中明确列出了软件的版本，
# 使用 conda solving environment时速度会快很多
conda env create -f ehbio_env.yml
```

### Conda软件安装 core dump error/Segment fault/段错误 怎么办 {#cond_segment_fault}

```
# 清空缓存
# https://github.com/conda/conda/issues/7815
conda clean -a
```


### Conda为什么越来越慢？{#conda_slow}

Conda中包含的软件越来越多，而且软件的不同版本都保留了下来，软件的索引文件越来越大，安装一个新软件时搜索满足环境中所有软件依赖的软件的搜索空间也会越来越大，导致`solving environment`越来越慢。

### Conda是如何工作的 {#conda_how_work}

1. 从设定的通道 (`channel`)处下载通道中所有软件的索引信息 (`repodata.json`) (*Collecting package metadata (repodata.json)*)

   ~~~~~~~~~~~~~~~~~~~~~~~~
   "packages" : {
    "moto-1.3.7-py_0.tar.bz2" : {
      "build" : "py_0",
      "build_number" : 0,
      "depends" : [ "aws-xray-sdk !=0.96,>=0.93", "backports.tempfile", "boto >=2.36.0", "boto3 >=1.6.15", "botocore >=1.12.13", "cookies", "dicttoxml", "docker-py", "flask", "jinja2 >=2.7.3", "jsondiff 1.1.1.*", "mock", "pyaml", "python", "python-dateutil", "python-jose <3.0.0", "pytz", "requests >=2.5", "responses >=0.9.0", "six", "werkzeug", "xmltodict" ],
      "license" : "Apache-2.0",
      "md5" : "17b424658cd07e678b5feebdc932eb52",
      "name" : "moto",
      "sha256" : "5924666f8c1758472dc4c3d22b270b46cd1c4b66c50a9ba50d5c636d2237bdd1",
      "size" : 399973,
      "subdir" : "noarch",
      "timestamp" : 1552438392680,
      "version" : "1.3.7"
    }
  }
   ~~~~~~~~~~~~~~~~~~~~~~~~~~

2. 解析`repodata`中的信息获取所有依赖的包的信息
3. 采用`SAT-solver`算法决定需要下载包的哪个版本和它们的安装顺序
4. 下载并安装包

### Conda哪一步慢？ {#cond_which_step_slow}

主要是第`3`步，确定待安装包的依赖包之间的兼容和已安装软件之间的兼容，获得需要下载的包和对应版本。


### 如何提速Conda {#cond_accelarate}


* 采用最新版的`conda` (Conda4.7相比Conda4.6提速**3.5**倍, Conda 4.8应该不会比4.7慢)
* 安装时指定版本减少搜索空间 `conda install python=3.7.4`
* 安装R包时指定R的版本也会极大减小搜索空间 (R包因其数目众多，也是生物类软件依赖解析较慢的原因之一) `conda install r-base=4.0.2 r-ggplot2=3.3.2`
* 采用`mamba`加速软件依赖解析 [mamba采用`c++`重写了部分解析过程，这个提速效果是很明显的] (安装好`mamba`后就可以用`mamba`替换`conda`进行安装了)

  ~~~~~~~~~~~~~~~~~~~~~~~~~~~
  conda install mamba -c conda-forge
  mamba install python=3.7.4
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~

* ，默认conda解析软件依赖时优先考虑允许的最高版本，设置通道优先级权限高于软件版本新旧后，conda会能更快的解决依赖关系，避免`defaults`和`conda-forge`通道的奇怪组合导致软件依赖解析迟迟不能将结束的问题: `conda config --set channel_priority strict` (这个命令只需要运行一次)。
* 创建一个新环境 (`conda env create -n env_name`)再安装软件，这样就不用考虑与已有的软件的兼容问题了，也可以大大降低搜索空间和提高解析软件依赖的速度。
* 如果安装的软件提供了`environment.yaml`那么用起来，文件中对应的软件版本都很明确，解析依赖关系时更快。也可以按前面提供的方式导出一个已经配置好的环境的`yaml`文件，在其它电脑配置时直接读取。 (具体导出方式见[Bioconda软件安装神器：多版本并存、环境复制、环境导出](https://mp.weixin.qq.com/s/XZf652njPMg9qUTjcVCMgQ)。

  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
  channels:
   - qiime2/label/r2020.6
   - conda-forge
   - bioconda
   - defaults
  dependencies:
   - _libgcc_mutex=0.1
   - _openmp_mutex=4.5
   - _r-mutex=1.0.1
   - alsa-lib=1.1.5
   - arb-bio-tools=6.0.6
   - attrs=19.3.0
   - backcall=0.2.0
   - bibtexparser=1.1.0
   - binutils_impl_linux-64=2.34
   - binutils_linux-64=2.34
   - bioconductor-biobase=2.42.0
   - bioconductor-biocgenerics=0.28.0
   - bioconductor-biocparallel=1.16.6
   - bioconductor-biostrings=2.50.2
   - bioconductor-dada2=1.10.0
  ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

* 添加Bioconda通道时，注意顺序，给予`conda-forge`最高优先级，其次是`bioconda`。如果之前已经添加好了通道，自己在`~/.condarc`中调整顺序。

  ~~~~~~~~~~~~~~~~~~~~~~~
  conda config --add channels defaults
  conda config --add channels bioconda
  conda config --add channels conda-forge
  ~~~~~~~~~~~~~~~~~~~~~

* 综合以上组合，之前尝试多次都没安装好的工具，直接搞定。

### 下载提速 {#conda_downlaod_fast}

1. 国内镜像，见*[软件安装不上，可能是网速慢！Conda/R/pip/brew等国内镜像大全拿走不谢~~](https://mp.weixin.qq.com/s/eIw-k6RcR5KQFbrNmBsWBw)*
2. 换个网或从朋友处拷贝已经下载好的压缩包一般在`anaconda_root_dir/pkgs`下，拷贝放在自己的`anaconda3/pkgs`下面，再次下载时系统会识别已经下载好的包而跳过 (并不总是有效)。
3. 获取所有相关包的名字，从朋友处拷贝下载好的安装包，自己手动安装。

   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   mamba install r-base=4.0.2 r-ggplot2=3.3.2 --dry-run >package_solving_result
   
   
   # _anaconda_depends  pkgs/main/linux-64::_anaconda_depends-2020.07-py37_0
   # _r-mutex           conda-forge/noarch::_r-mutex-1.0.1-anacondar_1
   # binutils_impl_lin~ pkgs/main/linux-64::binutils_impl_linux-64-2.33.1-he6710b0_7
   # binutils_linux-64  conda-forge/linux-64::binutils_linux-64-2.33.1-h9595d00_17
   # brotlipy           conda-forge/linux-64::brotlipy-0.7.0-py37h516909a_1000
   # bwidget            conda-forge/linux-64::bwidget-1.9.14-0
   # gcc_impl_linux-64  pkgs/main/linux-64::gcc_impl_linux-64-7.3.0-habb00fd_1
   # gcc_linux-64       conda-forge/linux-64::gcc_linux-64-7.3.0-h553295d_17
   
   # 获取所有包的名字
   grep '::' a | sed 's/.*:://' | sed 's/$/.tar.bz2/'
   
   # 手动安装
   for i in `grep '::' a | sed 's/.*:://' | sed 's/$/.tar.bz2/'`; do conda install --offline /anaconda3/pkgs/$i; done
   ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
   
4. 如果拷贝过来未能自动识别，可手动安装 `conda install --offline local_path`。

### 使用conda-pack直接从已经安装好的地方拷贝一份 (同一操作系统) {#conda_pack}

安装`conda-pack`

```
conda install -c conda-forge conda-pack
# pip install git+https://github.com/conda/conda-pack.git
```

打包已经安装好的环境

```
conda pack -n my_env_name -o my_env_name.tar.gz
```

拷贝打包好的环境`my_env_name.tar.gz`到目标机器，并解压到任何目录，一般推荐放到`envs`目录下 `(anaconda_root/envs)`。(注意：*anaconda_root*改为自己的conda安装路径。)

```
# 解压打包好的环境
# 默认是全都解压到当前目录，场面很壮观
# -C 一定要指定
mkdir -p anaconda_root/envs/my_env
tar -xzf my_env.tar.gz -C anaconda_root/envs/my_env

# 激活环境
source my_env/bin/activate

# Unpack
conda-unpack

# 至此环境就完全拷贝过来了

# 去激活
source deactivate
```


## Docker安装 {#docker}

### Docker能做什么 {#docker_what}

The key benefit of Docker is that it allows users to package an
application with all of its dependencies into a standardized unit for
software development. 

* 提供一个虚拟的操作平台，供我们安装依赖不同版本系统的工具软件。

* 提供一个即时可用的应用软件或者流程的镜像，开发者把软件部署到系统镜像中，
  使用者可以直接下载下来使用，省去了个人安装软件的烦恼。

* 提供一个系统资源分配手段，给不同用户的程序分配独立的计算资源。


### Docker的几个基本概念 {#docker_basic}

* 镜像 (Images): 可以认为是超级轻量级的虚拟机的快照。
  镜像会有自己的唯一ID，名字和标签，比如`ubuntu:latest`, `django:1.6`等。
  通常都是在已有的镜像（多数是Linux操作系统的镜像）的基础上构建自己的
  具有新功能的镜像。

* 容器 (Containers): 可以认为是超级轻量级的虚拟机，
  是镜像运行起来所处的可读写的状态。
  容器里面可以安装、运行程序，还可以把安装好的程序存储起来获得新的镜像。
  
  与虚拟机很大的不同在于，一个容器通常只运行一个程序。在Docker中，
  应用程序和数据文件是分开的，因此可以在不影响数据的情况下快速升级代码
  或系统。

* 数据卷 (Volumes): 永久保存数据的磁盘空间。
  Docker允许用户定义哪一部分是应用程序，哪一步分是数据，并且把他们分隔开。
  这就保证了在Docker中容器的生命周期是短暂的，而数据的存储是永恒的。
  
  数据卷存储在运行Docker的宿主机上，对每个容器来说是特有的。
  我们可以启动同一个镜像来产生多个容器，并且分别给他们分配一个数据卷。

  数据卷也可用于在不同的容器间共享数据。
  具体参见<http://blog.genesino.com//2016/09/docker-lamp/>

* 联通 (Links): 容器启动后会分配有一个私有IP，其它容器可以通过这个IP地
  址与这个容器通讯。

  假如有个正在运行的数据库容器 (dbapp)，
  那么我们可以在网络服务器容器 (webserver)中通过指定端口连接dbapp与数据库容器通讯。


### 安装和配置 {#docker_install}

* Centos 6.5 安装Docker

  ```{bash eval=F}

  #添加epel的源
  su -c 'rpm -Uvh  http://download.fedoraproject.org/pub/epel/6/i386/epel-release-6-8.noarch.rpm'
  yum update

  # 安装Docker
  yum install docker-io

  # 启动Docker服务
  service docker start
  # 关闭Docker服务
  service docker stop

  # 设置Docker开机启动
  /sbin/chkconfig --add docker
  /sbin/chkconfig docker on
  ```

* 其他新版操作系统的安装可以直接使用系统自带的`yum`或`apt`工具，
  启动和配置如上。

  ```{bash eval=F}
  apt-get install docker.io
  ```

### Docker用户权限 {#docker_priviledges}

默认情况下，Docker命令的运行需要根用户权限。一个解决办法是把用户加入
`docker`用户组，原因是Docker能够将`/run/docker.socket`的文件权限设为
`660`、用户组设为`docker`。当把用户加入到`docker`用户组后，就无需使用
`sudo`或`su`命令切换获取根用户权限。[check here](https://docs.docker.com/engine/installation/linux/ubuntulinux/#create-a-docker-group)

```{bash eval=F}
###以下操作都是在根用户下进行的

###增加一个用户组docker
# groupadd docker
###把用户${USER}加入docker用户组
# usermod -aG docker ${USER}
###重启docker服务(可不执行)
# service docker restart
###新窗口登录${USER}
```

但通常只应把信任的用户加入docker用户组因为docker用户组的权限相当于root。

如果打算只允许用户访问一个特定的容器，可以写一个简单脚本

```{bash eval=F}
# cat /bin/docker_container1
#!/bin/sh
docker run -ti --rm container_name /bin/sh
```

脚本完成后，配置sudoers

```{bash eval=F}
# grep username /etc/sudoers
username   ALL=(ALL)  NOPASSWD: /bin/docker_container1
```

更多权限设置见<http://dockone.io/article/589>


### Docker试用 {#docker_try}

* 查看本地Docker的信息 `docker info`
* 运行Docker需要有一个镜像和容器。镜像是容器的只读版本，
  最基础的镜像是一个操作系统，是运行其他命令的基础。
  因此我们需要先获取一个操作系统镜像，通常使用Ubuntu系统, CentOS系统和
  Alpine (只有5M)。
  我们也可以根据所要运行软件的需要，来获取不同的操作系统，
  方便软件的安装。
* 搜索镜像 `docker search ubuntu`; 镜像的名字通常由`用户名/镜像名`构成,
  无用户名的为官方认证镜像。	

```{bash eval=F}
root@server:~# docker search ubuntu
NAME              DESCRIPTION      STARS     OFFICIAL   AUTOMATED
ubuntu            Ubuntu is ...    4595      [OK]       
ubuntu-upstart    Upstart is...     66       [OK]
jordi/ubuntu      Ubuntu bas...     1                    [OK] 
```

* 获取镜像 
  * `docker pull ubuntu` 获取镜像的最新版本(不指定版本号即为latest)
  * `docker pull ubuntu:14.04` 获取指定版本的镜像；14.04为镜像的版本号(又称`TAG`)。

* 查看本机Docker中存在的镜像 `docker images`
  
```
REPOSITORY   TAG      IMAGE ID       CREATED      VIRTUAL SIZE
ubuntu       latest   37b164bb431e   4 days ago   126.6 MB
```

* 获得了镜像之后，我们需要运行镜像；运行起来的镜像就是容器，是可读写的。
  我们可以在容器中安装软件、运行命令，就如在正常的操作系统中一样。
  
  在容器中运行单个命令或程序, 通常加`--rm`参数，容器运行结束之后就自动
  删除。如果我们想保留容器的修改，则不能加`--rm`参数。

```{bash eval=F}
docker run --rm ubuntu echo "Hello from docker"
Hello from docker
```

  交互式运行容器 `docker run -it ubuntu`, 这时可以发现终端的用户名变了
  
```{bash eval=F}
root@server:~# docker run -it ubuntu
root@57cb695e904f:/# ls
bin   dev  home  lib64  mnt  proc  run   srv  tmp  var
boot  etc  lib   media  opt  root  sbin  sys  usr
root@57cb695e904f:/# 
```
  
  `docker run --help`可以查看这个命令的参数。

* 在容器中部署软件，安装`build-essential`和`r-base`; 
  *build-essential* 是编译软件包的基础，提供需要的编译器、头文件和库文件。
  *r-base* 是编译R语言程序包的基础。

```{bash eval=F}
apt-get update
#apt-get install -y build-essential r-base
apt-get install toliet
```

  这一步我们可以安装任意的软件，测试时可以选择小一点的软件包。
  最开始时选择了安装`build-essential`, 只是为了学习，
  到后来发现安装这个并没有什么用，也不方便测试。为了简单起见，
  可以尝试安装`Apache`。在本文后面有个简单的测试`Apache`安装的例子。

* 运行` docker commit -m 'Add build-essential r-base' -a ct5869 8aca49b869be ct5869/ubuntu-dev:v1''`。

* 测试运行新的镜像 `docker run --rm -it username/ubuntu-dev:v1`。

* 挂载宿主机硬盘在容器内部操作, 通过`-v`参数，路径都为绝对路径，
  `docker run --rm -v /host_absolute_dir:/container_absolute_dir
  username/ubuntu-dev:v1 echo 'test' >/container_absolute_dir/test_file`
  这样，就相当于把host机目录`/host_absolute_dir`链接为docker容器路径
  `/container_absolute_dir`。

* 如果只是自己用，到现在就可以结束了，我们可以在镜像里面继续更多的操作了。

* 另外我们还可以运用`导出`和`导入`来迁移镜像
	* 导出镜像：`docker export image_id >ubuntu-dev.v1.tar`
	* 导入镜像：`cat ubuntu-dev.v1.tar | docker import - username/ubuntu-dev:v1 `

* 如果我们想把镜像分发给别人使用，就需要把镜像传到镜像仓库比如Docker Hub。
  我们需要现在[Docker hub](https://hub.docker.com)注册，
  用注册的用户名替换掉前文提到的`username`。

* 注册成功之后，在本地服务器尝试登录，用以把登录信息存储在本地，方便后续使用。
  运行`docker login`，按提示输入用户名、密码和邮件。登录成功会返回
  `Login Succeeded`.

* 运行`docker push username/ubuntu-dev:v1`把准备好的镜像上传；
  等待片刻，完成上传。这时就可以再Docker hub上看到上传的镜像了。

* 其它用户可以使用 `docker pull username/ubuntu-dev:v1`来获取安装好编
  译环境的ubuntu系统了。
  
### Docker系统基本操作 {#docker_basic_operation}

* 当一个容器不再使用时，运行`docker rm container_id`移除容器，以节省空间。
  这不会对镜像造成影响。

* 当一个容器不再使用时，运行`docker rm -v container_id`移除容器及其挂载卷，
  以节省空间。这不会对镜像造成影响。

* 批量删除退出的容器`docker rm -v $(docker ps -a -q -f status=exited)`。

* 对于只需要单次运行的容器，比如执行一个命令等，则只需要在
  `docker run`时添加`--rm`参数就好。这样容器运行结束后会自动删除。

* 运行`docker rmi username/ubuntu-dev:v1`移除镜像。

* 运行`docker tag 26d99f722dca username/ubuntu-dev:v0`修改镜像的名字。

* 运行`docker run -d --name=container_name username/ubuntu-dev:v1`
  指定运行的container的名字。

* 运行`docker run --rm -ti -v /host_abs_dir:/container_abs_dir:ro
  username/ubuntu-dev:v1`挂载只读目录。

* 运行`docker stop containde_id/container_name`停止镜像。

* 运行`docker rm $(docker ps -a -q)`和`docker rmi $(docker images -q)`移除全部镜像。**BE CAREFULL**

* 查看Docker镜像的创建历史 `docker history image_name`

```
IMAGE          CREATED       CREATED BY SIZE                COMMENT
3d4f934accdb   7 months ago        /bin/sh -c #(nop) CMD ["/run.sh" ]               0 B                 
aa321fa8d23f   7 months ago        /bin/sh -c #(nop) EXPOSE  3306/tcp 80/tcp        0 B                 
6446fbfc507d   7 months ago        /bin/sh -c #(nop) VOLUME  [/etc/mysql /var/lib   0 B                 
44e98bdf2bbf   7 months ago        /bin/sh -c #(nop) ENV PHP_POST_MAX_SIZE=10M     0 B                 
bedff16caee9   7 months ago        /bin/sh -c #(nop) ENV  PHP_UPLOAD_MAX_FILESIZE   0 B                 
72b723ccc97f   7 months ago        /bin/sh -c mkdir -p /app && rm -fr /var/www/h   0 B
```

* 查看镜像的JSON文件 `docker inspect image_name`

* Docker images的安装路径为 `/var/lib/docker`。

  * `/var/lib/docker/{driver-name}` will contain the driver specific storage for contents of the images.
  * `/var/lib/docker/graph/<id>` now only contains metadata about the image,  in the json and layersize files.

* 查看Docker 容器启动和运行日志

```
docker logs --tail=all container_id
```

### 使用Dockerfile自动构建镜像 {#Dockerfile}

除了可以像上面那样一步步地获取镜像、修改容器、存储镜像、上传镜像等操作外，
我们还可以使用Dockerfile自动实现上述操作。

典型的Dockerfile如下所示，

```
FROM alpine
MAINTAINER username username@internet.com
RUN apk add --no-cache apache2 apache2-utils
COPY public_html /var/www/html
EXPOSE 80 443
CMD ["rc-service apache2 start"]
```

* `FROM`为除注释之外的第一条命令，用来声明镜像的基础系统。
* `MAINTAINER`设置镜像维护人的信息。
* `RUN`在容器内部运行shell命令。
* `COPY`是把本地的bash配置文件拷贝到新维护的镜像中；
  COPY的文件的路径是相对于docker build的PATH，一般是当前路径；
* `CMD`指定容易运行时默认执行的命令，如出现多个，只有最后一个会被运行。

运行命令`docker build -t="username/httpd-alpine:v1" .`就可以构建镜像了。
最后的`.`表示Dockerfile在当前目录，也可指定其他目录。`public_html`必须
与Dockerfile在同一目录。

### Docker的特征 {#docker_single_process}

* Docker will watch only one single process. 
  If you need multiple processes, 
  you need to add a monitor like [Monit](http://mmonit.com/monit/) or 
  [Supervisor](http://supervisord.org/) at the top-level to take
  care of the others. But this is not recommended.

### Docker使用注意 {#docker_attention}

* 避免安装不必要的软件包。

* 每个容器都只运行一个进程。

* 最小化层：每执行一个命令，都会产生一个层。

## Makefile知识 {#makefile}

Makefile通常的格式和布局如下，有兴趣的可以自己去学，或者我们再出一个教程。

```make
# 假设当前文件夹下Makefile文件中内容如下 
ct@ehbio:~$ cat Makefile
# first: target名字
# echo "compile first": target对应的命令，任何Linux命令都可以
first:
echo "compile first"
all: first second
echo "compile all"
second:
echo "compile second"

# 直接运行make，会make第一个出现的target
ct@ehbio:~$ make
echo "compile first"
compile first
# make first与直接make相同，因为它出现在第一个 
ct@ehbio:~$ make first
echo "compile first"
compile first
# all依赖于first, second，因此make all会先执行make first, make second
# 然后才是自己所代表的命令 
ct@ehbio:~$ make all
echo "compile first"
compile first
echo "compile second"
compile second
echo "compile all"
compile all
```

### 参考 {#docker_ref}

* 入门级 <http://blog.saymagic.cn/2015/06/01/learning-docker.html>

* 入门级 <https://www.dwhd.org/20151115_140935.html>

* 入门级 <http://www.cnblogs.com/kevinX/p/5458244.html>

* Start (english version) <https://scotch.io/tutorials/getting-started-with-docker>

* Start (english version) <https://prakhar.me/docker-curriculum/>

* Greate english version <https://blog.talpor.com/2015/01/docker-beginners-tutorial/>

* Docker trick <https://blog.docker.com/2014/06/why-you-dont-need-to-run-sshd-in-docker/>

* Docker root and non-root <http://www.2cto.com/os/201508/432930.html>

## References

* [https://samrelton.wordpress.com/2015/07/02/rconda/](https://samrelton.wordpress.com/2015/07/02/rconda/)
* [https://www.anaconda.com/blog/developer-blog/anaconda-r-users-sparkr-and-rbokeh/](https://www.anaconda.com/blog/developer-blog/anaconda-r-users-sparkr-and-rbokeh/)
* [http://www.bioinfo-scrounger.com/archives/209](http://www.bioinfo-scrounger.com/archives/209)
* [清华大学开源镜像站](https://mirror.tuna.tsinghua.edu.cn/help/anaconda/)
* [Linux学习 - 又双叒叕一个软件安装方法](http://mp.weixin.qq.com/s/A4_j8ZbyprMr1TT_wgisQQ)
* [Linux - 命令运行监测和软件安装](http://mp.weixin.qq.com/s/TNU7X2mhfVVffaJ7NRBuNA)
* [Linux - 应用Docker安装软件](http://mp.weixin.qq.com/s/HLHiWMLaWtB7SOJe_jP3mA)
* [Linux - Conda软件安装方法](http://mp.weixin.qq.com/s/A4_j8ZbyprMr1TT_wgisQQ)
* [Nature Method：Bioconda解决生物软件安装的烦恼](https://mp.weixin.qq.com/s/VeexRyguwozqrMaOeeMF7Q)
* [手把手教你生信分析平台搭建](https://mp.weixin.qq.com/s/6BPvNOw854pkdJCklelGWQ)
* [Windows轻松实现linux shell环境：gitforwindows](https://mp.weixin.qq.com/s/KtM4c4o4iLfD4ZkEnMi1pg)
* [Bioconda软件安装神器：多版本并存、环境复制、环境导出](https://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&mid=2247489108&idx=1&sn=0d0ec3dc931271a509fed07cb0efcfd7&scene=21#wechat_redirect)
* [软件安装不上，可能是网速慢！Conda/R/pip/brew等国内镜像大全拿走不谢~~ ](https://mp.weixin.qq.com/s/eIw-k6RcR5KQFbrNmBsWBw)


<!--chapter:end:02.SoftInstall.Rmd-->

# Linux神器 {#LinuxGreatTools}

视频课见 <http://bioinfo.ke.qq.com>。

## 正则表达式替换文本随心所欲 {#regularExpr}

正则表达式 (regular expression)是用来做模糊匹配的，匹配符合特定模式的文本。最早来源于Unix系统中的`sed`和`grep`命令，在各个程序语言，如`perl`, `python`中也都有实现。不同程序语言中正则表达式语法大体通用，细节上又各自有自己的特色。

```{r, fig.cap="正则表达式基本语法"}
url = "http://www.ehbio.com/ehbio_resource/pyre.png"
if(!file.exists(pic_file <- "pyre.png")){
  download.file(url, pic_file, mode="wb")
}
knitr::include_graphics(if(identical(knitr:::pandoc_to(),'html')) url else pic_file)
```

```bash
# 假如有这么一个测试文件
ct@ehbio: ~/$ cat <<END >url.list
http://www.ehbio.com/ImageGP
http://www.ehbio.com/Training
http://www.ehbio.com/Esx
www.ehbio.com
http://www.ehbio.com/ImageGP/index.php/Home/Index/Lineplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/GOenrichmentplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/PHeatmap.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Volcanoplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Manhattanplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Histogram.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/VennDiagram.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/UpsetView.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Densityplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/PCAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/PCoAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/CPCoAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Sankey.html
http://blog.genesino.com
https://blog.csdn.net/qazplm12_3/
https://blog.csdn.net/woodcorpse/
blog.csdn.net/woodcorpse/article/details/79313846

ImageGP is one of the Best online plot.
123456789
END
```

获取以`https`开头的行

```
ct@ehbio: ~/$ grep '^https' url.list
https://blog.csdn.net/qazplm12_3/
https://blog.csdn.net/woodcorpse/
```

获取包含数字的行

```
ct@ehbio:~/$ grep '[0-9]' url.list 
https://blog.csdn.net/qazplm12_3/
blog.csdn.net/woodcorpse/article/details/79313846
123456789
```

获取空行

```
ct@ehbio:~/$ grep '^$' url.list 

```

获取`html`结尾的行

```
ct@ehbio:~/$ grep 'html$' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/Lineplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/GOenrichmentplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/PHeatmap.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Volcanoplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Manhattanplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Histogram.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/VennDiagram.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/UpsetView.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Densityplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/PCAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/PCoAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/CPCoAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Sankey.html
```

获取`Boxplot`和`Barplot`的地址

```
# 未能满足要求
ct@ehbio:~/$ grep 'B.*plot' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html
ImageGP is one of the Best online plot.

# 一个办法：更长的匹配
ct@ehbio:~/$ grep 'B.*plot.html' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html

# 限定中间不能有空格
ct@ehbio:~/$ grep 'B[^ ]*plot' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html

# 限定中间只能有2个字符
ct@ehbio:~/$ grep 'B..plot' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html

# 2个字符的另外一种写法
ct@ehbio:~/$ grep -P 'B.{2}plot' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html

# 2个字符的再一种写法，只允许出现特定字符
ct@ehbio:~/$ grep -P 'B[arox]*plot' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/Boxplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/Barplot.html
```

获取PCA或PCoA相关的行

```
ct@ehbio:~/$ grep 'PCo*A' url.list 
http://www.ehbio.com/ImageGP/index.php/Home/Index/PCAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/PCoAplot.html
http://www.ehbio.com/ImageGP/index.php/Home/Index/CPCoAplot.html
```


## awk-生信分析不可缺少 {#awk}

前面的学习过程中已经提到了`awk`和`sed`的使用，作为一个引子。现在则详细列举关于`awk`常用的操作和一些偏门的操作。

### awk基本参数解释 {#awk_explain}

awk擅长于对文件按行操作，每次读取一行，然后进行相应的操作。

awk读取单个文件时的基本语法格式是`awk 'BEGIN{OFS=FS="\t"}{print $0, $1;}' filename`。

读取多个文件时的语法是`awk 'BEGIN{OFS=FS="\t"}ARGIND==1{print $0, $1;}ARGIND==2{print $0;}' file1 file2`。

awk后面的命令部分是用引号括起来的，可以单引号，可以双引号，但注意不能与内部命令中用到的引号相同，否则会导致最相邻的引号视为一组，引发解释错误。**引号不可以嵌套**

* `OFS`: 文件输出时的列分隔符 (output field separtor)

* `FS`: 文件输入时的列分隔符 (field separtor)

* `BEGIN`: 设置初始参数，初始化变量

* `END`: 读完文件后做最终的处理

* 其它`{}`：循环读取文件的每一行

* `$0`表示一行内容；`$1`, `$2`, ... `$NF`表示第一列，第二列到最后一列。

* `NF (number of fields)`文件多少列；`NR (number of rows)` 文件读了多少行: `FNR` 当前文件读了多少行，常用于多文件操作时。

* `a[$1]=1`: 索引操作，类似于python中的字典，在`ID map`，`统计`中有很多应用。

### awk基本常见操作 {#awk_common_op}

* 针对特定列的计算，比如wig文件的标准化

```bash
# 注意除了第一行是空格，其它行都是tab键分割
ct@ehbio:~/sxbd$ cat <<END >ehbio.wig
variableStep chrom=chr2
300701	12
300702	10
300703	11
300704	13
300705	12.5
END

ct@localhost:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}\
	{if(FNR>1) $2=$2*10^6/(2.5*10^6); print $0}' ehbio.wig
variableStep chrom=chr2
300701	4.8
300702	4
300703	4.4
300704	5.2
300705	5
```

* 计算某列内容出现的次数。

```bash
# 怎么获得count文件，应该不难吧
ct@ehbio:~/sxbd$ cat count 
ID	Type
Pou5f1	Pluripotency
Nanog	Pluripotency
Sox2	Neuron
Tet1	Epigenetic
Tet3	Epigenetic
Myc	Oncogene

ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}{if(FNR>1) a[$2]+=1;}END\
	{print "Type\tCount"; for(i in a) print i,a[i];}' count
Type	Count
Neuron	1
Epigenetic	2
Oncogene	1
Pluripotency	2

# 这个也可以用下面方式代替，但不直接
ct@ehbio:~/sxbd$ tail -n +2 count | cut -f 2 | sort | uniq -c | \
		sed -e 's/^  *//' -e 's/  */\t/' 
2	Epigenetic
1	Neuron
1	Oncogene
2	Pluripotency
```

* 之前也提到过的[列操作](http://mp.weixin.qq.com/s/rZ26i19hiS5ZOqIoqkL1Wg)，从GTF文件中提取启动子区域

GRCh38.gtf可以从<ftp://ftp.ensembl.org/pub/release-91/gtf/homo_sapiens/Homo_sapiens.GRCh38.91.gtf.gz>下载，或使用提供的测试文件。


```bash
ct@ehbio:~/sxbd$ sed 's/"/\t/g' GRCh38.gtf | \
	awk 'BEGIN{OFS=FS="\t"}{if($3=="gene") {ensn=$10; symbol=$16; \
		if($7=="+") {start=$4-1; up=start-1000; if(up<0) up=0; dw=start+500; \
		print $1,up, dw, ensn, symbol, $7;} else \
		if($7=="-") {start=$5-1; up=start+1000; dw=start-500; \
		if(dw<0) dw=0; print $1,dw,up,ensn,symbol,$7}}}' | sort -k1,1 -k2,2n \
		>GRCh38.promoter.bed
```

* 数据矩阵的格式化输出

```bash
ct@ehbio:~/sxbd$ cat numeric.matrix 
ID	A	B	C
a	1.002	1.234	1.999
b	2.333	4.232	0.889

ct@ehbio:~/sxbd$ awk '{if(FNR==1) print $0; \
	else {printf "%s%s",$1,FS; for (i=2; i<=NF; i++) \
		printf "%.1f %s", $i, (i==NF?RS:FS)}}' numeric.matrix 
ID	A	B	C
a 1.0  1.2  2.0 
b 2.3  4.2  0.9 
```

* 判断FASTQ文件中，输出质量值的长度是与序列长度不一致的序列ID

```bash
ct@ehbio:~/sxbd$ cat <<END | gzip -c >Test_2.fq.gz
>ehbio1
ACGTCGACGACGAGAGGAGAGGAGCCCTCTCGCCCGCCCTACTACCACCCACACACAACACAAGTGT
+
FFFFFFA$A#$$AFEEEEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>ehbio2
ACGTCGACGACGAGAGGAGAGGAGCCCTCTCGCCCGCCCTACTACCACCCACACACAACACAAGTGT
+
FFFFFF$A#$$AFEEEEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
>ehbio3
ACGTCGACGACGAGAGGAGAGGAGCCTCTCGCCCGCCCTACTACCACCCACACACAACACAAGTGT
+
FFFFFFA$A#$$AFEEEEFFFFFFFFEFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF
END
```

```bash
ct@ehbio:~/sxbd$ zcat Test_2.fq.gz | \
	awk '{if(FNR%4==1) ID=$0; else if(FNR%4==2) seq_len=length($0); \
		else if(FNR%4==0) {quality_len=length($0); if(seq_len!=quality_len) print ID; }}' 
```

* 筛选差异基因

```bash
# TAB键分割的文件
ct@ehbio:~/sxbd$ cat de_gene
ID	log2fc	padj
A	1	0.001
B	-1	0.001
C	1	0.001
D	2	0.0001
E	-0.51	0.051
F	0.1	0.1
G	1	0.1

ct@ehbio:~/sxbd$ awk '$3<0.05 || NR==1' de_gene 
ID	log2fc	padj
A	1	0.001
B	-1	0.001
C	1	0.001
D	2	0.0001

ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}{if(FNR==1) print $0; \
	else {abs_log2fc=($2<0?$2*(-1):$2);if(abs_log2fc>=1 && $3<0.05) print $0;}}' de_gene 
ID	log2fc	padj
A	1	0.001
B	-1	0.001
C	1	0.001
D	2	0.0001
```

* 筛选差异基因存储到不同的文件

```bash
ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"; up="up"; dw="dw";}\
	{if(FNR==1) {print $0 >up; print $0 >dw;} else \
	if ($3<0.05) {if ($2>=1) print $0 >up; else if($2<=-1) print $0 >dw;}}' de_gene 

ct@ehbio:~/sxbd$ head up dw
==> up <==
ID	log2fc	padj
A	1	0.001
C	1	0.001
D	2	0.0001

==> dw <==
ID	log2fc	padj
B	-1	0.001
```

* 筛选差异基因存储到不同的文件(自动版)

```bash
awk 'BEGIN{OFS=FS="\t"; up=ARGV[1]".up"; dw=ARGV[1]".dw";}\
	{if(FNR==1) {print $0 >up; print $0 >dw;} \
	else if ($3<=0.05) {if($2<=-1) print $0 >up; else if ($2>=1) print $0 >dw;}}' de_gene
```

* ID map，常用于转换序列的ID、提取信息、合并信息等

```bash
# TAB键分割的文件
ct@ehbio:~/sxbd$ cat id_map 
ENSM	Symbol	Entrez
ENSG00000280516	TMEM42	693149
ENSG00000281886	TGM4	7047
ENSG00000280873	DGKD	8527
ENSG00000281244	ADAMTS13	11093
ENSG00000280701	RP11-272D20.2	
ENSG00000280674	ZDHHC3	51304
ENSG00000281623	Y_RNA	
ENSG00000280479	CACFD1	11094
ENSG00000281165	SLC2A6	11182
ENSG00000281879	ABO	28
ENSG00000282873	BCL7A	605
ENSG00000280651	AC156455.1	100506691
ct@ehbio:~/sxbd$ vim ensm
ct@ehbio:~/sxbd$ cat ensm 
ENSG00000281244
ENSG00000281165
ENSG00000282873

ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}ARGIND==1{if(FNR>1) ensm2entrez[$1]=$3;}\
		ARGIND==2{print ensm2entrez[$1];}' id_map ensm
11093
11182
605

# 替代解决方案，注意 -w的使用，避免部分匹配。最稳妥的方式还是使用awk。

ct@ehbio:~/sxbd$ grep -w -f ensm id_map | cut -f 3
11093
11182
605
```

* 转换大小写, `toupper`, `tolower`

```bash
ct@ehbio:~/sxbd$ cat symbol 
Tgm4
Dgkd
Abo

ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}ARGIND==1{if(FNR>1) ensm2entrez[$2]=$3;}\
		ARGIND==2{print ensm2entrez[toupper($1)];}' id_map symbol 
7047
8527
28
```

* awk数值操作

```bash
ct@ehbio:~/sxbd$ cat <<END >file
2
4
3.1
4.5
5.4
7.6
8
END

# log2对数
ct@ehbio:~/sxbd$ awk 'BEGIN{OFS="\t";FS="\t"}{print log($0)/log(2)}' file

# 取整,四舍五入
ct@ehbio:~/sxbd$ awk 'BEGIN{OFS="\t";FS="\t"}{print int($1+0.5);}' file
```

* awk定义函数

```bash
ct@ehbio:~/sxbd$ cat <<END | sed 's/  */\t/g'>file
1	2	3	4
5	6	7	8
9	10	11	12
END
```

```bash
ct@ehbio:~/sxbd$ awk 'function abs(x){return ((x < 0.0) ? -x : x)}BEGIN{OFS="\t";FS="\t"}\
	{pos[1]=$1;pos[2]=$2;pos[3]=$3;pos[4]=$4; len=asort(pos); \
	for(i=len;i>1;i--) print abs(pos[i]-pos[i-1]);}' file
```

* 字符串匹配

```bash
# TAB键分割的文件
ct@ehbio:~/sxbd$ cat ens.bed
1	100	105
2	100	105
3	100	105
Mt	100	105
X	100	105

ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}{if($1~/^[0-9XY]/) $1="chr"$1; else \
	if($1~/M.*/) gsub(/M.*/, "chrM", $1); print $0}' ens.bed 
chr1	100	105
chr2	100	105
chr3	100	105
chrM	100	105
chrX	100	105
```

* 字符串分割

```bash
ct@ehbio:~/sxbd$ cat trinity_id
Trinity_C1_g1_i1
Trinity_C1_g1_i2
Trinity_C1_g1_i3
Trinity_C2_g1_i1
Trinity_C3_g1_i1
Trinity_C3_g3_i2
ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}{count=split($1, geneL, "_"); gene=geneL[1]; \
	for(i=2;i<count;i++) gene=gene"_"geneL[i]; print gene,$1;}' trinity_id 
Trinity_C1_g1	Trinity_C1_g1_i1
Trinity_C1_g1	Trinity_C1_g1_i2
Trinity_C1_g1	Trinity_C1_g1_i3
Trinity_C2_g1	Trinity_C2_g1_i1
Trinity_C3_g1	Trinity_C3_g1_i1
Trinity_C3_g3	Trinity_C3_g3_i2
```

* awk脚本

```bash

ct@ehbio:~/sxbd$ cat <<END >grade.awk
BEGIN{OFS=FS="\t"; up=ARGV[1]".up"; dw=ARGV[1]".dw";}
	{if(FNR==1) {print $0 >up; print $0 >dw;} 
				 else if ($3<=0.05) {
						 if($2<=-1) print $0 >up; 
						 else if ($2>=1) print $0 >dw;}
	}
END

ct@ehbio:~/sxbd$ awk -f grade.awk de_gene
```

* awk给每行增加行号，使其变为唯一

```bash
ct@ehbio:~/sxbd$ awk 'BEGIN{OFS="\t";FS="\t"}NR!=1{$4=$4"_"NR;print $0}' file
```

### awk糅合操作 - 命令组合体现魅力 {#awk_combine}

* awk中执行系统命令 (注意引号的使用)

```bash
# input_mat
ct@ehbio:~/sxbd$ cat <<END | sed 's/  */\t/g' >input_mat
SRR1	root
SRR2	leaf
SRR3	stem
END

ct@ehbio:~/sxbd$ touch SRR1.fq SRR2.fq SRR3.fq

ct@ehbio:~/sxbd$ ls
SRR1.fq SRR2.fq SRR3.fq 

# 系统命令组成字符串，交给system函数运行
ct@ehbio:~/sxbd$ awk 'BEGIN{OFS=FS="\t"}{system("mv "$1".fq "$2".fq");}' input_mat

# 
ct@ehbio:~/sxbd$ ls
leaf.fq root.fq stem.fq
```

* awk 引用系统变量

```bash
ct@ehbio:~/sxbd$ echo 1 | awk -v ehbio="shengxinbaodian" \
						-v ehbio2="sxbd" '{print ehbio, ehbio2;}'
shengxinbaodian sxbd
```


## SED命令 - 文本替换舍我其谁 {#sed}

### sed基本参数解释 {#sed_basic}

sed是`stream editor`的简称，擅长对文件进行各种正则操作、插入操作、替换操作和删除操作，可以全局，可以指定特定范围的行或者特定特征的行。

`s/pat/replace/`: 正则替换

前插行`i`, 后插行`a`, 替换行`c`, 删除行`d`, 输出行`p`

`N`: 读入下一行，同时存储；`n`:读入下一行，抛弃当前行

### 常见操作 {#sed_common}

* 替换特定的文本

```bash
# 空格是我们不太喜欢出现在文件中的一个符号，尤其是作为列名字时
# 列使用TAB键分割
ct@ehbio:~/sxbd$ cat <<END | sed 's/;/\t/g' mat
ID;2 cell;4 cell;8 cell;embryo
Pou5f1_1;2;3;4;5
Nanog_1;2;3.2;4.3;5
c-Myc;2;3;4;5
Tet1_3;2;3;4;5
END

# 一次替换
ct@ehbio:~/sxbd$ sed 's/ /_/' mat 
ID	2_cell	4 cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1_3	2	3	4	5

# 全部替换
ct@ehbio:~/sxbd$ sed 's/ /_/g' mat 
ID	2_cell	4_cell	8_cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1_3	2	3	4	5
```

* 获得逗号分隔的一组数

```bash
ct@ehbio:~/sxbd$ echo `seq 1 10` | sed 's/ /,/g'
1,2,3,4,5,6,7,8,9,10
```

* 针对指定行替换

```bash
ct@ehbio:~/sxbd$ sed '2,$ s/_[0-9]//g' mat 
ID	2 cell	4 cell	8 cell	embryo
Pou5f1	2	3	4	5
Nanog	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1	2	3	4	5
```

* 替换特定出现位置

```bash
# 替换第一个空格
ct@ehbio:~/sxbd$ sed 's/ /_/1' mat 
ID	2_cell	4 cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1_3	2	3	4	5
# 替换第二个空格
ct@ehbio:~/sxbd$ sed 's/ /_/2' mat 
ID	2 cell	4_cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1_3	2	3	4	5
# 替换第二个及以后的空格
ct@ehbio:~/sxbd$ sed 's/ /_/2g' mat 
ID	2 cell	4_cell	8_cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1_3	2	3	4	5
```

* 给序列起名字

```bash
ct@ehbio:~/sxbd$ cat seq
ACDGTFGGCATGCDTGD
ACDGAGCDTAGCDGTA
CAGDTAGDCTADTG
ct@ehbio:~/sxbd$ sed = seq
1
ACDGTFGGCATGCDTGD
2
ACDGAGCDTAGCDGTA
3
CAGDTAGDCTADTG
# 同时缓冲两行，但只对第一行行首操作
ct@ehbio:~/sxbd$ sed = seq | sed 'N;s/^/>/;'
>1
ACDGTFGGCATGCDTGD
>2
ACDGAGCDTAGCDGTA
>3
CAGDTAGDCTADTG
```

* 给文件增加标题行

```bash
ct@ehbio:~/sxbd$ tail -n +2 mat | sort -k2,2n
c-Myc	2	3	4	5
Nanog_1	2	3.2	4.3	5
Pou5f1_1	2	3	4	5
Tet1_3	2	3	4	5

# 1 表示第一行
# i 表示插入，在指定行前面插入新行
ct@ehbio:~/sxbd$ tail -n +2 mat | sort -k2,2n | sed '1 i ID\t2_cell\t4_cell\t8_cell\tembryo'
ID	2_cell	4_cell	8_cell	embryo
c-Myc	2	3	4	5
Nanog_1	2	3.2	4.3	5
Pou5f1_1	2	3	4	5
Tet1_3	2	3	4	5
```

* 提取特定或指定范围的行

```bash
# -n是必须的，阻止程序自动输出匹配行，不然会导致重复输出
ct@ehbio:~/sxbd$ sed -n '2,4p' mat
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5

ct@ehbio:~/sxbd$ sed -n '4p' mat
c-Myc	2	3	4	5
```

* 提取符合特定模式的行

  `/pattern/`支持普通字符串和正则表达式匹配

```bash
ct@ehbio:~/sxbd$ sed -n '/_/ p' mat
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
Tet1_3	2	3	4	5

ct@ehbio:~/sxbd$ sed -n '/-/ p' mat
c-Myc	2	3	4	5
```

* 去除文件中的空行

```bash
ct@ehbio:~/sxbd$ cat mat
ID	2 cell	4 cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5

c-Myc	2	3	4	5
Tet1_3	2	3	4	5


# 空行就是只有行首和行尾的行
ct@ehbio:~/sxbd$ sed '/^$/d' mat 
ID	2 cell	4 cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1_3	2	3	4	5
```

* 原位删除

```bash
ct@ehbio:~/sxbd$ cat mat
ID	2 cell	4 cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5

c-Myc	2	3	4	5
Tet1_3	2	3	4	5

# -i 参数的使用
ct@ehbio:~/sxbd$ sed -i '/^$/d' mat 
ct@ehbio:~/sxbd$ cat mat
ID	2 cell	4 cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc	2	3	4	5
Tet1_3	2	3	4	5
```

* 删除指定范围的行

```bash
ct@ehbio:~/sxbd$ cat mat
ID	2 cell	4 cell	8 cell	embryo
Pou5f1_1	2	3	4	5
Nanog_1	2	3.2	4.3	5
c-Myc_2	2	3	4	5
Tet1_3	2	3	4	5

ct@ehbio:~/sxbd$ sed '2,3d' mat
ID	2 cell	4 cell	8 cell	embryo
c-Myc_2	2	3	4	5
Tet1_3	2	3	4	5
```

* 记忆匹配

`\(\)`启动记忆匹配；`\1`为第一个匹配项，`\2`为第二个匹配项；匹配项的计数根据左括号出现的位置来定，第一个`(`包括起来的为`\1`。

```bash
ct@ehbio:~/sxbd$ echo "hah ehbio hah" | sed 's/ \(.*\) /\t\1\t\1\t/'
hah	ehbio	ehbio	hah
```

* 奇偶数行处理

```bash
ct@ehbio:~/sxbd$ echo -e "odd\neven\nodd\neven"
odd
even
odd
even

# 奇偶数行合并
ct@ehbio:~/sxbd$ echo -e "odd\neven\nodd\neven" | sed 'N;s/\n/\t/'
odd	even
odd	even

# 取出偶数行，比较简单
# 注意 n (小写)撇掉了奇数行
ct@ehbio:~/sxbd$ echo -e "odd\neven\nodd\neven" | sed -n 'n;p'
even
even

# 取出奇数行
# 先都读进去，然后替换偶数行为空值，再输出
ct@ehbio:~/sxbd$ echo -e "odd\neven\nodd\neven" | sed -n 'N;s/\n.*//;p'
odd
odd
```

* Windows/Linux换行符困境

Windows下的换行符是`\r\n`, Linux下换行符是`\n`, MAC下换行符是`\r`。所以Windows下的文件拷贝到Linux后，常会出现行尾多一个`^M`符号的情况，从而引起匹配或其它解析问题。


`^M`的输是 `ctrl+v+M`  `ctrl+v;ctrl+m`，不是简单的输入`^`,再输入`M`。

```bash
ct@ehbio:~/sxbd$ cat -A windows.txt 
ID^M$
A^M$
B^M$
C^M$
ct@ehbio:~/sxbd$ sed 's/^M//' windows.txt | cat -A
ID$
A$
B$
C$
```

* sed中使用bash变量

```bash
# 注意双引号的使用
ct@ehbio:~/sxbd$ bash_variable='ehbio'
ct@ehbio:~/sxbd$ echo "sheng xin bao dan " | sed "s/$/$bash_variable/"
sheng xin bao dan ehbio
```

## VIM的使用 {#vim}

`VIM`是一款功能强大的文本编辑工具，也是我在`Linux`，`Windows`下编辑程序和文本最常用的工具。

### 初识VIM {#vim_first}

VIM分多种状态模式，`写入`模式，`正常`模式，`可视化`模式。

* `正常`模式：打开或新建文件默认在`正常`模式，可以浏览，但不可以写入内容。这个模式也可以称作`命令行`模式，这个模式下可以使用VIM强大的命令行和快捷键功能。其它模式下按`ESC`就可以到`正常`模式。
* `写入`模式：在`正常`模式下按字母`i` (光标前插入), `o` (当前光标的下一行操作), `O` (当前光标的上一行操作)，`a` (光标后插入)都可以进入`写入`模式，就可以输入内容了。
* `可视化`模式：通常用于选择特定的内容。

进入`写入`模式后，VIM使用起来可以跟`记事本`一样了。在写入文字时，可以利用组合键`CTRL+n`和`CTRL+p`完成写作单词的自动匹配补全，从而加快输入速度，保证输入的前后一致。

`正常`模式有更强大的快捷键编辑功能，把手从鼠标上解放出来。

* `dd`: 删除一行
* `3dd`: 删除一行
* `dw`: 删除一个单词
* `d3w`: 删除3个单词
* `yy`: 复制一行
* `3yy`: 复制三行
* `yw`: 复制一个单词
* `p`: (小写p)粘贴到下一行
* `P`: (大写P)粘贴到上一行
* `>>`: 当前行右缩进一个TAB
* `3>>`: 当前行及后2行都向右缩进一个TAB
* `<<`: 当前行左缩进一个TAB
* `3<<`: 当前行及后2行都向左缩进一个TAB
* `/word`: 查找特定单词

* `u`: 撤销上一次操作
* `.`: 重复上一次操作
* `CTRL+r`: 重做撤销的操作

* `y$`: 从当前复制到行尾
* `d$`: 从当前删除到行尾


跳转操作

* `gg`: 跳到文件开头
* `G`: 跳到文件结尾
* `zt`: 当前行作为可视屏幕的第一行
* `5G`: 跳到第5行


`正常`模式下输入`冒号`进入更强大的命令行定制功能。

* `:5d`: 删除第5行
* `:20,24y`：复制20到24行
* `:.,+3y`：复制当前行和下面3行
* `:2,11>`: 右缩进
* `:w`: 保存文件
* `:q`: 退出编辑器

* `:vsplit`: 分屏

键盘操作不容易被捕获，看右下角可以得到一点信息。动图请[点击查看](//blog.genesino.com/images/vim/vim_basic_operation.gif)。

```{r}
if (identical(knitr:::pandoc_to(), "html")){
	url = "http://blog.genesino.com/images/vim/vim_basic_operation.gif"
	if(!file.exists(vim_basic_operation <- "vim_basic_operation.gif")){
	  download.file(url, vim_basic_operation, mode='wb')
	}
	knitr::include_graphics(if(identical(knitr:::pandoc_to(), "html")) url else vim_basic_operation)
}
```

VIM还有不少**魔性**操作，具体可以看这两个帖子：

* [http://coolshell.cn/articles/5426.html](http://coolshell.cn/articles/5426.html)
* [http://coolshell.cn/articles/11312.html](http://coolshell.cn/articles/11312.html)

### VIM中使用正则表达式 {#vim_re}

这儿以提取生信宝典公众号中发过的原创文章的HTML代码为例子，获得原创文章的名字和链接，用以制作文章列表。

部分数据如下所示，利用正则表达式的第一步就是找规律。

* 这段文字是JSON格式，列表和字典的组合，使用`json`函数可以很容易解析。但我们这通过正则表达式解析。
* `title`后面跟随的文章的题目; `url`后面跟随的是文章的链接。
* `{"`和`"}`标记每篇文章的信息的开始和结束。
* `auth_apply_num`是目前不关注的信息。


```{r}
url = "http://blog.genesino.com/images/vim/wechatSXBD_source.png"
if(!file.exists(wechatSXBD_source <- "wechatSXBD_source.png")){
  download.file(url, wechatSXBD_source, mode='wb')
}
knitr::include_graphics(if(identical(knitr:::pandoc_to(), "html")) url else wechatSXBD_source)
```

下面的[动画](http://blog.genesino.com/images/vim/vim_bregexpr.gif)展示了如何通过正则表达式，把这段文字只保留题目和链接，并转成`Markdown`的格式。


```{r}
if (identical(knitr:::pandoc_to(), "html")){
	url = "http://blog.genesino.com/images/vim/vim_bregexpr.gif"
	if(!file.exists(vim_bregexpr <- "vim_bregexpr.gif")){
	  download.file(url, vim_bregexpr, mode='wb')
	}
	knitr::include_graphics(if(identical(knitr:::pandoc_to(), "html")) url else vim_bregexpr)
}
```

* `:set wrap`: 折行显示
* `:s/"}, {"/\r/g`: `:`开启命令行模式；`s`: 是替换，之前讲Linux命令时也多次提及；`/`作为分割符，三个一起出现，前两个`/`中的内容为被替换内容，后两个`/`中的内容为替换成的内容；这里没有使用正则表达式，直接是原字符的替换，`\r`表示换行符。这样把每篇文章的信息单行显示，方便后续处理。
* `:%s/auth_apply.*"title":"/[/`：`%`表示对所有行进行操作；被替换的内容是`auth_apply`和`title":"`及其之间的内容(`.*`表示，`.`表示任意字符，`*`表示其前面的字符出现任意次)
* `:%s/".*"url":"/](/`：从题目到url之间的内容替换掉；第一次替换时忘记了第一行中开头还有引号，结果出现了误操作，后面又退回去，手动删除特殊部分，其它部分继续匹配。
* `:%s/$/)/`：表示在行尾(`$`)加上`)`, 就组成了Markdown中完整的链接形式`[context](link)`。
* `:%s/^/* /`：表示在行首(`^`)加上`* `变成Markdown格式的列表

至此就完成了生信宝典公众号文章到Markdown链接的转换，可以放到菜单栏`文章集锦`里面方便快速查询了。

一步步的处理也有些麻烦，有没有办法更简单些呢？ 动画可查看[链接](http://blog.genesino.com/images/vim/vim_bregexpr_record.gif)。




```{r}
if (identical(knitr:::pandoc_to(), "html")){
	url = "http://blog.genesino.com/images/vim/vim_bregexpr_record.gif"
	if(!file.exists(vim_bregexpr_record <- "vim_bregexpr_record.gif")){
	  download.file(url, vim_bregexpr_record, mode='wb')
	}
	knitr::include_graphics(if(identical(knitr:::pandoc_to(), "html")) url else vim_bregexpr_record)
}
```

* 首先也是把每篇文章的信息处理为单行显示，一样的模式更容易操作，去掉第一行行首不一致的部分
* 使用上下箭头可以回溯之前的命令，类似于Linux终端下的操作
* `%s/.*title":"\([^"]*\).*url":"\(.*\)/* [\1](\2)/c`: 这个是记忆匹配，记录下匹配的内容用于替换，`\(`和`\)`表示记忆匹配的开始和结束，自身不匹配任何字符，只做标记使用；从左只右, 第一个`\(`中的内容记录为`\1`, 第二个`\(`中的内容记录为`\2`,以此类推。尤其在存在括号嵌套的情况下，注意匹配位置，左括号出现的顺序为准。在匹配文章题目时使用了`[^"]*`而不是`.*`，是考虑到正则表达式的匹配是贪婪的，会囊括更多的内容进来，就有可能出现非预期情况，所以做这么个限定，匹配所有非`"`内容。

正则表达式在数据分析中有很多灵活的应用，可以解决复杂的字符串抽提工作。常用的程序语言或命令如`pytho`, `R`, `grep`, `awk`, `sed`都支持正则表达式操作，语法也大体相似。进一步学习可参考一下链接：


* VIM正则表达式 [http://blog.csdn.net/u014015972/article/details/50688837](http://blog.csdn.net/u014015972/article/details/50688837)
* Pyton正则表达式 [https://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html](https://www.cnblogs.com/huxi/archive/2010/07/04/1771073.html)

## 有了这些，文件批量重命名还需要求助其它工具吗？{#rename_all}

### 简单重命名 {#rename_simple}

Linux下文件重命名可以通过两个命令完成，`mv`和`rename`。

* `mv`: 直接运行可以进行单个文件的重命名，如 `mv old_name.txt new_name.txt`
* `rename`: 默认支持单个文件或有固定规律的一组文件的批量重命名，示例如下：

#### rename演示 {#rename_simple1}

使用`touch`新建文件，两个样品（分别是易生信a，易生信b），各自双端测序的FASTQ文件

```
ysx@ehbio:~/test$ touch YSX_a_1.fq.gz YSX_a_2.fq.gz YSX_b_2.fq.gz YSX_b_1.fq.gz
ysx@ehbio:~/test$ ls
YSX_a_1.fq.gz  YSX_a_2.fq.gz  YSX_b_1.fq.gz  YSX_b_2.fq.gz
```

把文件名中的 易生信(`YSX`)改为易汉博 (`ehbio`)

```
# rename '被替换文字' '要替换成的文字' 操作对象
ysx@ehbio:~/test$ rename 'YSX' 'ehbio' *.gz
ysx@ehbio:~/test$ ls
ehbio_a_1.fq.gz  ehbio_a_2.fq.gz  ehbio_b_1.fq.gz  ehbio_b_2.fq.gz
```

不同操作系统，`rename`的使用方法略有不同。印象中:

* 在CentOS都是上面的语法 `rename old new file_list`

* 在Ubuntu都是下面的语法 `rename s/old/new/ file_list`

```
# 在Centos下，该命令未起作用
ysx@ehbio:~/test$ rename 's/ehbio_//' *
ysx@ehbio:~/test$ ls
ehbio_a_1.fq.gz  ehbio_a_2.fq.gz  ehbio_b_1.fq.gz  ehbio_b_2.fq.gz

# 如果写的rename命令没发挥作用，使用man rename查看写看其具体使用方法, 个人经验，无外乎上面提到的两种用法。
ysx@ehbio:~/test$ man rename

# NAME
#        rename - rename files
# 
# SYNOPSIS
#        rename [options] expression replacement file...
```

替换后缀

```
# 替换后缀
ysx@ehbio:~/test$ rename 'fq' 'fastq' *.gz
ysx@ehbio:~/test$ ls
ehbio_a_1.fastq.gz  ehbio_a_2.fastq.gz  ehbio_b_1.fastq.gz  ehbio_b_2.fastq.gz
```

### 复杂重命名 {#rename_complex}

但有时，需要重命名的文件不像上面那样有很清晰的模式，直接可以替换，需要多几步处理获得对应关系。

#### 假如已经有对应关系 {#rename_for_known_relation}

如下`name.map.txt`是自己手动编写的文件，`a`对应`Control`, `b`对应`Treatment`。

```
ysx@ehbio:~/test$ ls
name.map.txt ehbio_a_1.fastq.gz  ehbio_a_2.fastq.gz  ehbio_b_1.fastq.gz  ehbio_b_2.fastq.gz

ysx@ehbio:~/test$ cat name.map.txt
a	Control
b	Treatment
```

##### 组合文件名，使用mv重命名 {#rename_combine_name}

首先组合出原名字和最终名字

```
ysx@ehbio:~/test$ awk '{print "ehbio_"$1"_1.fastq.gz", "ehbio_"$2"_1.fastq.gz", "ehbio_"$1"_2.fastq.gz",  "ehbio_"$2"_2.fastq.gz"}' name.map.txt
ehbio_a_1.fastq.gz ehbio_Control_1.fastq.gz ehbio_a_2.fastq.gz ehbio_Control_2.fastq.gz
ehbio_b_1.fastq.gz ehbio_Treatment_1.fastq.gz ehbio_b_2.fastq.gz ehbio_Treatment_2.fastq.gz
```

加上`mv`

```
ysx@ehbio:~/test$ awk '{print "mv ehbio_"$1"_1.fastq.gz ehbio_"$2"_1.fastq.gz"; print "mv ehbio_"$1"_2.fastq.gz ehbio_"$2"_2.fastq.gz";}' name.map.txt
mv ehbio_a_1.fastq.gz ehbio_Control_1.fastq.gz
mv ehbio_a_2.fastq.gz ehbio_Control_2.fastq.gz
mv ehbio_b_1.fastq.gz ehbio_Treatment_1.fastq.gz
mv ehbio_b_2.fastq.gz ehbio_Treatment_2.fastq.gz
```

可以直接拷贝上面的输出再粘贴运行，或存储为文件运行

```
ysx@ehbio:~/test$ awk '{print "mv ehbio_"$1"_1.fastq.gz ehbio_"$2"_1.fastq.gz"; print "mv ehbio_"$1"_2.fastq.gz ehbio_"$2"_2.fastq.gz";}' name.map.txt >rename.sh
ysx@ehbio:~/test$ #bash rename.sh
```

也可以把`print`改为`system`直接运行

```
ysx@ehbio:~/test$ ls
ehbio_a_1.fastq.gz  ehbio_a_2.fastq.gz  ehbio_b_1.fastq.gz  ehbio_b_2.fastq.gz  name.map.txt  rename.sh
ysx@ehbio:~/test$ awk '{system("mv ehbio_"$1"_1.fastq.gz ehbio_"$2"_1.fastq.gz"); system("mv ehbio_"$1"_2.fastq.gz ehbio_"$2"_2.fastq.gz");}' name.map.txt
ysx@ehbio:~/test$ ls
ehbio_Control_1.fastq.gz  ehbio_Control_2.fastq.gz  ehbio_Treatment_1.fastq.gz  ehbio_Treatment_2.fastq.gz  name.map.txt  rename.sh
```

##### 使用rename会不会稍微简单一点？ {#rename_for_complex_style}

一定注意符号匹配和避免误匹配。

```
# 注意引号和空格
ysx@ehbio:~/test$ awk '{print("rename "$1" "$2" *.fastq.gz"); }' name.map.txt
rename a Control *.fastq.gz
rename b Treatment *.fastq.gz

# 上面的命令有什么问题吗？
# fastq中也存在a，是否也会被替换
# ehbio中也存在b，是否也会倍替换

ysx@ehbio:~/test$ awk '{system("rename "$1" "$2" *.fastq.gz"); }' name.map.txt

# 执行后，文件名都乱套了
ysx@ehbio:~/test$ ls
ehbio_b_1.fControlstq.gz  ehbio_b_2.fControlstq.gz  ehTreatmentio_Control_1.fastq.gz  ehTreatmentio_Control_2.fastq.gz  name.map.txt  rename.sh

# 再重命名回去，再次尝试
ysx@ehbio:~/test$ rename 'Control' 'a' *
ysx@ehbio:~/test$ rename 'Treatment' 'b' *
ysx@ehbio:~/test$ ls
ehbio_a_1.fastq.gz  ehbio_a_2.fastq.gz  ehbio_b_1.fastq.gz  ehbio_b_2.fastq.gz  name.map.txt  rename.sh

# 重命名两侧加下划线, 这也是我们做匹配时常需要注意的，尽量限制让匹配更准确
ysx@ehbio:~/test$ awk '{system("rename _"$1"_ _"$2"_ *.fastq.gz"); }' name.map.txt

# 打印出来看下
ysx@ehbio:~/test$ awk '{print("rename _"$1"_ _"$2"_ *.fastq.gz"); }' name.map.txt
# rename _a_ _Control_ *.fastq.gz
# rename _b_ _Treatment_ *.fastq.gz

# 这次没问题了
ysx@ehbio:~/test$ ls
ehbio_Control_1.fastq.gz  ehbio_Control_2.fastq.gz  ehbio_Treatment_1.fastq.gz  ehbio_Treatment_2.fastq.gz  name.map.txt  rename.sh
```


#### 从原文件名获取对应关系 {#rename_relation_from_old_name}

##### 基于paste {#rename_paste}

像上面自己写好对应文件是一个方法，有时也可以从文件名推测规律，生成对应文件。

如下有一堆测序原始数据，选择A组样品来查看:

```
# 如下有一堆测序原始数据，选择A组样品来查看
ysx@ehbio:~/test2# ls A*

A1_FRAS192317015-1a_1.fq.gz  A2_FRAS192320421-1a_1.fq.gz  A3_FRAS192317017-1a_1.fq.gz
A1_FRAS192317015-1a_2.fq.gz  A2_FRAS192320421-1a_2.fq.gz  A3_FRAS192317017-1a_2.fq.gz
```

中间的那一串字符`FRA...-`是我们不需要的。

观察规律，按下划线分割(`_`)，获取第`1,3`个元素；另外习惯性给生物重复前面也加上下划线（用到了`sed`的记忆匹配）。

```
ysx@ehbio:~/test2# ls A*.gz | cut -f 1,3 -d '_' | sed 's/\([A-E]\)/\1_/'
A_1_1.fq.gz
A_1_2.fq.gz
A_2_1.fq.gz
A_2_2.fq.gz
```

把原样品名字与新样品名字对应起来，这里用到了`paste`和输入重定向 (`<`):

```
ysx@ehbio:~/test2# paste <(ls A*.gz) <(ls A*.gz | cut -f 1,3 -d '_' | sed 's/\([A-E]\)/\1_/')
A1_FRAS192317015-1a_1.fq.gz	A_1_1_fq.gz
A1_FRAS192317015-1a_2.fq.gz	A_1_2_fq.gz
A2_FRAS192320421-1a_1.fq.gz	A_2_1_fq.gz
A2_FRAS192320421-1a_2.fq.gz	A_2_2_fq.gz
A3_FRAS192317017-1a_1.fq.gz	A_3_1_fq.gz
A3_FRAS192317017-1a_2.fq.gz	A_3_2_fq.gz
```

使用`mv`直接重命名 （还可以把这个脚本保存下来，保留原始名字和新名字的对应关系，万一操作错了，在看到结果异常时也可以方便回溯）

```
ysx@ehbio:~/test2# paste <(ls A*.gz) <(ls A*.gz | cut -f 1,3 -d '_' | sed 's/\([A-E]\)/\1_/') | sed 's#^#/bin/mv #'
/bin/mv A1_FRAS192317015-1a_1.fq.gz	A_1_1_fq.gz
/bin/mv A1_FRAS192317015-1a_2.fq.gz	A_1_2_fq.gz
/bin/mv A2_FRAS192320421-1a_1.fq.gz	A_2_1_fq.gz
/bin/mv A2_FRAS192320421-1a_2.fq.gz	A_2_2_fq.gz
/bin/mv A3_FRAS192317017-1a_1.fq.gz	A_3_1_fq.gz
/bin/mv A3_FRAS192317017-1a_2.fq.gz	A_3_2_fq.gz
```

软链接也是常用的 (但一定注意源文件使用全路径)

```
ysx@ehbio:~/test2# paste <(ls *.gz) <(ls *.gz | sed 's/\./_/' | cut -f 1,3,4 -d '_' | sed 's/\([A-E]\)/analysis\/\1_/') | sed 's#^#ln -s `pwd`/#'
ln -s `pwd`/A1_FRAS192317015-1a_1.fq.gz	analysis/A_1_1_fq.gz
ln -s `pwd`/A1_FRAS192317015-1a_2.fq.gz	analysis/A_1_2_fq.gz
ln -s `pwd`/A2_FRAS192320421-1a_1.fq.gz	analysis/A_2_1_fq.gz
.
.
.
ln -s `pwd`/E15_FRAS192317028-1a_1.fq.gz	analysis/E_15_1_fq.gz
ln -s `pwd`/E15_FRAS192317028-1a_2.fq.gz	analysis/E_15_2_fq.gz
```

##### 基于awk {rename_awk}

转换下输入数据的格式，字符处理在`awk`也可以操作，但我更习惯使用命令组合，每一步都用最简单的操作，不容易出错。

```
ysx@ehbio:~/test2# ls A*.gz | sed -e 's/\([A-E]\)/\1_/'
A_1_FRAS192317015-1a_1.fq.gz
A_1_FRAS192317015-1a_2.fq.gz
A_2_FRAS192320421-1a_1.fq.gz
A_2_FRAS192320421-1a_2.fq.gz
A_3_FRAS192317017-1a_1.fq.gz
A_3_FRAS192317017-1a_2.fq.gz
ysx@ehbio:~/test2# ls A*.gz | sed -e 's/\([A-E]\)/\1_/' -e 's/\./_./'
A_1_FRAS192317015-1a_1_.fq.gz
A_1_FRAS192317015-1a_2_.fq.gz
A_2_FRAS192320421-1a_1_.fq.gz
A_2_FRAS192320421-1a_2_.fq.gz
A_3_FRAS192317017-1a_1_.fq.gz
A_3_FRAS192317017-1a_2_.fq.gz
```

采用`awk`生成对应关系

```
# 生成样品重复，计数出错了，每行记了一个数，而实际两行是一个样本。
ysx@ehbio:~/test2# ls A*.gz | sed -e 's/\([A-E]\)/\1_/' -e 's/\./_./' | awk 'BEGIN{OFS=" ";FS="_"}{sum[$1]+=1; print $0, $1"_"sum[$1]"_"$4$5;}'
A_1_FRAS192317015-1a_1_.fq.gz A_1_1.fq.gz
A_1_FRAS192317015-1a_2_.fq.gz A_2_2.fq.gz
A_2_FRAS192320421-1a_1_.fq.gz A_3_1.fq.gz
A_2_FRAS192320421-1a_2_.fq.gz A_4_2.fq.gz
A_3_FRAS192317017-1a_1_.fq.gz A_5_1.fq.gz
A_3_FRAS192317017-1a_2_.fq.gz A_6_2.fq.gz
```

```
# 稍微改进下
ysx@ehbio:~/test2# ls A*.gz | sed -e 's/\([A-E]\)/\1_/' -e 's/\./_./' | awk 'BEGIN{OFS=" ";FS="_"}{sum[$1]+=1; print $0, $1"_"sum[$1]"_"$4$5;}'
A_1_FRAS192317015-1a_1.fq.gz A_1_1.fq.gz
A_1_FRAS192317015-1a_2.fq.gz A_2_2.fq.gz
A_2_FRAS192320421-1a_1.fq.gz A_3_1.fq.gz
A_2_FRAS192320421-1a_2.fq.gz A_4_2.fq.gz
A_3_FRAS192317017-1a_1.fq.gz A_5_1.fq.gz
A_3_FRAS192317017-1a_2.fq.gz A_6_2.fq.gz

# 记得源文件名字的替换
ysx@ehbio:~/test2# ls A*.gz | sed -e 's/\([A-E]\)/\1_/' -e 's/\./_./' | awk 'BEGIN{OFS=" ";FS="_"}{sum[$1]+=1; print $0, $1"_"sum[$1]"_"$4$5;}' | sed -e 's/_//' -e 's/_\././' -e 's#^#ln -s `pwd`/#' |head
ln -s `pwd`/A1_FRAS192317015-1a_1.fq.gz A_1_1.fq.gz
ln -s `pwd`/A1_FRAS192317015-1a_2.fq.gz A_2_2.fq.gz
```

好了，重命名就到这了。有了这个思路，关键是如何根据自己的文件名字特征，构造对应的匹配关系。

另外，Window下使用`Git for windows`应该也可以实现对应的操作。

## 耗时很长的程序忘加nohup就运行了怎么办？  {#nohup}

在[NGS基础：测序原始数据下载](https://mp.weixin.qq.com/s/6oJYGxuBE850PyjMhRi3xg)一文中提到可以使用`SRA-toolkit`中的命令`fastq-dump`从NCBI下载原始测序数据，命令如下。

```
nohup fastq-dump -v --split-3 --gzip SRR5908360 &
nohup fastq-dump -v --split-3 --gzip SRR5908361 &
```

这个代码，给我们4个提示：

1. `fastq-dump`不只可以转换下载好的`sra`文件为`fastq`文件，还可以顺带下载`sra`文件。只需提供`SRR`号，就可以获得`FASTQ`序列。不需要先调用`prefetch`下载，然后再转换。其它参数解释见引用文章。
2. 每一行命令后面`&`号表示把命令放入后台运行，当前终端可以继续输入其它命令；此处也相当于实现了一个手动并行下载多样本，配合`for`可以自动并行下载。
3. `nohup`表示让程序在终端因人为原因或网络原因断开后不挂断，适用于运行时间比较长的命令，一般与`&`连用，形式如`nohup 你的命令 &` (注意空格的存在)。如果程序运行输出错误信息，则会写入当前目录下`nohup.out`文件里面，供后续查看和调试。
4. 经常会有一些培训班“拿来主义”比较严重，以上推文和生信宝典的其它推文都被发现过直接用于某些培训班的教材，但从未申请过授权，也未引用过出处。更有甚者，盗版易生信早期培训教案和视频，用于自己的课程或在全网发布，希望大家多多举报。

言归正传，通常我们运行程序前，会有个预判，如前面那个例子，运行时间比较长，会使用`nohup 我的命令 &`的形式进行运行，从而保证程序不受网络或终端异常退出的影响。

但有时也会有误判，如没想到某个程序运行了半个小时还没结束，或数据传输时网太慢，需要传输很久，这时怎么办？中止程序，然后加上`nohup`再从头运行？还是有更好的办法？

下面看这个例子：马上要去吃午饭了，把文件同步到另一个服务器，饭后回来继续操作：

```
ysx@ehbio:~/test/Bigwig$ rsync -av * ysx@46.93.19.14:/tmp
ysx@46.93.19.14's password: 
sending incremental file list
test1Y_DK10.bw
```

输入密码后，发现同步速度太慢了，`1`分钟只同步了`1`个文件，后面还有`99`个文件，待会离开后，如果网断了，终端退出，程序终止怎么办？同步不能完成，饭后怎么愉快的工作？

还好我们有下面的方案，一步步跟着操作，补救一下。

第一步，按`ctrl+z`把程序挂起，操作后屏幕会出现如下提示(`[1]`中的`1`表示命令的作业号，后面会用到)：

```
^Z
[1]+  已停止               rsync -av * ysx@46.93.19.14:/tmp
```

第二步（可选），用`jobs`命令查看下任务状态，跟刚才的屏幕提示一致，程序被暂时终止，作业号还是`1`：

```
ysx@ehbio:~/test/Bigwig$ jobs
[1]+  已停止               rsync -av * ysx@46.93.19.14:/tmp
```

第三步，使用`bg %1`命令把作业号为`1`的任务放入后台，并从**停止**状态变为**运行**状态，相当于加了`&`后接着运行。再用`jobs`查看，任务状态变成了`运行中`，这一步很关键。如果没有运行`bg %1`则程序处于停止状态，一直不会运行，吃几顿饭都不会运行。

```
ysx@ehbio:~/test/Bigwig$ bg %1
[1]+ rsync -av * ysx@46.93.19.14:/tmp &
ysx@ehbio:~/test/Bigwig$ jobs
[1]+  运行中               rsync -av * ysx@46.93.19.14:/tmp &
```

第四步，运行`disown -h %1`，表示在终端关闭时不对作业号为`1`的程序发送终止信号，外部因素将不影响程序的运行。通过`ps`命令查看下任务进程 (可选)。

```
ysx@ehbio:~/test/Bigwig$ disown -h %1
ysx@ehbio:~/test/Bigwig$ ps -auwx | grep 'rsync'
ysx       18214  0.0  0.0 117844  1720 ?        S    09:43   0:01 rsync -av *.bw ysx@46.93.19.14:/tmp
ysx       18215  0.1  0.0 182376  8360 ?        S    09:43   0:04 ssh -l ysx 46.93.19.14 rsync --server -vlogDtpre.iLsfxC . /tmp
ysx       18340  0.0  0.0 112724   984 pts/1    S+   10:17   0:00 grep --color=auto rsync
```

通过以上4步就完成了对这次操作的事后补救。以后遇到同类问题，试一试这个新方案吧！

同时还有5点提示：

1. 例子中使用的是`rsync`同步，从节省时间来看，不是一个很好的例子。因为把命令停掉再运行一次时，已经同步完整的数据不会再同步，时间损失不会太大。这也是使用同步命令`rsync`相比于`scp`的一个好处。更多同步方式见([Linux服务器数据定期同步和备份方式](https://mp.weixin.qq.com/s/c2cspK5b4sQScWYMBtG63g)。
2. 例子中的`rsync`或其它涉及两个服务器交互的命令，都需要我们人为输入登录密码，因此直接加`nohup  &`运行是行不通的，无法接受密码的输入。因此通过上面这个操作先在前台启动运行、输入密码，再放入后台不挂断运行。从这个角度看，是一个不错的例子。当然解决这个问题也有其它方式，具体见[ssh免密码登录远程服务器](https://mp.weixin.qq.com/s/wTM8J9zVEdl1PcGpJQbeEw)。
3. 如果程序运行时，已加了`&`号，放入后台了，则只需运行`jobs`获得作业号，再运行`disown`不挂断即可。
4. 程序作业号不一定都是`1`，如果之前就有程序在后台运行，作业号相应的会自加。后面用到作业号时也需要相应修改，不要刻板总用`1`。
5. `nohup`和`disown`都可以使程序不挂断，可以获得一样的效果，但原理不太一致。`nohup`可以使程序忽略挂断信号(`SIGHUP`)或者使程序脱离终端的控制，从而终端不能再对其发送挂断信号(`SIGHUP`)；`disown`则是内生于`shell`，告诉`shell`在终止时不对对应程序发送挂断信号(`SIGHUP`)。



## References

* [www.ehbio.com/Training](www.ehbio.com/Training)
* [Linux学习 - 常用和不太常用的实用awk命令](http://mp.weixin.qq.com/s/8wD14FXt7fLDo1BjJyT0ew)
* [Linux-总目录](http://mp.weixin.qq.com/s/hEYU80fPf1eD5OWL3fO4Bg)
* [Linux-文件和目录](http://mp.weixin.qq.com/s/yKP1Kboji9N4p2Sl1Ovj0Q)
* [Linux-文件操作](http://mp.weixin.qq.com/s/4bYMzJclf_xHpqdrlbvAdA)
* [Linux文件内容操作](http://mp.weixin.qq.com/s/QFgINAYcQA9kYYSA28wK-Q)
* [Linux-环境变量和可执行属性](http://mp.weixin.qq.com/s/poFpNHQgHDr0qr2wqfVNdw)
* [Linux - 管道、标准输入输出](http://mp.weixin.qq.com/s/zL9Mw_2ig48gHrIjKM0CMw)
* [Linux - 命令运行监测和软件安装](http://mp.weixin.qq.com/s/TNU7X2mhfVVffaJ7NRBuNA)
* [Linux-常见错误和快捷操作](http://mp.weixin.qq.com/s/cDIN4_R4nETEB5irmIGFAQ)
* [Linux-文件列太多，很难识别想要的信息在哪列；别焦急，看这里。](http://mp.weixin.qq.com/s/1QaroFE7AH1pREuq-k2YAw)
* [Linux-文件排序和FASTA文件操作](http://mp.weixin.qq.com/s/R1OHRhZoDJuAdyVdJr2xHg)
* [Linux-应用Docker安装软件](http://mp.weixin.qq.com/s/HLHiWMLaWtB7SOJe_jP3mA)
* [Linux服务器数据定期同步和备份方式](http://mp.weixin.qq.com/s/c2cspK5b4sQScWYMBtG63g)
* [VIM的强大文本处理方法](https://mp.weixin.qq.com/s/4lUiZ60-aXLilRk9--iQhA)
* [Linux - Conda软件安装方法](http://mp.weixin.qq.com/s/A4_j8ZbyprMr1TT_wgisQQ)
* [查看服务器配置信息](http://mp.weixin.qq.com/s/xq0JfkHJJeHQk1acjOAJUQ)
* [Linux - SED操作，awk的姊妹篇](http://mp.weixin.qq.com/s/cywkIeRbhkYTZvkwTeIVSA)
* [Linux - 常用和不太常用的实用awk命令](http://mp.weixin.qq.com/s/8wD14FXt7fLDo1BjJyT0ew)
* [Bash概论 - Linux系列教程补充篇](http://mp.weixin.qq.com/s/lWNp_6W_jLiogmtlk9nO2A)
* [CIRCOS圈图绘制 - circos安装](http://mp.weixin.qq.com/s/OEBJU3BiQdQOeN_tD2o7sA)
* [CIRCOS圈图绘制 - 最简单绘图和解释](http://mp.weixin.qq.com/s/2E1Y5-cEdptkQGVm0bxKbQ)
* [CIRCOS圈图绘制 - 染色体信息展示和调整](https://mp.weixin.qq.com/s/o_3DyYdSubWCh5FfoVKBOg)
* [CIRCOS增加热图、点图、线图和区块属性](http://mp.weixin.qq.com/s/6L8wmsy0eOxtiAEs3hYgCA)
* [有了这些，文件批量重命名还需要求助其它工具吗？ ](https://mp.weixin.qq.com/s/hyiGxm0jx6xEc90nHLN4dQ)
* [耗时很长的程序忘加nohup就运行了怎么办？ ](https://mp.weixin.qq.com/s/kt_e-DCq7xBfh9tTCJinZQ)

<!--chapter:end:03.highlevel.Rmd-->

# Bash 字符串处理 {#bash_string}

视频课见 <http://bioinfo.ke.qq.com>。

## Bash特殊字符 {#bash_specific}

1. 通配符:   

`*`: 匹配任何字符

`**`: 匹配任何字符串  

`*?`: 匹配任何单个字符

2. 集合运算符

用一些单个字、一个连续范围或断续的字符集合作为通配符  

`[a-z]`: 用字符集合作通配符匹配单个字符, 如: `[aeiou]`, `[a-o]`, `[A-Z]`, `[0-9]`  

`[!A-Za-z0-9]`: 除了集合外的所有字符组成的集合作通配符
   
3. 花括号展开式（可以嵌套）:   

`c{a{r,t,n}, b{r,t,n}}s` 可以匹配`cars` `cats` `cans` `cbrs` `cbts` `cbns`
   
4. 其它特殊字符:   

`()`: 子shell运行；比如 `(cd ehbio; mdkir ysx)`进入`ehbio`目录，新建`ysx`文件夹，运行完之后还在当前目录。
 
`'`: 强引用字符串, 不解释特殊字符  

`"`: 弱引用字符串, 解释所有特殊字符  

`;`: 命令分隔符（命令终止符）, 运行在一行里执行多条命令;一般在终端直接写判断语句或执行`for`循环时用。

`#`: 行注释  
`$`: 变量表达式，变量解析
`&`: 在后台执行命令，在`for`循环中也可用作命令分割符，取代`done`前面的`;`

## Bash变量 {#bash_variable}

1. 自定义变量

用户自定义的变量由字母、数字和下划线组成, 并且变量名的第一个字符不能为数字, 且变量名大小写敏感。  

`varname=value` **注意bash不能在等号两侧留空格**  

shell语言是非类型的解释型语言, 给一个变量赋值实际上就是定义了变量, 而且可以赋不同类型的值。引用变量有两种方式, `$varname`和`${varname}`, 为防止变量在字符串中产生歧义建议使用第二种方式, 引用未定义的变量其值为空。  

```
ct@ehbio:~$ a="EHBIO"
ct@ehbio:~$ echo ${a}
EHBIO
ct@ehbio:~$ echo $a
EHBIO

#出错了
ct@ehbio:~$ echo $agood

#引用变量时大括号的作用
ct@ehbio:~$ echo ${a}good
EHBIOgood
ct@ehbio:~$ echo $a.good
EHBIO.good

#出错了
ct@ehbio:~$ echo $a_good

#引用变量时大括号的作用
ct@ehbio:~$ echo ${a}_good
EHBIO_good
```

为了使变量可以在其它进程中使用, 需要将变量导出: `export varname`


2. 环境变量

可以用`set`命令给变量赋值或查看环境变量值, 使用`unset`命令清除变量值, 使用`export`导出变量将可以使其它进程访问到该环境变量。可以把设置保存到`.bashrc`或`.bash_profile`中, 成为永久的环境变量。

环境变量不限于我们之前讲过的[可执行程序的环境变量、动态库、Python模块的环境变量](http://mp.weixin.qq.com/s/TNU7X2mhfVVffaJ7NRBuNA)，任何变量都可以的。

3. 位置变量

位置变量对应于命令行参数, 其中`$0`为脚本名称, `$1`为第一个参数, 依次类推, 参数超过9个必须使用`${}`引用变量。shell保留这些变量, 不允许用户以另外的方式定义它们, 传给脚本或函数的位置变量是局部和只读的, 而其余变量为全局的（可以用local关键字声明为局部）。

4. 其它变量

`$?`: 保存前一个命令的返回码; `0`为运行成功，常用来判断上一个程序的退出状态。

`$$`: 当前shell的进程号  

`$!`: 上一个子进程的进程号  

`$#`: 传给脚本或函数的参数个数, 即位置变量数减`1`(1代表脚本自身)  
`$*`和`$@`: 传给脚本的所有参数(不包含脚本本身), 每个参数以`$IFS`分隔（一般内为空格, TAB, 换行）; 两者的不同点是引号括起来时，`$*`会被作为一个整体，`$@`还是单个的参数。

```
ct@ehbio:~$ cat ehbio_testParam.sh
#!/bin/bash

echo "EHBIO${IFS}great"

echo '$*'
echo -ne "\t";
echo $*

echo '$@'
echo -ne "\t";
echo $@

echo 'Each element in $*:'

for i in "$*"; do
	echo -ne "\t";
	echo $i;
done


echo 'Each element in $@:'
for i in "$@"; do
	echo -ne "\t";
	echo $i;
done

ct@ehbio:~$ bash ehbio_testParam.sh sheng xin bao dian
EHBIO 	
great
$*
	sheng xin bao dian
$@
	sheng xin bao dian
Each element in $*:
	sheng xin bao dian
Each element in $@:
	sheng
	xin
	bao
	dian
```

## Bash操作符 {#bash_operator}

1. 字符串操作符（替换操作符）

`${var:-word}`: 如果var存在且不为空, 返回它的值, 否则返回word  
`${var:=word}`: 如果var存在且不为空, 返回它的值, 否则将word赋给var,  返回它的值  
`${var:+word}`: 如果var存在且不为空, 返回word, 否则返回空  
`${var:?message}` 如果var存在且不为空, 返回它的值,   
否则显示“-bash: var: message”, 然后退出当前命令或脚本  
`${var:offset[:length]}` 从offset位置开始返回var的一个长为length的子串,   
若没有length, 则默认到var串末尾

```bash
ct@ehbio:~$ echo ${var:?message}
-bash: var: message
ct@ehbio:~$ var='sheng xin bao dian'
ct@ehbio:~$ echo ${var:6:3}
xin
ct@ehbio:~$ echo ${var:?message}
sheng xin bao dian
ct@ehbio:~$ echo $?
0
ct@ehbio:~$ unset var
ct@ehbio:~$ echo ${var:?message}
-bash: var: message
ct@ehbio:~$ echo $?
1
ct@ehbio:~$ echo ${var:=ehbio}
ehbio
ct@ehbio:~$ echo ${var}
ehbio
```

2. 模式匹配操作符

`${var#pattern}` 从var头部开始, 删除和pattern匹配的最短模式串, 然后返回 剩余串  

`${var##pattern}` 从var头部开始, 删除和pattern匹配的最长模式串, 然后返回 剩余串, `basename path＝${path##*/}`  

`${var%pattern}` 从var尾部开始, 删除和pattern匹配的最短模式串, 然后返回 剩余串, `dirname path＝${path%/*}`

`${var%%pattern}` 从var尾部开始, 删除和pattern匹配的最长模式串, 然后返回 剩余串  

`${var/pattern/string}`  用string替换var中和pattern匹配的最长模式串

个人最常用的是最后一个，常用于`for`循环中。

```
ct@ehbio:~$ var='sheng xin bao dian good'
ct@ehbio:~$ ${var/good/great}
-bash: sheng: command not found
ct@ehbio:~$ echo ${var/good/great}
sheng xin bao dian great
```

比如获取fastq文件的名字部分

```
for i in `ls *_1.fq.gz`; do j=${i/_1.fq.gz/}; echo "$j"; done
```

## Shell中条件和test命令 {#bash_logic}

Bash可以使用`[ … ]`结构或`test`命令测试复杂条件  
格式: `[ expression ]` 或 `test expression`  
返回一个代码, 表明条件为真还是为假, 返回`0`为真, 否则为假。  
注: 左括号`后`和右括号`前空格`是**必须的**语法要求

1. 文件测试操作符

`-d file`: file存在并且是一个目录  
`-e file`: file存在  
`-f file`: file存在并且是一个普通文件  
`-g file`: file存在并且是SGID(设置组ID)文件  
`-r file`: 对file有读权限  
`-s file`: file存在并且不为空  
`-u file`: file存在并且是SUID(设置用户ID)文件  
`-w file`: 对file有写权限  
`-x file`: 对file有执行权限, 如果是目录则有查找权限  
`-O file`: 拥有file  
`-G file`: 测试是否是file所属组的一个成员  
`-L file`: file为符号链接  
`file1 –nt file2`: file1比file2新

`file1 –ot file2`: file1比file2旧

举两个例子

```
ct@ehbio:~$ touch older
ct@ehbio:~$ touch newer

ct@ehbio:~$ if test -e older; then echo "older esists"; fi
older esists
ct@ehbio:~$ if test -s older; then echo "older is unempty"; fi
ct@ehbio:~$ if [ -s older ]; then echo "older is unempty"; fi
ct@ehbio:~$ if [ ! -s older ]; then echo "older is empty"; fi
older is empty
ct@ehbio:~$ if [ newer -nt older ]; then echo "newer"; fi
newer
```

2. 字符串操作符

`str1=str2` str1和str2匹配  
`str1!=str2` str1和str2不匹配  
`str1>str2` str1大于str2  
`-n str` str的长度大于0（不为空）
`-z str` str的长度为0（空串），常用于判断必须的命令行参数是否传入

```
# 字符串的大小比较的是最先遇到的不同的ASCII码的大小
ct@ehbio:~$ if test "10">"20"; then echo "10>20"; fi
10>20
ct@ehbio:~$ if test 10>20; then echo "10 < 20"; fi
```

3. **整数**操作符

var1 –eq var2 var1等于var2  
var1 –ne var2 var1不等于var2  
var1 –ge var2 var1大于等于var2  
var1 –gt var2 var1大于var2  
var1 –le var2 var1小于等于var2  
var1 –lt var2 var1小于var2

`ge`: great equal; `gt`: great than

**需要注意的是常用的数学运算符给了字符串比较，数字比较使用的却是英文缩写**

数学表达式也可以

```
if (( 3>2 )); then echo 'TRUE'; fi
TRUE
```

4. 逻辑操作符

`!expr` 对expr求反
`expr1 && expr2` 对expr1与expr2求逻辑与, 当expr1为假时不再执行expr2  
`expr1 || expr2` 对expr1与expr2求逻辑或, 当expr1为真时不再执行expr2  


## Shell流控制 {#bash_flow}

1. 条件语句: if

`if`, `then`, `elif`, `else`, `fi`是关键词，其它的是需要替换掉的。

```
if conditions; then
	do sth when conditions are true
elif another_conditions; then
	do sth when another_conditions are true
else:
	do sth when above condiitons are all false
fi
```

```
if test $guanzhu_sxbd == "already"; then
	echo "Enjoy it"
elif test $guanzhu_hjyz == "already"; then
	echo "Enjoy it"
else
	echo "Guan zhu them"
fi

Enjoy it
```


2. 确定性循环: `for do done` **常用的批量操作方式**

遍历一个列表，取出每个元素，针对性操作。

```
for i in `ls *_1.fq.gz`; do 
	echo "$i"; 
done
```

3. 不确定性循环: `while`和`until`

```  
declare -i a #定义整数变量
a=1   # 初始化变量
while test $a -lt 3; do
	echo $a
	a=$a+1
done 

echo $a
```

4. 选择结构: `case`和`select` (类似getopts)

```
ct@ehbio:~$ cat select_case.sh

PS3="Input the position of selected parameter (1 for exit):"

select opts in a b c d
do
	case $opts in
		a)
			exit 0;
			;;
		b)
			echo " Parameters $opts"
			;;
		c)
			echo " Parameters $opts"
			;;
		d)
			echo " Parameters $opts"
			;;
		?)
			echo "Unknown"
			;;
	esac
done

ct@ehbio:~$ bash select_case.sh 
1) a
2) b
3) c
4) d
Input the position of selected parameter (1 for exit):2
 Parameters b
Input the position of selected parameter (1 for exit):3
 Parameters c
Input the position of selected parameter (1 for exit):4
 Parameters d
Input the position of selected parameter (1 for exit):1

```

5. 命令`shift`

将存放在位置变量中的命令行参数依次向左传递`shift n` 命令行参数向左传递`n`个参数串

```
ct@ehbio:~$ cat ehbio_testParam.sh
#!/bin/bash

echo 'Each element in $*:'

for i in "$*"; do
	echo -ne "\t";
	echo $i;
done

echo $1
shift

for i in "$*"; do
	echo -ne "\t";
	echo $i;
done
ct@ehbio:~$ bash ehbio_testParam.sh sheng xin bao dian
Each element in $*:
	sheng xin bao dian
sheng
	xin bao dian
```

## Shell函数 {#bash_function}

`function function_name () { function body}`定义函数，函数参数的获取同命令行参数获取。

```
ct@ehbio:~$ cat test_func.sh 
function show_ehbio () {
	echo $@
	echo $1
}

show_ehbio "EHBIO great" "SXBD great"
ct@ehbio:~$ bash test_func.sh
EHBIO great SXBD great
EHBIO great
```

## 输入输出 {#bash_inputoutput}

1. I/O重定向  

[管道、标准输入输出](http://mp.weixin.qq.com/s/zL9Mw_2ig48gHrIjKM0CMw)之前有过详细介绍。

`<`: 输入重定向 

`>`: 输出重定向(没有文件则创建, 有则覆盖)  

`>>`: 输出重定向(没有则创建, 有则追加到文件尾部)  

`<<`: 输入重定向(here文档)  

```
command << label  
input…  
label  
说明:  使一个命令的输入为一段shell脚本(input…), 直到标号(label)结束  
```

```
ftp: USER=anonymous  
PASS=YC@163.com  
#-i: 非交互模式 -n: 关闭自动登录  
ftp –i –n << END 
open ftp.163.com  
user $USER $PASS  
cd /pub  
close  
END
#END标记输入结束 
```
 
2. 字符串I/O操作  

字符串输出: `echo`  

命令选项:  `-e`: 启动转义序列 `-n`: 取消输出后换行  (前面已经用到过)

3. 字符串输入: `read` 可以用于用户交互输入, 也可以用来一次处理文本文件中的一行

命令选项: 

```
ct@ehbio:~$ read -p "Enter the best tutorial: " tutorial
Enter the best tutorial: Sheng Xin Bao Dian
ct@ehbio:~$ echo $tutorial
Sheng Xin Bao Dian

# 隐藏输入内容
ct@ehbio:~$ read -s -p "Enter your password: " password
Enter your password: 
ct@ehbio:~$ echo $password
haha
```

## 命令行处理 命令行处理命令 {#command_parameter}

`getopts` 有两个参数, 第一个为字母和冒号组成的选项列表字符串, 第二个为一个变量名

选项列表字符串以冒号开头的选项字母排列组成, 如果一选项需要一个参数则该选项字母后跟一个冒号

`getopts`分解第一参数, 依次将选项摘取出来赋给第二个参数变量

如果某选项有参数, 则读取参数到内置变量`OPTARG`中 内置变量`OPTIND`保存着将被处理的命令行参数（位置参数）的数值选项列表处理完毕`getopts`返回`1`, 否则返回`0` 如: 

在我们推出的[一步绘图脚本](https://mp.weixin.qq.com/s/bsvB1k17Izom2ldgdwXrdg)里面，就是使用`Bash`封装的R脚本，通过修改命令行参数，完成热图、柱状图、线图、Venn图、火山图、泡泡图等图形的绘制和定制。

```
while getopts "hf:m:a:A:b:I:t:x:l:j:J:d:F:G:H:P:L:y:V:D:c:C:B:X:Y:R:w:u:r:o:O:s:S:p:z:Z:v:e:E:i:" OPTION
do
        case $OPTION in
                h)
                        usage
                        exit 1
                        ;;
                f)
                        file=$OPTARG
                        ;;
                m)
                        melted=$OPTARG
						;;
				.
				.
				.
                ?)
                        usage
                        exit 1
                        ;;
        esac
done				
```

## 进程和作业控制 {#process_monitor}

[命令行运行监测和软件安装](https://mp.weixin.qq.com/s/TNU7X2mhfVVffaJ7NRBuNA)文中讲述了部分监测命令。

如果一个命令需要运行比较久，一般使用`nohup cmmand &`来放入后台不中断运行，这样推出终端也不影响程序。

`command &`是把程序放入后台。

`jobs`: 查看后台进程

`bg`: 显示后台进程, 即用Ctrl+z挂起或‘命令 &’执行的进程

`fg job_id`: 将后台进程转到前台执行

`kill –9 process_id`: 强制杀掉某个进程



<!--chapter:end:04.bashstring.Rmd-->

# Bioinfo tools

## 寻找Cas9的同源基因并进行进化分析 {#cas9}

见PPT

## 如何获取目标基因的转录因子（上）——biomart下载基因和motif位置信息 {#biomart_motif}

科研过程中我们经常会使用Ensembl(http://asia.ensembl.org/index.html) 网站来获取物种的参考基因组，其中`BioMart`工具可以获取物种的基因注释信息，以及跨数据库的`ID`匹配和注释等。

在[参考基因组和基因注释文件](https://mp.weixin.qq.com/s/2OoXy4f1t0hE8OUqsAt1kw)一文中有详细介绍如何在Ensembel数据库中获取参考基因组和基因注释文件。（点击蓝字即可阅读）

生信分析中，想要找到感兴趣基因的转录因子结合位点，该怎么做呢？

### 1. 文件准备 {#biomart_motif_1}

首先需要准备以下3个文件，后面两个文件可以在ensembl网站中下载：

1. 感兴趣基因的名称列表（1列基因名即可）
2. 基因组中各基因位置信息列表（6列的bed文件）
3. 基因组中各转录因子结合位点信息列表（5列的bed文件）

### 2. 什么是bed文件？{#biomart_motif_2}

bed格式文件提供了一种灵活的方式来定义数据行，以此描述基因注释的信息。BED行有3个必须的列和9个可选的列。 每行的数据格式要求一致。

关于bed文件格式的介绍，在<https://genome.ucsc.edu/FAQ/FAQformat.html#format1>中有详细说明。

我们需要下载的**基因位置信息列表**是一个6列的bed文件，每列信息如下：

Chromosome/scaffold name | Gene start (bp) | Gene end (bp) | Gene stable ID | Gene name | Strand
---|---|---|---|---|---
染色体的名称（例如chr3） | Gene起始位点 | Gene终止位点 | Gene stable ID | Gene name | 定义基因所在链的方向，+或-

注：起始位置和终止位置以0为起点，前闭后开。

**转录因子结合位点列表**是一个5列的bed文件，每列信息如下：

Chromosome/scaffold name | Start (bp) | End (bp) | Score | Feature Type
---|---|---|---|---
染色体的名称（例如chr3） | TF起始位点 | TF终止位点 | Score |  转录因子的名字

具体内容见后面示例，更方便理解。

### 3. BioMart数据下载 {#biomart_motif_3}

1. 进入Ensembl主页后点击**BioMart**

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/1.png)

2. 使用下拉框-`CHOOSE DATASET`- 选择数据库，我们选则**Ensembl Genes 93**；这时出现新的下拉框-`CHOOSE DATASET`- ，选择目的物种，以**Human gene GRCh38.p12**为例。如果自己实际操作，需要选择自己的数据常用的基因组版本。如果没有历史包袱，建议选择**GRCh38**最新版。

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/2.png)

3. 选择数据库后，点击Filters对数据进行筛选，如果是对全基因组进行分析可不用筛选, **略过不填**。

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/3.png)   

4. 点击**Attributes**，在GENE处依次选择1-6列的内容，勾选顺序便是结果矩阵中每列的顺序。

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/4.png)   

5. 如上图中所示，点击**results**后跳转下载页面，中间展示了部分所选的数据矩阵，确定格式无误后点击**GO**即可下载。

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/5.png) 

6. **转录因子结合位点矩阵的下载**类似上面，不过在下拉框-CHOOSE DATASET- 选择数据库时，我们选则**Ensembl Regulation 93**，再选择**Human Binding Motif (GRCh38.p12) **

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/6.png) 

7. 在Attributes处选择需要的信息列，点击**Results**和**GO**进行数据下载

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/7.png) 

   ![BioMart](http://www.ehbio.com/ehbio_resource/BioMart/8.png) 

将上述下载的两个文件分别命名为 `GRCh38.gene.bed`和 `GRCh38.TFmotif_binding.bed` ，在Shell中查看一下：

基因组中每个基因所在的染色体、位置和链的信息，以及对应的ENSG编号和Gene symbol。

```
Chromosome/scaffold name        Gene start (bp) Gene end (bp)   Gene stable ID  Gene
3       124792319       124792562       ENSG00000276626 RF00100 -1
1       92700819        92700934        ENSG00000201317 RNU4-59P        -1
14      100951856       100951933       ENSG00000200823 SNORD114-2      1
22      45200954        45201019        ENSG00000221598 MIR1249 -1
1       161699506       161699607       ENSG00000199595 RF00019 1
```

第五列为人中的转录因子，每一行表示每个转录因子在基因组范围的结合位点分布，即其可能在哪些区域有结合motif。这些区域是与TF的结合motif矩阵相似性比较高的区域，被视为潜在结合位点。有程序`MEME-FIMO`或`Homer-Findmotifs.pl`可以完成对应的工作。

```
Chromosome/scaffold name        Start (bp)      End (bp)        Score   Feature Type
14      23034888        23034896        7.391   THAP1
3       10026599        10026607        7.054   THAP1
10      97879355        97879363        6.962   THAP1
3       51385016        51385024        7.382   THAP1
16      20900537        20900545        6.962   THAP1
```


## 如何获取目标基因的转录因子（下）——Linux命令获取目标基因TF {#biomart_motif_4}


我们知道有很多数据库可以[查找启动子、UTR、TSS等区域以及预测转录因子结合位点](https://mp.weixin.qq.com/s/vFO7uAtI6nh-zTW7RHCixA)，但是怎么用**Linux命令处理**基因信息文件来**得到关注基因的启动子和启动子区结合的TF**呢？

### 1. 基础回顾 {#biomart_motif_5}

**转录起始位点（TSS）**：转录时，mRNA链第一个核苷酸相对应DNA链上的碱基，通常为一个嘌呤；(不考虑转录启动复合体的预转录情况)

**启动子（promoter）**：与RNA聚合酶结合并能起始mRNA合成的序列。与传统的核心启动子概念不同，做生信分析时，一般选择转录起始位点上游1 kb，下游 200 nt，也有选上下游各1 kb或者 2 kb的（记住这两个数，之后计算要用到）；总体上生信中选择的启动子更长，范围更广一些。

**文件准备**：感兴趣的基因列表（命名为`targetGene.list`）、还有上一期下载的`GRCh38.gene.bed`和`GRCh38.TFmotif_binding.bed`

### 2. 文件格式处理 {#biomart_motif_6}


删除文件`GRCh38.gene.bed`首行，第六列正负链表示形式改为`-`和`+`，并在第一列染色体位置加上`chr`；

```
sed -i '1d' GRCh38.gene.bed 
# 如果用sed，注意下面2列的顺序，为什么不能颠倒过来？
sed -i 's/-1$/-/' GRCh38.gene.bed
sed -i 's/1$/+/' GRCh38.gene.bed 
sed -i 's/^/chr/' GRCh38.gene.bed
```

删除文件`GRCh38.TFmotif_binding.bed`首行,并在第一列染色体位置加上`chr`

```
sed -i '1d' GRCh38.TFmotif_binding.bed
sed -i 's/^/chr/' GRCh38.TFmotif_binding.bed
```


`less -S filename`查看一下两个矩阵内容，发现已转换完成

```
chr3    124792319       124792562       ENSG00000276626 RF00100 -
chr1    92700819        92700934        ENSG00000201317 RNU4-59P        -
chr14   100951856       100951933       ENSG00000200823 SNORD114-2      +
chr22   45200954        45201019        ENSG00000221598 MIR1249 -
chr1    161699506       161699607       ENSG00000199595 RF00019 +
```

```
chr14   23034888        23034896        7.391   THAP1
chr3    10026599        10026607        7.054   THAP1
chr10   97879355        97879363        6.962   THAP1
chr3    51385016        51385024        7.382   THAP1
chr16   20900537        20900545        6.962   THAP1
```

### 3. 计算基因的启动子区 {#biomart_motif_7}


上面已提过，根据经验一般启动子区域在转录起始位点（TSS）上游1 kb、下游 200 nt处，注意**正负链的运算方式是不一样的**，切忌出错。

```
awk 'BEGIN{OFS=FS="\t"}{if($6=="+") {tss=$2; tss_up=tss-1000; tss_dw=tss+200;} else {tss=$3; tss_up=tss-200; tss_dw=tss+1000;} if(tss_up<0) tss_up=0;print $1, tss_up, tss_dw,$4,$5,$6;}' GRCh38.gene.bed > GRCh38.gene.promoter.U1000D200.bed
```

关于`awk`命令的使用方法，可以参考[Linux学习 - 常用和不太常用的实用awk命令](https://mp.weixin.qq.com/s/8wD14FXt7fLDo1BjJyT0ew)一文。

`head GRCh38.gene.bed GRCh38.gene.promoter.U1000D200.bed`检查一下计算是否有误。自己选取正链和负链的一个或多个基因做下计算，看看结果是否一致。做分析不是出来结果就完事了，一定谨防程序中因为不注意核查引起的bug。

```
==> GRCh38.gene.bed <==
chr3	124792319	124792562	ENSG00000276626	RF00100	-
chr1	92700819	92700934	ENSG00000201317	RNU4-59P	-
chr14	100951856	100951933	ENSG00000200823	SNORD114-2	+
chr22	45200954	45201019	ENSG00000221598	MIR1249	-
chr1	161699506	161699607	ENSG00000199595	RF00019	+

==> GRCh38.gene.promoter.U1000D200.bed <==
chr3	124792362	124793562	ENSG00000276626	RF00100	-
chr1	92700734	92701934	ENSG00000201317	RNU4-59P	-
chr14	100950856	100952056	ENSG00000200823	SNORD114-2	+
chr22	45200819	45202019	ENSG00000221598	MIR1249	-
chr1	161698506	161699706	ENSG00000199595	RF00019	+
```

### 4. 取两文件的交集 {#biomart_motif_8}

本条命令我们使用了`bedtools`程序中的子命令`intersect`

`intersect`可用来求区域之间的交集，可以用来注释peak，计算reads比对到的基因组区域不同样品的peak之间的peak重叠情况；[Bedtools使用简介](https://mp.weixin.qq.com/s/bIXom5bSDov-4sPqsTRc6A)一文中有关于bedtools的详细介绍；

两文件取完交集后，`cut -f`取出交集文件的第5列和第11列，`sort -u`去处重复项，并将这两列内容小写全转变为大写，最终**得到一个两列的文件**。第一列是基因名，第二列是能与基因结合的TF名字。

程序不细解释，具体看文后的Linux系列教程。[Bedtools使用简介](https://mp.weixin.qq.com/s/bIXom5bSDov-4sPqsTRc6A)

```
# cut时注意根据自己的文件选择对应的列
# tr转换大小写。
bedtools intersect -a GRCh38.gene.promoter.U1000D200.bed -b GRCh38.TFmotif_binding.bed -wa -wb | cut -f 5,11 | sort -u | tr 'a-z' 'A-Z' > GRCh38.gene.promoter.U1000D200.TF_binding.txt
```


### 5. 提取我们关注的基因 {#biomart_motif_9}

上一步中，我们将`GRCh38.gene.promoter.U1000D200.TF_binding.txt`文件中的基因名和TF名都转换成了大写。

为了接下来提取目标基因转录因子时不会因大小写差别而漏掉某些基因，我们将`targetGene.list`中的基因名也全部转换成大写。

```
# 基因名字转换为大写，方便比较。不同的数据库不同的写法，只有统一了才不会出现不必要的失误
tr 'a-z' 'A-Z' targetGene.list > GeneUP.list
```

目标基因列表和基因-TF对应表都好了，内容依次如下：

```
==> GeneUP.list <==
ACAT2
ACTA1
ACTA2
ADM
AEBP1

==> GRCh38.gene.promoter.U1000D200.TF_binding.txt <==
A1BG	RXRA
A2M-AS1	GABP
A2M	SRF
A4GALT	GABP
AAAS	CTCF
```

用`awk`命令，根据第一个文件`GeneUP.list`建立索引，若第二个文件`GRCh38.gene.promoter.U1000D200.TF_binding.txt`第一列中检索到第一个文件中的基因，则把第二个文件中检索到目标基因的整行存储起来，最终得到了目标基因和基因对应TF的文件`targetGene.TF_binding.txt`。这也是常用的取子集操作。

```
awk 'BEGIN{OFS=FS="\t"}ARGIND==1{save[$1]=1;}ARGIND==2{if(save[$1==1]) print $0}' GeneUP.list GRCh38.gene.promoter.U1000D200.TF_binding.txt > targetGene.TF_binding.txt
```


获取目标基因的转录因子是生信分析中常见的分析，希望[如何获取目标基因的转录因子（上）]()和本文能够帮助到各位小伙伴

### 重点总结 {#biomart_motif_10}

1. 什么是bed文件

2. awk命令的使用

3. bedtools使用 ([Bedtools使用简介](https://mp.weixin.qq.com/s/bIXom5bSDov-4sPqsTRc6A))


## emboss的使用 {#emboss}


`EMBOSS`是欧洲分子生物学开放软件包，主要做序列比对，数据库搜搜，蛋白motif分析和功能域分析，序列模式搜索，引物设计等。

```{r}
emboss= "Popular applications;Functions
prophet;Gapped alignment for profiles.
infoseq;Displays some simple information about sequences.
water;Smith-Waterman local alignment.
pepstats;Protein statistics.
showfeat;Show features of a sequence.
palindrome;Looks for inverted repeats in a nucleotide sequence.
eprimer3;Picks PCR primers and hybridization oligos.
profit;Scan a sequence or database with a matrix or profile.
extractseq;Extract regions from a sequence.
marscan;Finds MAR/SAR sites in nucleic sequences.
tfscan;Scans DNA sequences for transcription factors.
patmatmotifs;Compares a protein sequence to the PROSITE motif database.
showdb;Displays information on the currently available databases.
wossname;Finds programs by keywords in their one-line documentation.
abiview;Reads ABI file and display the trace.
tranalign;Align nucleic coding regions given the aligned proteins."

emboss = read.table(text=emboss,sep=";",row.names=NULL,header=T)
knitr::kable(emboss, booktabs=T, caption="Popular applications of EMBOSS.")
```

emboss可以使用源码编译安装或用Conda安装，在前面的基础课中已有过讲述。

下载地址 <ftp://emboss.open-bio.org/pub/EMBOSS/emboss-latest.tar.gz>。

下载地址 <http://primer3.sourceforge.net/>。

```
# Make sure bioconda channel has added
# http://blog.genesino.com/2017/09/bioconda/
ct@ehbio:~$ conda install emboss
ct@ehbio:~$ url=https://sourceforge.net/projects/primer3/files/primer3/2.3.7/
ct@ehbio:~$ wget ${url}primer3-2.3.7.tar.gz -O primer3-2.3.7.tar.gz
ct@ehbio:~$ tar xvzf primer3-2.3.7.tar.gz
ct@ehbio:~$ cd primer3-2.3.7/src
ct@ehbio:~$ make all
# 确保~/bin在环境变量中
ct@ehbio:~$ ln -s `pwd`/primer3_core ~/bin/primer32_core

# Error: thermodynamic approach chosen,  but path to thermodynamic parameters not specified
ct@ehbio:~$ mkdir /opt/primer3_config
ct@ehbio:~$ cp -R primer3-2.3.7/src/primer3_config/* /opt/primer3_config
```

测试数据

```
ct@ehbio:~$ cat <<END >test.fa
>comp24_c0_seq1
TTACTCTCATCCTCCCCTTGTTGAAAGATTGGCTGCAATTGATGAACCCGATAAGAAGGTCAACTAAGAGAAGTGTAC
TTTTACGCATGGCATGGCATGGCGAGATATGGCTGTAATATGAGTATTATTTTCCTATGTTGCTACCGATATTTTCTA
TTTGCATATGAAAATTCCAAACCCAGAGTTAGGGGCCATATCTAAAGGGAATTTGCTAACGAGTAAATGGGAAAATAG
GAAATGTCAGAGGAGAtagcctagcctagcctagcctagccTCGCCTCATGTAACGAAATACAATTTAAATTTTGCTT
TACAGCTAATAGTCAGACTTTACATTTTGCTAAAA
END
```

设计引物

```
ct@ehbio:~$ eprimer32 -sequence test.fa -outfile test.fa.primer \
	-targetregion 0,371 -optsize 20 -numreturn 3 \
	-minsize 15 -maxsize 25 \
	-opttm 50 -mintm 45 -maxtm 55 \
	-psizeopt 200 -prange 100-280
```

引物结果

```
# EPRIMER32 RESULTS FOR comp24_c0_seq1

#                      Start  Len   Tm     GC%   Sequence

   1 PRODUCT SIZE: 200
     FORWARD PRIMER     126   20  50.17  35.00  TATTTTCCTATGTTGCTACC

     REVERSE PRIMER     306   20  50.01  30.00  ACTATTAGCTGTAAAGCAAA


   2 PRODUCT SIZE: 199
     FORWARD PRIMER     134   20  49.88  30.00  TATGTTGCTACCGATATTTT

     REVERSE PRIMER     313   20  50.30  35.00  AAGTCTGACTATTAGCTGTA


   3 PRODUCT SIZE: 198
     FORWARD PRIMER     134   20  49.88  30.00  TATGTTGCTACCGATATTTT

     REVERSE PRIMER     312   20  50.30  35.00  AGTCTGACTATTAGCTGTAA
```

整理引物格式位PrimerSearch需要的格式

```
ct@ehbio:~$ awk '{if($0~/EPRIMER32/) {seq_name=$5;count=1;} else \
	if($0~/FORWARD PRIMER/) forward=$7; else if ($0~/REVERSE PRIMER/) \
	{reverse=$7; printf("%s@%d\t%s\t%s\n", seq_name,count,forward, reverse); \
	count+=1;} }' test.fa.primer >all_primer_file
```

```
ct@ehbio:~$ cat all_primer_file
comp24_c0_seq1@1        TATTTTCCTATGTTGCTACC    ACTATTAGCTGTAAAGCAAA
comp24_c0_seq1@2        TATGTTGCTACCGATATTTT    AAGTCTGACTATTAGCTGTA
comp24_c0_seq1@3        TATGTTGCTACCGATATTTT    AGTCTGACTATTAGCTGTAA
```

模拟PCR

```
ct@ehbio:~$ primersearch -seqall test.fa -infile all_primer_file \
	-mismatchpercent 5 -outfile test.database.primerSearch
```

```
Primer name comp24_c0_seq1@1
Amplimer 1
	Sequence: comp24_c0_seq1  
	
	TATTTTCCTATGTTGCTACC hits forward strand at 126 with 0 mismatches
	ACTATTAGCTGTAAAGCAAA hits reverse strand at [23] with 0 mismatches
	Amplimer length: 200 bp

Primer name comp24_c0_seq1@2
Amplimer 1
	Sequence: comp24_c0_seq1  
	
	TATGTTGCTACCGATATTTT hits forward strand at 134 with 0 mismatches
	AAGTCTGACTATTAGCTGTA hits reverse strand at [16] with 0 mismatches
	Amplimer length: 199 bp

Primer name comp24_c0_seq1@3
Amplimer 1
	Sequence: comp24_c0_seq1  
	
	TATGTTGCTACCGATATTTT hits forward strand at 134 with 0 mismatches
	AGTCTGACTATTAGCTGTAA hits reverse strand at [17] with 0 mismatches
	Amplimer length: 198 bp
```


**needleall** 读入两个文件，第一个文件的每个序列都与第二个文件的每个序列进行全局比对，采用`Needleman-Wunsch`算法。 

```
# 生成测试数据
ct@ehbio:~$ cat <<END >generateRandom.awk
BEGIN{srand(seed); seq[0]="A"; seq[1]="C"; seq[2]="G"; seq[3]="T"}
	{for(i=1;i<=chrNum;i++) 
		{print ">"label""i; len=(10-int(rand()*10)%2)/10*expected_len; 
	    for(j=0;j<=len;j++) printf("%s", seq[int(rand()*10)%4]); print "";
	    }
	} 
END

ct@ehbio:~$ echo 1 | awk -v seed=$RANDOM -v label=mm -v chrNum=2 \
			  -v expected_len=40 -f generateRandom.awk >test1.fa
ct@ehbio:~$ echo 1 | awk -v seed=$RANDOM -v label=hs -v chrNum=2 \
			  -v expected_len=40 -f generateRandom.awk >test2.fa
```

```
ct@ehbio:~$ cat test1.fa
>mm1
GTATACATCCGTAATCGGATAAAAGCGTACTATGGCG
>mm2
TAATTTCCCATGCACTATCACAACCCCTCGGATCAGACGCC
ct@ehbio:~$ cat test2.fa
>hs1
GCAAACGATTGGCCGGACGTCATCACTCCCCTCCGCGGATG
>hs2
CACAGTCCACGCTTTAAACGTACGAACAGACTTCCTT
```

```
# 输出格式见： http://emboss.sourceforge.net/docs/themes/AlignFormats.html
# Both fa and fq are supported
# -auto: 关闭弹出选项
ct@ehbio:~$ needleall -asequence test1.fa -bsequence test2.fa -gapopen 10 -gapextend 0.5 \
	-outfile test12.needle.alignment -auto -aformat3 pair
```

```
ct@ehbio:~$ cat test12.needle.alignment
########################################
# Program: needleall
# Rundate: Fri 30 Mar 2018 13:49:30
# Commandline: needleall
#    -asequence test1.fa
#    -bsequence test2.fa
#    -auto
#    -aformat3 pair
# Align_format: pair
# Report_file: test1.needleall
########################################

#=======================================
#
# Aligned_sequences: 2
# 1: mm1
# 2: hs1
# Matrix: EDNAFULL
# Gap_penalty: 10.0
# Extend_penalty: 0.5
#
# Length: 62
# Identity:      15/62 (24.2%)
# Similarity:    15/62 (24.2%)
# Gaps:          46/62 (74.2%)
# Score: 27.0
# 
#
#=======================================

mm1                1 ------------------GT-ATACA------TCCGTAATCGGATAAAAG     25
                                       || || ||      ||||    |||||.    
hs1                1 GCAAACGATTGGCCGGACGTCAT-CACTCCCCTCCG----CGGATG----     41

mm1               26 CGTACTATGGCG     37
                                 
hs1               42 ------------     41


#=======================================
#
# Aligned_sequences: 2
# 1: mm2
# 2: hs1
# Matrix: EDNAFULL
# Gap_penalty: 10.0
# Extend_penalty: 0.5
#
# Length: 51
# Identity:      23/51 (45.1%)
# Similarity:    23/51 (45.1%)
# Gaps:          20/51 (39.2%)
# Score: 41.0
# 
#
#=======================================

mm2                1 -----TAATTTCCCATGCAC--TATCACAACCCCT---CGGATCAGACGC     40
                          ..|||..||  |.||  .||||| .|||||   |||||.      
hs1                1 GCAAACGATTGGCC--GGACGTCATCAC-TCCCCTCCGCGGATG------     41

mm2               41 C     41
                      
hs1               42 -     41


#=======================================
#
# Aligned_sequences: 2
# 1: mm1
# 2: hs2
# Matrix: EDNAFULL
# Gap_penalty: 10.0
# Extend_penalty: 0.5
#
# Length: 51
# Identity:      18/51 (35.3%)
# Similarity:    18/51 (35.3%)
# Gaps:          28/51 (54.9%)
# Score: 26.0
# 
#
#=======================================

mm1                1 GTATACA-TCCGTAATCGGATAAAAGCGTACTATGGCG------------     37
                        .||| |||    .||..|.||| ||||      ||            
hs2                1 ---CACAGTCC----ACGCTTTAAA-CGTA------CGAACAGACTTCCT     36

mm1               38 -     37
                      
hs2               37 T     37


#=======================================
#
# Aligned_sequences: 2
# 1: mm2
# 2: hs2
# Matrix: EDNAFULL
# Gap_penalty: 10.0
# Extend_penalty: 0.5
#
# Length: 55
# Identity:      18/55 (32.7%)
# Similarity:    18/55 (32.7%)
# Gaps:          32/55 (58.2%)
# Score: 36.0
# 
#
#=======================================

mm2                1 TAATTTCCCATGCACTATCACAACCC---CT-----CG---GATCAGACG     39
                                       ||||..||   ||     ||   ||.|||||.
hs2                1 ------------------CACAGTCCACGCTTTAAACGTACGAACAGACT     32

mm2               40 CC---     41
                     .|   
hs2               33 TCCTT     37


#---------------------------------------
#---------------------------------------
```

```
ct@ehbio:~$ needleall -asequence test1.fa -bsequence test2.fa -gapopen 10 -gapextend 0.5 \
	-outfile test12.needle.score -auto
```

```
# 序列1 序列2 比对长度 比对得分
ct@ehbio:~$ cat test12.needle.score
mm1 hs1 62 (27.0)
mm2 hs1 51 (41.0)
mm1 hs2 51 (26.0)
mm2 hs2 55 (36.0)
```

 
## 使用samtools计算SNP {#samtools_snp}

1. 安装samtools和bedtools

```
ct@ehbio:~$ conda install samtools
ct@ehbio:~$ conda install bedtools
```

2. 产生随机的基因组文件。

```
# srand: 随机数发生器。设置固定的种子，保证每次出来的结果一致
# rand: 返回[0,1)之间的随机数，包含0不包含1
ct@ehbio:~$ echo 1 | awk -v seed=1 -v label=chr -v chrNum=4 \
			  -v expected_len=60000 -f generateRandom.awk >genome.fa
# 显示前60个碱基
ct@ehbio:~$ ct@ehbio:~/bio$ head genome.fa | cut -c 1-60
>chr1
GACCCACACTACGAGGCTCCCAACGATCAGGATTCCTATTCCCTCCTCGCTACCGGAAAA
>chr2
AGCCCTTACACCATCTGAGTCTGGCACACTTTTAGAACATCTACCCGTCACGAACAAGAA
>chr3
GTACAAGGCCCGGGGCTCGGACATTAAGCTCCTCCACTCAGCAGTCAAGTCAAACGAACA
>chr4
ACGCCCGTCAATTAGAGGCATTCAAAGACACCCGCCCGTGCTACAATAGGTACTACAACC
```

3. 产生随机的测序文件

```
# -N: 获得40K read pairs
# mut.txt: 突变位点或区域
ct@ehbio:~$ wgsim -N 40000 genome.fa ehbio_1.fq ehbio_2.fq > mut.txt
```

```
# FASTQ格式序列，4行一组
# 第一行以@开头，后面为序列名字，
# 第二行为序列
# 第三行+开头，后面一般无内容；若有，也是序列名字
# 第四行，质量值，对应序列中每个碱基的测序准确度
ct@ehbio:~$ head ehbio_1.fq
@chr1_17674_18124_2:0:0_2:0:0_0/1
TCGTTCAGTGGTGGTTACTCGTAGGGTCTTCCATCTGAGGCGGGCGAGCGGACGCCTTTTCTGCCTCCAG
+
2222222222222222222222222222222222222222222222222222222222222222222222
@chr1_29806_30221_2:0:0_0:0:0_1/1
TTAAGTGTGCTTGGACAACGGATATGCAAGTGTCTTTGATATATCGTTAGGGATAGGTTAATTAAGGGTC
+
2222222222222222222222222222222222222222222222222222222222222222222222
```

```
# 获得的突变文件如下
# Check IUPAC here: http://www.bioinformatics.org/sms/iupac.html
Col1: chromosome
Col2: position
Col3: original base
Col4: new base (IUPAC codes indicate heterozygous)
Col5: which genomic copy/haplotype 
ct@ehbio:~$ head mut.txt
chr1	6274	T	C	-
chr1	6923	C	Y	+
chr1	7022	C	Y	+
chr1	10426	A	W	+
chr1	11130	C	S	+
chr1	12135	G	R	+
```

4. 创建基因组索引

```
ct@ehbio:~$ bwa index genome.fa
# samtools fadix快速获取某区域序列
ct@ehbio:~$ samtools faidx genome.fa
```

5. 序列比对回基因组

```
ct@ehbio:~$ bwa mem -t 3 genome.fa ehbio_1.fq ehbio_2.fq | gzip >map.sam.gz
```

6. 筛选比对上的高质量reads

```
ct@ehbio:~$ samtools view -F4 -q1 -b map.sam.gz -o map.bam
# 下面2个排序用法都可以，看使用的samtools版本
ct@ehbio:~$ #samtools sort -@ 2 map.bam map.sortP
ct@ehbio:~$ samtools sort -@ 2 -o map.sortP.bam map.bam
ct@ehbio:~$ samtools index map.sortP.bam
```

7. 统计比对reads数

```
ct@ehbio:~$ samtools view -c map.sortP.bam
79998
```

8. 统计未比对上的reads数

```
ct@ehbio:~$ samtools view -c -f 4 map.sam.gz
```

9. 统计比对到正链的reads数

```
ct@ehbio:~$ samtools view -c -F 16 map.sam.gz
40001
```

10. 获取properly-paired的reads数

```
ct@ehbio:~$ samtools view -f2 -F 256 -c map.sortP.bam
79996
```

11. 查看每个位置碱基比对或错配情况

```
# -Q 0: 测试数据使用，默认为-Q 13，表示过滤掉低质量测序碱基
ct@ehbio:~$ samtools mpileup -f genome.fa -Q 0 map.sortP.bam | less
# chrName	coordinate	ref_base	coverage	reads_base	reads_quality
chr1    5       C       1       ^].     2
chr1    6       A       2       .^].    22
chr1    7       C       2       ..      22
chr1    8       A       2       ..      22
chr1    9       C       2       G.      22
chr1    10      T       3       ..^].   222
chr1    11      A       3       ...     222
chr1    12      C       4       ...^].  2222
chr1    13      G       4       ....    2222
chr1    14      A       4       ....    2222
chr1    15      G       4       ....    2222
chr1    16      G       4       ....    2222
```

mpileup format (http://samtools.sourceforge.net/pileup.shtml)

测序碱基列解释：

> 1. 点(`.`)代表匹配正链碱基
> 2. 逗号(`,`)代表匹配负链碱基
> 3. 大写字母(`ACGTN`)表示正链错配
> 4. 小写字母(`acgtn`)表示负链错配
> 5. 模式`\+[0-9]+[ACGTNacgtn]+`表示在当前参考位置和下一个参考位置之间有插入，插入碱基数是`+`后面的证书，插入碱基是数字后面的字母串。下面展示的是`2 bp`的插入
> 
> 	> seq2 156 A 11  .$......+2AG.+2AG.+2AGGG    <975;:<<<<<
> 
> 6. 模式`-[0-9]+[ACGTNacgtn]+'参考基因组存在碱基缺失。下面展示的是`4 bp`缺失：
> 
> 	> seq3 200 A 20 ,,,,,..,.-4CACC.-4CACC....,.,,.^~. ==<<<<<<<<<<<::<;2<<
> 
> 7. 符号`^`表示测序序列起始位置落于此 (A symbol `^' marks the start of a read segment which is a contiguous subsequence on the read separated by `N/S/H' CIGAR operations). 后面跟随的符号的ASCII值减去33表示该位置碱基的质量。符号`$'表示测序序列片段的终止。主要用于从pileup文件中获得原始测序reads。


12. 输出vcf格式

```
# 获得未压缩的vcf格式，方便查看
ct@ehbio:~$ samtools mpileup -f genome.fa -Q 0 -vu map.sortP.bam >snp.vcf
```

## Bedtools使用 {#bedtools}

[Bedtools](http://bedtools.readthedocs.io/en/latest/)是处理基因组信息分析的强大工具集合。

```
bedtools: flexible tools for genome arithmetic and DNA sequence analysis.
usage:    bedtools <subcommand> [options]

The bedtools sub-commands include:

[ Genome arithmetic ]
    intersect     Find overlapping intervals in various ways.
				  求区域之间的交集，可以用来注释peak，计算reads比对到的基因组区域
				  不同样品的peak之间的peak重叠情况。
    window        Find overlapping intervals within a window around an interval.
    closest       Find the closest, potentially non-overlapping interval.
				  寻找最近但可能不重叠的区域
    coverage      Compute the coverage over defined intervals.
	              计算区域覆盖度
    map           Apply a function to a column for each overlapping interval.
    genomecov     Compute the coverage over an entire genome.
    merge         Combine overlapping/nearby intervals into a single interval.
				  合并重叠或相接的区域
    cluster       Cluster (but don't merge) overlapping/nearby intervals.
    complement    Extract intervals _not_ represented by an interval file.
	              获得互补区域
    subtract      Remove intervals based on overlaps b/w two files.
	              计算区域差集
    slop          Adjust the size of intervals.
	              调整区域大小，如获得转录起始位点上下游3 K的区域
    flank         Create new intervals from the flanks of existing intervals.
    sort          Order the intervals in a file.
	              排序，部分命令需要排序过的bed文件
    random        Generate random intervals in a genome.
	              获得随机区域，作为背景集
    shuffle       Randomly redistrubute intervals in a genome.
	              根据给定的bed文件获得随机区域，作为背景集
    sample        Sample random records from file using reservoir sampling.
    spacing       Report the gap lengths between intervals in a file.
    annotate      Annotate coverage of features from multiple files.

[ Multi-way file comparisons ]
    multiinter    Identifies common intervals among multiple interval files.
    unionbedg     Combines coverage intervals from multiple BEDGRAPH files.

[ Paired-end manipulation ]
    pairtobed     Find pairs that overlap intervals in various ways.
    pairtopair    Find pairs that overlap other pairs in various ways.

[ Format conversion ]
    bamtobed      Convert BAM alignments to BED (& other) formats.
    bedtobam      Convert intervals to BAM records.
    bamtofastq    Convert BAM records to FASTQ records.
    bedpetobam    Convert BEDPE intervals to BAM records.
    bed12tobed6   Breaks BED12 intervals into discrete BED6 intervals.

[ Fasta manipulation ]
    getfasta      Use intervals to extract sequences from a FASTA file.
	              提取给定位置的FASTA序列
    maskfasta     Use intervals to mask sequences from a FASTA file.
    nuc           Profile the nucleotide content of intervals in a FASTA file.

[ BAM focused tools ]
    multicov      Counts coverage from multiple BAMs at specific intervals.
    tag           Tag BAM alignments based on overlaps with interval files.

[ Statistical relationships ]
    jaccard       Calculate the Jaccard statistic b/w two sets of intervals.
	              计算数据集相似性
    reldist       Calculate the distribution of relative distances b/w two files.
    fisher        Calculate Fisher statistic b/w two feature files.

[ Miscellaneous tools ]
    overlap       Computes the amount of overlap from two intervals.
    igv           Create an IGV snapshot batch script.
				  用于生成一个脚本，批量捕获IGV截图
    links         Create a HTML page of links to UCSC locations.
    makewindows   Make interval "windows" across a genome.
	              把给定区域划分成指定大小和间隔的小区间 (bin)
    groupby       Group by common cols. & summarize oth. cols. (~ SQL "groupBy")
	              分组结算，不只可以用于bed文件。
    expand        Replicate lines based on lists of values in columns.
    split         Split a file into multiple files with equal records or base pairs.

[ General help ]
    --help        Print this help menu.
    --version     What version of bedtools are you using?.
    --contact     Feature requests, bugs, mailing lists, etc.
```

1. 安装bedtools

```
ct@ehbio:~$ conda install bedtools
```

2. 获得测试数据集(http://quinlanlab.org/tutorials/bedtools/bedtools.html)

```
ct@ehbio:~$ mkdir bedtools
ct@ehbio:~$ cd bedtools
ct@ehbio:~$ url=https://s3.amazonaws.com/bedtools-tutorials/web
ct@ehbio:~/bedtools$ curl -O ${url}/maurano.dnaseI.tgz
ct@ehbio:~/bedtools$ curl -O ${url}/cpg.bed
ct@ehbio:~/bedtools$ curl -O ${url}/exons.bed
ct@ehbio:~/bedtools$ curl -O ${url}/gwas.bed
ct@ehbio:~/bedtools$ curl -O ${url}/genome.txt
ct@ehbio:~/bedtools$ curl -O ${url}/hesc.chromHmm.bed
```

3. 交集 (intersect)


```{r, fig.cap="bedtools intersect"}
url = "http://bedtools.readthedocs.io/en/latest/_images/intersect-glyph.png"
if(!file.exists(pic_file <- "intersect-glyph.png")){
  download.file(url, pic_file, mode="wb")
}
knitr::include_graphics(if(identical(knitr:::pandoc_to(),'html')) url else pic_file)
```

查看输入文件，`bed`格式，至少三列，分别是`染色体`，`起始位置`(0-based, 包括)，`终止位置` (1-based，不包括)。第四列一般为区域名字，第五列一般为空，第六列为链的信息。更详细解释见<http://www.genome.ucsc.edu/FAQ/FAQformat.html#format1>。

自己做研究CpG岛信息可以从UCSC的Table Browser获得，具体操作见<http://blog.genesino.com/2013/05/ucsc-usages/>。

```
ct@ehbio:~/bedtools$ head -n 3 cpg.bed exons.bed
==> cpg.bed <==
chr1	28735	29810	CpG:_116
chr1	135124	135563	CpG:_30
chr1	327790	328229	CpG:_29

==> exons.bed <==
chr1	11873	12227	NR_046018_exon_0_0_chr1_11874_f	0	+
chr1	12612	12721	NR_046018_exon_1_0_chr1_12613_f	0	+
chr1	13220	14409	NR_046018_exon_2_0_chr1_13221_f	0	+
```

获得重叠区域(既是外显子，又是CpG岛的区域)

```
ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed | head -5
chr1	29320	29370	CpG:_116
chr1	135124	135563	CpG:_30
chr1	327790	328229	CpG:_29
chr1	327790	328229	CpG:_29
chr1	327790	328229	CpG:_29
```

输出重叠区域对应的原始区域(与外显子存在交集的CpG岛)

```
ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed -wa -wb > | head -5
```

* chr1	28735	29810	CpG:_116	chr1	29320	29370	NR_024540_exon_10_0_chr1_29321_r	0	-
* chr1	135124	135563	CpG:_30	chr1	134772	139696	NR_039983_exon_0_0_chr1_134773_r	0	-
* chr1	327790	328229	CpG:_29	chr1	324438	328581	NR_028322_exon_2_0_chr1_324439_f	0	+
* chr1	327790	328229	CpG:_29	chr1	324438	328581	NR_028325_exon_2_0_chr1_324439_f	0	+
* chr1	327790	328229	CpG:_29	chr1	327035	328581	NR_028327_exon_3_0_chr1_327036_f	0	+

计算重叠碱基数

```
ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed -wo | head -10
```

* chr1	28735	29810	CpG:_116	chr1	29320	29370	NR_024540_exon_10_0_chr1_29321_r	0	-	50
* chr1	135124	135563	CpG:_30	chr1	134772	139696	NR_039983_exon_0_0_chr1_134773_r	0	-	439
* chr1	327790	328229	CpG:_29	chr1	324438	328581	NR_028322_exon_2_0_chr1_324439_f	0	+	439
* chr1	327790	328229	CpG:_29	chr1	324438	328581	NR_028325_exon_2_0_chr1_324439_f	0	+	439
* chr1	327790	328229	CpG:_29	chr1	327035	328581	NR_028327_exon_3_0_chr1_327036_f	0	+	439
* chr1	713984	714547	CpG:_60	chr1	713663	714068	NR_033908_exon_6_0_chr1_713664_r	0	-	84
* chr1	762416	763445	CpG:_115	chr1	761585	762902	NR_024321_exon_0_0_chr1_761586_r	0	-	486
* chr1	762416	763445	CpG:_115	chr1	762970	763155	NR_015368_exon_0_0_chr1_762971_f	0	+	185
* chr1	762416	763445	CpG:_115	chr1	762970	763155	NR_047519_exon_0_0_chr1_762971_f	0	+	185
* chr1	762416	763445	CpG:_115	chr1	762970	763155	NR_047520_exon_0_0_chr1_762971_f	0	+	185


计算第一个(-a)bed区域有多少个重叠的第二个(-b)bed文件中有多少个区域

```
ct@ehbio:~/bedtools$ bedtools intersect -a cpg.bed -b exons.bed -c | head
chr1	28735	29810	CpG:_116	1
chr1	135124	135563	CpG:_30	1
chr1	327790	328229	CpG:_29	3
chr1	437151	438164	CpG:_84	0
chr1	449273	450544	CpG:_99	0
chr1	533219	534114	CpG:_94	0
chr1	544738	546649	CpG:_171	0
chr1	713984	714547	CpG:_60	1
chr1	762416	763445	CpG:_115	10
chr1	788863	789211	CpG:_28	9
```

另外还有`-v`取出不重叠的区域, `-f`限定重叠最小比例，`-sorted`可以对按`sort -k1,1 -k2,2n`排序好的文件加速操作。

同时对多个区域求交集 (可以用于peak的多维注释)

```
# -names标注注释来源
# -sorted: 如果使用了这个参数，提供的一定是排序好的bed文件
ct@ehbio:~/bedtools$ bedtools intersect -a exons.bed \
	-b cpg.bed gwas.bed hesc.chromHmm.bed -sorted -wa -wb -names cpg gwas chromhmm \
  	| head -10000  | tail -10
```

* chr1	27632676	27635124	NM_001276252_exon_15_0_chr1_27632677_chromhmm	chr1	27633213	27635013	5_Strong_Enhancer
* chr1	27632676	27635124	NM_001276252_exon_15_0_chr1_27632677_chromhmm	chr1	27635013	27635413	7_Weak_Enhancer
* chr1	27632676	27635124	NM_015023_exon_15_0_chr1_27632677_f  chromhmm	chr1	27632613	27632813	6_Weak_Enhancer
* chr1	27632676	27635124	NM_015023_exon_15_0_chr1_27632677_f  chromhmm	chr1	27632813	27633213	7_Weak_Enhancer
* chr1	27632676	27635124	NM_015023_exon_15_0_chr1_27632677_f  chromhmm	chr1	27633213	27635013	5_Strong_Enhancer
* chr1	27632676	27635124	NM_015023_exon_15_0_chr1_27632677_f  chromhmm	chr1	27635013	27635413	7_Weak_Enhancer
* chr1	27648635	27648882	NM_032125_exon_0_0_chr1_27648636_f   cpg	chr1	27648453	27649006	CpG:_63
* chr1	27648635	27648882	NM_032125_exon_0_0_chr1_27648636_f   chromhmm	chr1	27648613	27649413	1_Active_Promoter
* chr1	27648635	27648882	NR_037576_exon_0_0_chr1_27648636_f   cpg	chr1	27648453	27649006	CpG:_63
* chr1	27648635	27648882	NR_037576_exon_0_0_chr1_27648636_f   chromhmm	chr1	27648613	27649413	1_Active_Promoter

4. 合并区域


```{r, fig.cap="bedtools merge"}
url = "http://bedtools.readthedocs.io/en/latest/_images/merge-glyph.png"
if(!file.exists(pic_file <- "merge-glyph.png")){
  download.file(url, pic_file, mode="wb")
}
knitr::include_graphics(if(identical(knitr:::pandoc_to(),'html')) url else pic_file)
```

`bedtools merge`输入的是按`sort -k1,1 -k2,2n`排序好的bed文件。

只需要输入一个排序好的bed文件，默认合并重叠或邻接区域。

```
ct@ehbio:~/bedtools$ bedtools merge -i exons.bed | head -n 5
chr1	11873	12227
chr1	12612	12721
chr1	13220	14829
chr1	14969	15038
chr1	15795	15947
```

合并区域并输出此合并后区域是由几个区域合并来的

```
ct@ehbio:~/bedtools$ bedtools merge -i exons.bed -c 1 -o count | head -n 5
chr1	11873	12227	1
chr1	12612	12721	1
chr1	13220	14829	2
chr1	14969	15038	1
chr1	15795	15947	1
```

合并相距`90 nt`内的区域，并输出是由哪些区域合并来的

```
# -c: 指定对哪些列进行操作
# -o: 与-c对应，表示对指定列进行哪些操作
# 这里的用法是对第一列做计数操作，输出这个区域是由几个区域合并来的
# 对第4列做收集操作，记录合并的区域的名字，并逗号分隔显示出来
ct@ehbio:~/bedtools$ bedtools merge -i exons.bed -d 340 -c 1,4 -o count,collapse | head -4
chr1	11873	12227	1	NR_046018_exon_0_0_chr1_11874_f
chr1	12612	12721	1	NR_046018_exon_1_0_chr1_12613_f
chr1	13220	15038	3	NR_046018_exon_2_0_chr1_13221_f,NR_024540_exon_0_0_chr1_14362_r,NR_024540_exon_1_0_chr1_14970_r
chr1	15795	15947	1	NR_024540_exon_2_0_chr1_15796_r
```


5. 计算互补区域

给定一个全集，再给定一个子集，求另一个子集。比如给定每条染色体长度和外显子区域，求非外显子区域。给定基因区，求非基因区。给定重复序列，求非重复序列等。

重复序列区域的获取也可以用上面提供的链接 <http://blog.genesino.com/2013/05/ucsc-usages/>。

```
ct@ehbio:~/bedtools$ head genome.txt 
chr1	249250621
chr10	135534747
chr11	135006516
chr11_gl000202_random	40103
chr12	133851895
chr13	115169878
chr14	107349540
chr15	102531392

ct@ehbio:~/bedtools$ bedtools complement -i exons.bed -g genome.txt | head -n 5
chr1	0	11873
chr1	12227	12612
chr1	12721	13220
chr1	14829	14969
chr1	15038	15795
```

6. 基因组覆盖广度和深度

计算基因组某个区域是否被覆盖，覆盖深度多少。有下图多种输出格式，也支持RNA-seq数据，计算junction-reads覆盖。

```{r, fig.cap="bedtools genomecov"}
url = "http://bedtools.readthedocs.io/en/latest/_images/genomecov-glyph.png"
if(!file.exists(pic_file <- "genomecov-glyph.png")){
  download.file(url, pic_file, mode="wb")
}
knitr::include_graphics(if(identical(knitr:::pandoc_to(),'html')) url else pic_file)
```

`genome.txt`里面的内容就是染色体及对应的长度。

```
# 对单行FASTA，可如此计算
# 如果是多行FASTA，则需要累加
ct@ehbio:~/bedtools$ awk 'BEGIN{OFS=FS="\t"}{\
	if($0~/>/) {seq_name=$0;sub(">","",seq_name);} \
	else {print seq_name,length;} }' ../bio/genome.fa | tee ../bio/genome.txt 
chr1	60001
chr2	54001
chr3	54001
chr4	60001
ct@ehbio:~/bedtools$ bedtools genomecov -ibam ../bio/map.sortP.bam -bga \
	-g ../bio/genome.txt | head

# 这个warning很有意思，因为BAM中已经有这个信息了，就不需要提供了
*****
*****WARNING: Genome (-g) files are ignored when BAM input is provided. 
*****
# bedgraph文件，前3列与bed相同，最后一列表示前3列指定的区域的覆盖度。
chr1	0	11	0
chr1	11	17	1
chr1	17	20	2
chr1	20	31	3
chr1	31	36	4
chr1	36	43	6
chr1	43	44	7
chr1	44	46	8
chr1	46	48	9
chr1	48	54	10
```

两个思考题：

> 1. 怎么计算有多少基因组区域被测到了？

> 2. 怎么计算平均测序深度是多少？

7. 数据集相似性

`bedtools jaccard`计算的是给定的两个`bed`文件之间交集区域(intersection)占总区域(union-intersection)的比例(jaccard)和交集的数目(n_intersections)。

```
ct@ehbio:~/bedtools$ bedtools jaccard \
	-a fHeart-DS16621.hotspot.twopass.fdr0.05.merge.bed \
	-b fHeart-DS15839.hotspot.twopass.fdr0.05.merge.bed
intersection	union-intersection	jaccard	n_intersections
81269248	160493950	0.50637	130852
```

小思考：1. 如何用bedtools其它工具算出这个结果？2. 如果需要比较的文件很多，怎么充分利用计算资源？

一个办法是使用`for`循环, 双层嵌套。这种用法也很常见，不管是单层还是双层for循环，都有利于简化重复运算。

```
ct@ehbio:~/bedtools$ for i in *.merge.bed; do \
	for j in *.merge.bed; do \
	bedtools jaccard -a $i -b $j | cut -f3 | tail -n +2 | sed "s/^/$i\t$j\t/"; \
	done; done >total.similarity
```

另一个办法是用`parallel`，不只可以批量，更可以并行。

```
root@ehbio:~# yum install parallel.noarch
```

```
# parallel 后面双引号("")内的内容为希望用parallel执行的命令，
# 整体写法与Linux下命令写法一致。
# 双引号后面的 三个相邻冒号 (:::)默认用来传递参数的，可多个连写。
# 每个三冒号后面的参数会被循环调用，而在命令中的引用则是根据其出现的位置，分别用{1}, {2}
# 表示第一个三冒号后的参数，第二个三冒号后的参数。
#
# 这个命令可以替换原文档里面的整合和替换, 相比于原文命令生成多个文件，这里对每个输出结果
# 先进行了比对信息的增加，最后结果可以输入一个文件中。
#
ct@ehbio:~/bedtools$ parallel "bedtools jaccard -a {1} -b {2} | awk 'NR> | cut -f 3 \
	| sed 's/^/{1}\t{2}\t/'" ::: `ls *.merge.bed` ::: `ls *.merge.bed`  >totalSimilarity.2


# 上面的命令也有个小隐患，并行计算时的输出冲突问题，可以修改为输出到单个文件,再cat到一起
ct@ehbio:~/bedtools$ parallel "bedtools jaccard -a {1} -b {2} | awk 'NR> | cut -f 3 \
	| sed 's/^/{1}\t{2}\t/' >{1}.{2}.totalSimilarity_tmp" ::: `ls *.merge.bed` ::: `ls *.merge.bed` 
ct@ehbio:~/bedtools$ cat *.totalSimilarity_tmp >totalSimilarity.2

# 替换掉无关信息
ct@ehbio:~/bedtools$ sed -i -e 's/.hotspot.twopass.fdr0.05.merge.bed//' \
	-e 's/.hg19//' totalSimilarity.2  
```

```

```

原文档的命令，稍微有些复杂，利于学习不同命令的组合。使用时推荐使用上面的命令。

```
ct@ehbio:~/bedtools$ parallel "bedtools jaccard -a {1} -b {2} \
	  | awk 'NR>1' | cut -f 3 \
	  > {1}.{2}.jaccard" \
	 ::: `ls *.merge.bed` ::: `ls *.merge.bed`
```

This command will create a single file containing the pairwise Jaccard measurements from all 400 tests.

```
find . \
    | grep jaccard \
    | xargs grep "" \
    | sed -e s"/\.\///" \
    | perl -pi -e "s/.bed./.bed\t/" \
    | perl -pi -e "s/.jaccard:/\t/" \
    > pairwise.dnase.txt
```

A bit of cleanup to use more intelligible names for each of the samples.

```
cat pairwise.dnase.txt \
| sed -e 's/.hotspot.twopass.fdr0.05.merge.bed//g' \
| sed -e 's/.hg19//g' \
> pairwise.dnase.shortnames.txt
```

Now let’s make a 20x20 matrix of the Jaccard statistic. This will allow the data to play nicely with R.

```
awk 'NF==3' pairwise.dnase.shortnames.txt \
| awk '$1 ~ /^f/ && $2 ~ /^f/' \
| python make-matrix.py \
> dnase.shortnames.distance.matrix
```

## SRA toolkit使用 {#sra_tools}
 
SRA toolkit <https://trace.ncbi.nlm.nih.gov/Traces/sra/sra.cgi?view=software>根据服务器下载对应的二进制编码包。

CentOS下地址：<https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/2.9.0/sratoolkit.2.9.0-centos_linux64.tar.gz>。

常用的是`fastq-dump`，从NCBI的SRA数据库下载测序原始文件并转化为FASTQ格式供后续分析使用。

```
# --split-3: 若是双端测序则拆分
# --gzip: 拆分后压缩文件
# fastq-dump -v --split-3 --gzip SRR_number
fastq-dump -v --split-3 --gzip SRR502564
```

下面是我写的一个脚本，有3个用途。一是在`fastq-dump`下载过程中，如果断了可以再次启动下载；二是下载完成之后，给下载的文件进行重命名为方便识别的名字；三是清空下载缓存。

所需要的输入文件是一个2列文件，第一列为SRR号，第二列为样品名字，TAB键分割。

```
SRR2952884      Y25_root
SRR2952883      Y18_root
SRR2952882      Y12_root
SRR2952881      Y05_root
```

```
#!/bin/bash

set -x
set -e
set -u

usage()
{
cat <<EOF >&2
${txtcyn}
Usage:

$0 options${txtrst}

${bldblu}Function${txtrst}:

This script is used to download sra files from a file containing SRA
accession numbers and transfer SRA to fastq format.

The format of input file:

SRR2952884      Y25_root
SRR2952883      Y18_root
SRR2952882      Y12_root
SRR2952881      Y05_root

The second column will be treated as the prefix of final fastq files.

${txtbld}OPTIONS${txtrst}:
	-f	Data file with format described above${bldred}[NECESSARY]${txtrst}
	-z	Is there a header[${bldred}Default TRUE${txtrst}]
EOF
}

file=

while getopts "hf:z:" OPTION
do
	case $OPTION in
		h)
			usage
			exit 1
			;;
		f)
			file=$OPTARG
			;;
		?)
			usage
			exit 1
			;;
	esac
done

if [ -z $file ]; then
	usage
	exit 1
fi


#IFS="\t"

cat $file | while read -r -a array 
do
	sra="${array[0]}"
	name="${array[1]}"
	#echo $sra, $name
	#prefetch -v $sra
	#prefetch -v $sra
	#prefetch -v $sra
	#/bin/cp ~/ncbi/public/sra/${sra}.sra ${name}.sra
	while true
	do
		fastq-dump -v --split-3 --gzip ${sra}
		a=$?
		if [ "$a" == "0" ]; then break; fi
		sleep 5m
	done
	
	#/bin/cp ~/ncbi/public/sra/${sra}* .
	if [ "$a" == "0" ]
	then
		rename "${sra}" "${name}" ${sra}*
		/bin/rm ~/ncbi/public/sra/${sra}.sra
	fi
done
```


## 生信流程开发 {#bioinfo_pipeline}

最基本的是`Bash`脚本，把上面`call SNP`的命令放到一个`Bash`脚本文件中即可。另外可以使用`Makefile`和`Airflow`进行更高级一些的开发。

Airflow使用见 <http://blog.genesino.com/2016/05/airflow/>。

一篇不错的英文Makefile教程 <http://blog.genesino.com/2011/04/introduction-to-making-makefiles/>。

## 数据同步和备份 {#rsync}

### 原创拷贝scp {#scp}

最简单的备份方式，就是使用`cp` (本地硬盘)或 `scp` (远程硬盘)命令，给自己的结果文件新建一个拷贝；每有更新，再拷贝一份。具体命令如下：

```
cp -fur source_project project_bak
scp -r source_project user@remote_server_ip:project_bak
```

为了实现定期备份，我们可以把上述命令写入crontab程序中，设置每天的晚上23:00执行。对于远程服务器的备份，我们可以配置免密码登录，便于自动备份。后台输入免密码登录服务器，获取免密码登录服务器的方法。

```
# Crontab format
# Minute　　Hour　　Day　　Month　　Week　　command 
# * 表示每分/时/天/月/周
# 每天23:00 执行cp命令
0	23	*	*	*	cp -fur source_project project_bak
#	*/2	表示每隔2分分/时/天/月/周执行命令
#	每隔24小时执行cp命令
0	*/24	*	*	*	cp	-fur	source_project	project_bak
0	0	*/1	*	*	scp	-r	source_project	user@remote_server_ip:project_bak

# 另外crotab还有个特殊的时间
# @reboot: 开机运行指定命令
@reboot cmd
```

### 镜像备份和增量同步 rsync {#rsync1}

cp或scp使用简单，但每次执行都会对所有文件进行拷贝，耗时耗力，尤其是需要拷贝的内容很多时，重复拷贝对时间和硬盘都是个损耗。

rsync则是一个增量备份工具，只针对修改过的文件的修改过的部分进行同步备份，大大缩短了传输的文件的数量和传输时间。具体使用如下 ：

```
# 把本地project目录下的东西备份到远程服务器的/backup/project目录下
# 注意第一个project后面的反斜线，表示拷贝目录内的内容，不在目标目录新建project文件夹。注意与第二个命令的比较，两者实现同样的功能。
# -a: archive mode, quals -rlptgoD
# -r: 递归同步
# -p: 同步时保留原文件的权限设置
# -u: 若文件在远端做过更新，则不同步，避免覆盖远端的修改
# -L: 同步符号链接链接的文件，防止在远程服务器出现文件路径等不匹配导致的软连接失效
# -t: 保留修改时间
# -v: 显示更新信息
# -z: 传输过程中压缩文件，对于传输速度慢时适用
rsync -aruLptvz --delete project/ user@remoteServer:/backup/project
rsync -aruLptvz --delete project user@remoteServer:/backup/
```

rsync所做的工作为镜像，保证远端服务器与本地文件的统一。如果本地文件没问题，远端也不会有问题。但如果发生误删或因程序运行错误，导致文件出问题，而在同步之前又没有意识到的话，远端的备份也就没了备份的意义，因为它也被损坏了。误删是比较容易发现的，可以及时矫正。但程序运行出问题，则不一定了。

### 增量备份，记录各个版本 rdiff-backup {#rdiff_backup}

这里推荐一个工具rdiff-backup不只可以做增量备份，而且会保留每次备份的状态，新备份和上一次备份的差别，可以轻松回到之前的某个版本。唯一的要求就是，本地服务器和远端服务器需要安装统一版本的rdiff-backup。另外还有2款工具 duplicity和`Rsnapshot也可以做类似工作，但方法不一样，占用的磁盘空间也不一样，具体可查看原文链接中的比较。

具体的rdiff-backup安装和使用见<http://mp.weixin.qq.com/s/c2cspK5b4sQScWYMBtG63g>。

## References

* [高通量数据分析必备-基因组浏览器使用介绍 - 1](https://mp.weixin.qq.com/s/_5zoRvjku5pb9qtwrvlWYw)
* [高通量数据分析必备-基因组浏览器使用介绍 - 2](https://mp.weixin.qq.com/s/uzyccMorR6XWqjMsMd3Oaw)
* [高通量数据分析必备-基因组浏览器使用介绍 - 3](https://mp.weixin.qq.com/s/qdKxBAU__nbq8Ua0rLCEow)
* [测序文章数据上传找哪里](http://mp.weixin.qq.com/s/aDINq43Xwas_l4-AdY7xXg)
* [GO、GSEA富集分析一网打进](http://mp.weixin.qq.com/s/d1KCETQZ88yaOLGwAtpWYg)
* [GSEA富集分析 - 界面操作](http://mp.weixin.qq.com/s/3Nd3urhfRGkw-F0LGZrlZQ)
* [Bedtools使用简介](https://mp.weixin.qq.com/s/bIXom5bSDov-4sPqsTRc6A)
* [OrthoMCL鉴定物种同源基因 （安装+使用）](https://mp.weixin.qq.com/s/lC1KiRygr5RefMZLVPREdQ)
* [Rfam 12.0+本地使用 （最新版教程）](http://mp.weixin.qq.com/s/5OIRHA22ZLr5Z8bEhDiBqg)
* [轻松绘制各种Venn图](http://mp.weixin.qq.com/s/zn654JqG9OeO71rJUTDr2Q)
* [ETE构建、绘制进化树](http://mp.weixin.qq.com/s/DD1nZnx5mYxWGrohNgdPvQ)
* [psRobot：植物小RNA分析系统](http://mp.weixin.qq.com/s/kWkEQOX-6SKMAUQmAuc86w)
* [生信软件系列 - NCBI使用](http://mp.weixin.qq.com/s/4a5U8GdBoNFXkykL6m2EeA)
* [去东方，最好用的在线GO富集分析工具](https://mp.weixin.qq.com/s/l6j2encDfEQkt2UeNCMFhg)
* [2018 升级版Motif数据库Jaspar](https://mp.weixin.qq.com/s/S1SlhNfPvcXOwRQZvrm6GQ)
* [一文教会你查找基因的启动子、UTR、TSS等区域以及预测转录因子结合位点](https://mp.weixin.qq.com/s/vFO7uAtI6nh-zTW7RHCixA)

<!--chapter:end:05.biotools.Rmd-->

# 生物信息中Linux命令练习 {#bioinfo_linux}

```{r}
answer=T
```

* 进入sxbd目录，查看目录下的文件有哪些？
* 查看GTF文件的内容和格式 (如果没有，可在<ftp://ftp.ensembl.org/pub/release-91/gtf/homo_sapiens/Homo_sapiens.GRCh38.91.gtf.gz>下载。)
* 给每个区域的行首增加`chr`标签，并去掉`#`开头的行。

```
grep -v '^#' GRCh38.gtf | sed 's/^/chr/' >GRCh38.new.gtf
```

## 统计GTF文件中染色体数目？ {#gtf_chr}

```
ct@ehbio:~/sxbd$ cut -f1 GRCh38.new.gtf | uniq -c >chrCount.txt
ct@ehbio:~/sxbd$ awk '{print $2"\t"$1}' chrCount.txt 
chr1	236802
chr2	194223
chr3	160954
chr4	106152
chr5	115953
chr6	116635
chr7	122750
chrX	81525
chr8	95038
chr9	91333
chr11	159595
chr10	94467
chr12	154317
chr13	38817
chr14	93293
chr15	97353
chr16	125435
chr17	166619
chr18	47336
chr20	57175
chr19	163738
chrY	7167
chr22	56380
chr21	28928
chrMT	144
chrKI270728.1	120
chrKI270727.1	88
chrKI270442.1	6
chrGL000225.1	3
chrGL000009.2	8
chrGL000194.1	26
chrGL000205.2	17
chrGL000195.1	27
chrKI270733.1	12
chrGL000219.1	12
chrGL000216.2	3
chrKI270744.1	3
chrKI270734.1	96
chrGL000213.1	52
chrGL000220.1	12
chrGL000218.1	8
chrKI270731.1	11
chrKI270750.1	3
chrKI270721.1	25
chrKI270726.1	11
chrKI270711.1	151
chrKI270713.1	20
ct@ehbio:~/sxbd$ awk '/chr[0-9XYM]/' chrCount.txt 
 236802 chr1
 194223 chr2
 160954 chr3
 106152 chr4
 115953 chr5
 116635 chr6
 122750 chr7
  81525 chrX
  95038 chr8
  91333 chr9
 159595 chr11
  94467 chr10
 154317 chr12
  38817 chr13
  93293 chr14
  97353 chr15
 125435 chr16
 166619 chr17
  47336 chr18
  57175 chr20
 163738 chr19
   7167 chrY
  56380 chr22
  28928 chr21
    144 chrMT
ct@ehbio:~/sxbd$ awk '/chr[0-9XYM]/' chrCount.txt | sed 's/  *\([0-9]*\) \(chr.*\)/\2\t\1/' 
chr1	236802
chr2	194223
chr3	160954
chr4	106152
chr5	115953
chr6	116635
chr7	122750
chrX	81525
chr8	95038
chr9	91333
chr11	159595
chr10	94467
chr12	154317
chr13	38817
chr14	93293
chr15	97353
chr16	125435
chr17	166619
chr18	47336
chr20	57175
chr19	163738
chrY	7167
chr22	56380
chr21	28928
chrMT	144
```

## 统计GTF文件中基因数目？ {#gtf_num_gene}

```
ct@ehbio:~/sxbd$ time cut -f 3 GRCh38.new.gtf | sort | uniq -c
 712821 CDS
1199851 exon
 144659 five_prime_utr
  58302 gene
    119 Selenocysteine
  83743 start_codon
  75493 stop_codon
 137545 three_prime_utr
 200310 transcript

real	0m8.314s
user	0m8.259s
sys	0m0.679s
# 更快
ct@ehbio:~/sxbd$ time awk '{a[$3]+=1}END{for(i in a) print i,a[i];}' GRCh38.new.gtf
five_prime_utr 144659
exon 1199851
three_prime_utr 137545
CDS 712821
gene 58302
start_codon 83743
Selenocysteine 119
stop_codon 75493
transcript 200310

real	0m1.898s
user	0m1.504s
sys	0m0.394s


ct@ehbio:~/sxbd$ awk '{if(a[$3]=="") a[$3]=1; else a[$3]=a[$3]+1;}END{for(i in a) print i,a[i];}' GRCh38.new.gtf
```

## 计算GTF中外显子总长度？ {#gtf_exon_length}

```
# 这个是冗余的外显子，后面在计算非冗余外显子
ct@ehbio:~/sxbd$ awk '{if($3=="exon") sum+=$5-$4+1;}END\
	{print "Total redundant exon length", sum;}' GRCh38.new.gtf
```

* 计算GTF文件中每个基因的转录本数目？

```
# 第一个办法：基因和对应的转录本是排序好的，直接判断计算就可以
awk 'BEGIN{OFS=FS="\t";}{if($3=="gene" && count>0) {print count; count=0;} else \
	{if($3=="transcript") count+=1;}}END{print count}' GRCh38.new.gtf

# 第二个方法：取出所有基因和转录本名字
sed 's/"/\t/g' GRCh38.new.gtf | awk '$3=="transcript"' | cut -f 10,14 | cut -f 1 | uniq -c

# 第三个方法：与第二个类似，但使用了groupBy

sed 's/"/\t/g' GRCh38.new.gtf | awk '$3=="transcript"' | cut -f 10,14 | \
	bedtools groupby -g 1 -c 1,2 -o count,collapse | head
ENSG00000223972	2	ENST00000456328,ENST00000450305
ENSG00000227232	1	ENST00000488147
ENSG00000278267	1	ENST00000619216
ENSG00000243485	2	ENST00000473358,ENST00000469289
ENSG00000284332	1	ENST00000607096
ENSG00000237613	2	ENST00000417324,ENST00000461467
ENSG00000268020	1	ENST00000606857
ENSG00000240361	2	ENST00000642116,ENST00000492842
ENSG00000186092	2	ENST00000641515,ENST00000335137
ENSG00000238009	5	ENST00000466430,ENST00000477740,ENST00000471248,ENST00000610542,ENST00000453576

sed 's/"/\t/g' GRCh38.new.gtf | awk '$3=="transcript"' | cut -f 10,14 | \
	bedtools groupby -g 1 -c 1,2 -o count,collapse >geneTrCount.txt

```

## 计算GTF文件中基因所拥有的平均转录本数目 {#gtf_transcript_num}

```
awk 'BEGIN{OFS=FS="\t"}{sum+=$2}END{print sum/NR;}' geneTrCount.txt
# 3.43573
```

## 生成一个多行Fasta测试序列供后续运算 (也可使用我们前面提供的脚本生成) {#fasta}

```
cat <<END >test.fa
>id1
ACGCATGGGGGGGGGGGGGGGGG
AGTATGGTCCAGTA
>id11
AGTGGGGGGGGGGGGGGGGTTCCT
cgactaggcagtctgagttga
>id21
AGTGGGGGGGGGGGGGGGGTTCCT
cgactaggcagtctgagttga
END
```

## `test.fa`中的序列全转成大写 {#fasta_uppercase}

```
# \U 转换为大写
# & 表示所有匹配内容
sed -i '/^[^>]/ s/.*/\U&/' test.fa
```

## 计算多行FASTA文件`test.fa`中每条序列长度 {#fasta_len}

输出类似`genome.txt`格式的文件(文件有两列，第一列为序列ID，第二列为序列长度) 

```
# 计算一个输出一个
awk 'BEGIN{OFS="\t"; size=0;}{if($0~/>/) {if(size>0) print geneName,size; \
	geneName=$0; sub(">","",geneName); size=0;} else \
	{size+=length}}END{print geneName,size}' test.fa
```

```
# 全部计算完存储起来再输出
awk 'BEGIN{OFS="\t";}{if($0~/>/) {geneName=$0; sub(">","",geneName); size[geneName]=0;} \
	else {size[geneName]+=length($0)}}END\
	{for (geneName in size) print geneName,size[geneName]}' test.fa
```

## 多行FASTA转单行FASTA序列 {#fasta_format}

```
# conditions?true_value:false_value 三目运算符，条件为真时，返回冒号前结果，否则冒号后结果
# 对于非第一行的>，输出前先输出一个换行
awk '/^>/&&NR>1{print "";}{printf "%s",/^>/?$0"\n":$0}' test.fa >singleLine.fa
```


## 取出单行FASTA文件中序列长度大于40的序列的名字 {#fasta_name}

```
awk 'BEGIN{OFS="\t";}{if($0~/>/) {geneName=$0; sub(">","",geneName); } else \
	{if (length($0)>40) print geneName;}}' singleLine.fa
```


## 分别用`awk`和`grep`从`test.fa`中提取给定ID对应的序列 {#id_extract}

```
ID list:
id1
id21
```

## 利用AWK对基因表达数据进行标准化 {#standard}

```
cat <<END | sed 's/  */\t/g' >test.expr
ID	sampleA	sampleB	sampleC
A	1	2	3
B	4	5	6
C	6	7	8
D	10	11	12
END
```

```
# 单列
awk 'ARGIND==1{if(FNR>1) sum=sum+$2;}\
	 ARGIND==2{if(FNR>1) {$3=$2/sum;} print $0;}' test.expr test.expr

# 多列
awk 'ARGIND==1{if(FNR>1) {for(i=2;i<=NF;i++) sum[i]=sum[i]+$i;}}\
	 ARGIND==2{if(FNR>1) for(i=2;i<=NF;i++) {$i=$i/sum[i];} print $0;}' \
	 test.expr test.expr
```

## 写出3种写法，去掉上一题`test.expr`矩阵中的第一行？ {#skip_first_row}

```
awk 'FNR>1' test.expr

tail -n +2 test.expr

sed -n '2,$p' test.expr
```

## 分别用`awk`和`sed`给`test.expr`矩阵加上标题行？ {#add_row}

```
sed '1 iheaderline' test.expr
awk '{if(FNR==1} print "headerline"; print $0' test.expr
```

## 给定一个`BAM`文件，怎么计算有多少基因组区域被测到了？平均测序深度是多少？ {#bam}

```
bedtools genomecov -ibam ../bio/map.sortP.bam -bga 
```

## 如何使用`bedtools`的其它工具或其它Linux命令实现`bedtools jaccard`子功能？{#jaccard}

`bedtools jaccard`计算的是给定的两个`bed`文件之间交集区域(intersection)占总区域(union-intersection)的比例(jaccard)和交集的数目(n_intersections)。

```
ct@localhost:~/bedtools$ cat test1.bed 
chr1	1	100
chr2	1	50
chr3	20	50
ct@localhost:~/bedtools$ cat test2.bed 
chr1	50	150
chr3	1	50
chr4	1	50
chr5	1	50
ct@localhost:~/bedtools$ bedtools jaccard -a test1.bed -b test2.bed 
intersection	union-intersection	jaccard	n_intersections
80	296	0.27027	2
ct@localhost:~/bedtools$ bedtools intersect -a test1.bed -b test2.bed -wao \
	| awk '{sum+=$NF}END{print sum;}'
80
ct@localhost:~/bedtools$ cat test1.bed test2.bed | awk '{sum+=$3-$2}END{print sum;}'
376
```




<!--chapter:end:07-bioinfo.Rmd-->

# Supplemental

serverInfo.sh

```
#!/bin/bash

echo "This lists the information of this computer."

echo

echo "Hostname is $(tput setaf 3)`hostname`$(tput sgr0),\
Ip address is $(tput setaf 3)\
`/sbin/ifconfig | sed -n '2p' | cut -d ':' -f 2 | cut -d ' ' -f 1`.
$(tput sgr0)"


nuclear=`uname -a | cut -d ' ' -f 3`
bitInfo=`uname -a | cut -d ' ' -f 12`

if test $bitInfo == "x86_64"; then
    bit=64
else
    bit=32
fi

echo "The $(tput bold)${bit}$(tput sgr0) bit operating \
system is $(tput bold) `head -n 1 /etc/issue`\
$(tput sgr0), Nuclear info is $(tput setaf 1)\
${nuclear}$(tput sgr0)."

echo

echo "The CPU is$(tput setaf 4)`sed -n '5p' /proc/cpuinfo \
| cut -d ':' -f 2 | sed 's/[ ] */ /g'`$(tput sgr0)."

echo

echo "There are $(tput setaf 5)\
`cat /proc/cpuinfo | grep "physical id" | sort | uniq \
| wc -l`$(tput sgr0) physical cpu, \
each physical \
cpu has$(tput setaf 5)`sed -n '12p' /proc/cpuinfo | \
cut -d ':' -f 2`$(tput sgr0) cores,\
$(tput setaf 5)`sed -n '10p' /proc/cpuinfo | \
cut -d ':' -f 2`$(tput sgr0) threads."

echo

echo "There are $(tput setaf 5)\
`cat /proc/cpuinfo | grep "cpu cores" | wc -l`$(tput sgr0) logical cpu."

mem=`head -n 1 /proc/meminfo | cut -d ':' -f 2 | sed 's/^ *//g' | cut -d ' ' -f 1`
memInM=$(echo "$mem/1024/1024" | bc -l)

echo

echo "The memory of this server is $(tput setaf 5)${memInM}$(tput sgr0)G."

echo

echo "The disk information is :"

echo "`df -h`"

```

<!--chapter:end:08-supplemental.Rmd-->

# 生信教程文章集锦

## 生信宝典

生信的作用越来越大，想学的人越来越多，不管是为了以后发展，还是为了解决眼下的问题。但生信学习不是一朝一夕就可以完成的事情，也许你可以很短时间学会一个交互式软件的操作，却不能看完程序教学视频后就直接写程序。也许你可以跟着一个测序分析流程完成操作，但不懂得背后的原理，不知道什么参数需要修改，结果可以出来，却把我不住对还是错。

学习生信从来就不是一个简单的事，需要做好持久战的心理准备。

在学习时，我们都希望由浅入深的逐步深入，不断地练习和实践，这就是为什么我们需要一本书，因为书很系统。但生信发展的历史短于计算机编程的历史，如果想要一门程序设计的入门数据，每种语言都可以找到几本。但想要一个囊括生信的书，就有些难了。本身生信跨领域，需要多学科的知识，而其内部又有不少分子，都囊括了太大，包括的少又有些隔靴搔痒的感觉。

我们当时都是零基础下自学Linux,  自学Python，自学R，自学高通量测序；这些学习经历，之前都零星地记录在博客里。现在回头去看几年前自己记录的东西，觉得好简单，而当时却费了很大的力气。这些零星的随手记，当时也只是为了自己看，到现在确实只有自己能看得懂，不便惠及更多的人。

因此我们创建了生信宝典，希望从不同的角度传播知识。这个不同有三点含义，一是形式上的不同，摒弃之前主编们单人作战想写啥就写啥，而是有组织有计划的内容聚合，提供一系列的教程，由入门到提高。二是内容的不同，不去用网上现有教程的通用数据做例子，而是拿实际生物数据，讲述如何解释生信中普遍碰到的问题，讲述如何处理自己的数据。三是立足点不同。在写作时，我们回到了当年，在回忆中用整个阶段的学习去指导当初的那个小白，从那些会了的人觉得微不足道而不会的人又迈不过的坎入手，直击痛点。知识点的收录依据不是是否炫酷，是否难，而是是否必要。如果必要，再简单，也要提及；如果不必要，再炫酷，也暂不纳入。

通过大量的生信例子、关键的注释和浓缩的语句形成下面的一系列学习教程。每一篇内容都不多，可以当做小说阅读，也可以跟着去练，反复几遍，每读一次都会有不同的收获和体会。

### 系列教程

* [生物信息之程序](http://mp.weixin.qq.com/s/xoLBg0pI9seEksa0hMXi0A)
* [如何优雅的提问](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483955&amp;idx=1&amp;sn=946438376f94af6e8861b2b42701914e&amp;chksm=ec0dc7b9db7a4eafbef28fac1fb260f6f876f0ba674828784ac827dd23f9317f5a2d59d38bc0#rd)
* [生信宝典视频教程](http://mp.weixin.qq.com/s/C4EBufEtFF6bhBKrH8NXng)
* [好色之旅-画图三字经](https://mp.weixin.qq.com/s/bsvB1k17Izom2ldgdwXrdg)
* [转录组分析的正确姿势](http://mp.weixin.qq.com/s/Kx0gaU2x4pWjBq2I2Ffe6Q)
* [生信的系列教程](https://mp.weixin.qq.com/s/VguRtaGpEcaNzmZEi48gLg)
* [生信的系列书籍](http://mp.weixin.qq.com/s/IiehgNu3JGVTDa079ll1SQ)
* [文章用图的修改和排版 (1)](https://mp.weixin.qq.com/s/IJNyhinakY0lSXgCN7b9ug)
* [文章用图的修改和排版 (2)](http://mp.weixin.qq.com/s/HTsufk71U3wf14OOWSKEeQ)
* [简单强大的在线绘图](http://mp.weixin.qq.com/s/Ld2dNcaWR-jIzolHw_tkHA)
* [简单强大的在线绘图-升级版](http://mp.weixin.qq.com/s/pTHHqxuf0y1MCCCBaZjt9A)
* [论文图表基本规范](http://mp.weixin.qq.com/s/SCT4oso_vI0UNIJZTaG95g)
* [学术图表的基本配色方法](http://mp.weixin.qq.com/s/hq5p8Lqzn9Km2qVRLW2dVQ)
* [英语写作常见错误总结和学习视频](https://mp.weixin.qq.com/s/37dMnfA6RTSybzkzKnambw)
* [教育部推出首批490门“国家精品在线开放课程](http://mp.weixin.qq.com/s/JKn4kRiXYz6RKzQbTMVYlg)

### NGS分析工具评估

* [39个转录组分析工具，120种组合评估(转录组分析工具哪家强-导读版)](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&mid=2247484106&idx=1&sn=687a0def51f6ea91a335754eb3dc9ca9&chksm=ec0dc740db7a4e564e5b1e93a36e5d9447581e262eec9c2983d1d4e76788d673c9c07dec8f8e#rd)
* [39个转录组分析工具，120种组合评估(转录组分析工具大比拼 （完整翻译版）)](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&mid=2247484106&idx=2&sn=a09fa127d625c4072ae0343795346c56&chksm=ec0dc740db7a4e56821f32f60700027c85db46e81089721d1bbe23ceefa86160d9661c2f2d4c#rd)
* [无参转录组分析工具评估和流程展示](http://mp.weixin.qq.com/s/4HANWJY4oL7jGziroHfEpQ)

### 宏基因组教程

* [微生物组入门必读+宏基因组实操课程](http://mp.weixin.qq.com/s/sQyl5EctXFB95Oxg8YIasg)
* [扩增子图表解读-理解文章思路](http://mp.weixin.qq.com/s/oiVHO2S1JgYrKXPDU6fH2g)
* [扩增子分析流程-把握分析细节](http://mp.weixin.qq.com/s/KrYyy3jjzAL0rQzVfV6h4A)
* [扩增子统计绘图-冲击高分文章](http://mp.weixin.qq.com/s/6tNePiaDsPPzEBZjiCXIRg)
* [宏基因组分析教程](http://mp.weixin.qq.com/s/bcyvhFrNr6niqD13rQfZeg)
* [4500元的微生物组培训资料](http://mp.weixin.qq.com/s/li7SdZVaCEyFQF8h6MMh2A)

### 系列宣传

* [转录组分析的正确姿势](http://mp.weixin.qq.com/s/Kx0gaU2x4pWjBq2I2Ffe6Q)
* [120分的转录组考题，你能得多少](http://mp.weixin.qq.com/s/BmtIOcIzIutufFilbJIgEA)
* [生物信息作图系列R、Cytoscape及图形排版和Python编程培训研讨班开课了](http://mp.weixin.qq.com/s/x-DInL34BbKUR-2UD2Ec3g)
* [维密摔倒不可怕，关键时有人搀一把，坚持走下去](http://mp.weixin.qq.com/s/4mWms-r5kg8kN7kJ60zZDQ)
* [生物信息作图系列 - R、网络图及文章图形排版](http://mp.weixin.qq.com/s/IS3uVvulYsCbyuV64bcdLg)
* [易生信转录组培训总结和优惠分享](http://mp.weixin.qq.com/s/TLxzWyKImJhMINkNxLk6Yg)
* [生物信息9天速成班 — 你也可以成为团队不可或缺的人](http://mp.weixin.qq.com/s/aRuaX-qXlHkF2vme9QqWag)
* [Python没有捷径，但可以加速，零基础九天你也可以会编程](http://mp.weixin.qq.com/s/vDAHTitasAUphWsrS2Uzlg)
* [小学生都学Python了，你还不知道怎么开始-资源帖](http://mp.weixin.qq.com/s/1JlAROpOCBwaG574EwvkVw)
* [一个月学会Python的Quora指南和资料放送](http://mp.weixin.qq.com/s/VTVVfpNSGgOJLNxeIqmFiw)
* [扩增子分析基本流程和结果解读](http://mp.weixin.qq.com/s/cCW7HKjU8IetBgMoiYUeCQ)
* [微生物组——扩增子分析专题实战开课啦](http://mp.weixin.qq.com/s/y_KFJZlKSCJFmbuvNJQyAw)
* [如何入门生信Linux](http://mp.weixin.qq.com/s/V7vmnOv9rwKMoHtlPMo5nQ)
* [3分和30分文章差距在哪里？](https://mp.weixin.qq.com/s/kD-x7K4hI5KMgGXikyLt0Q)

### 生信生物知识

* [生物研究中不可缺少的数字概念，多少，多大，多快](http://mp.weixin.qq.com/s/JQBZv6snTkZzFwEG12riWw)

### 文献精读

* [CRISPR-CAS9发展历程小记](http://mp.weixin.qq.com/s/brx-i-Bbgp-XYwn5SkQLwA)
* [一场大病引起的诺贝尔2017年生理学奖角逐](http://mp.weixin.qq.com/s/T9Q6CUCt-wBoUCEwSBZALg)
* [Science搞反狗脑 - 人脑和狗脑一样？](https://mp.weixin.qq.com/s/zymhxusKNDZ9XynNGAlRcA)
* [一篇压根不存在的文献被引用400次？！揭开" 幽灵文献" 的真面目](http://mp.weixin.qq.com/s/OgAhb_UGUp7tZvQARbmLLg)
* [基于人工智能的文献检索，导师查找，更聪明](http://mp.weixin.qq.com/s/ikU0mVyX6BQNgljD1jCrRA)
* [GeenMedical：文献查询、筛选、引用排序、相似文献、全文下载、杂志分区、影响因子、结果导出、杂志评述、直接投稿，一站服务](http://mp.weixin.qq.com/s/hc8g64aHN7qv8YhVfrsuvQ)
* [YANDEX搜索，不翻墙稳定使用近谷歌搜索](http://mp.weixin.qq.com/s/fZ2Nm7Wck5mZLiESHcPusA)
* [Nature我的研究对后人毫无用途：21%的学术论文自发布后从未被引用](http://mp.weixin.qq.com/s/NMpqbKfXy002eMz9b9y1zg)
* [SCI-HUB镜像,  SSH隧道访问学校内网](https://mp.weixin.qq.com/s/NGsFlVb0fN1O37ecaYwxsA)
* [为了速成生物学，一位程序员探索了"爆款"基因背后的秘密](http://mp.weixin.qq.com/s/fFO6MX6Ttijx0bfYS5eQ-Q)

### Linux 

* [Linux-总目录](http://mp.weixin.qq.com/s/hEYU80fPf1eD5OWL3fO4Bg)
* [Linux-文件和目录](http://mp.weixin.qq.com/s/yKP1Kboji9N4p2Sl1Ovj0Q)
* [Linux-文件操作](http://mp.weixin.qq.com/s/4bYMzJclf_xHpqdrlbvAdA)
* [Linux文件内容操作](http://mp.weixin.qq.com/s/QFgINAYcQA9kYYSA28wK-Q)
* [Linux-环境变量和可执行属性](http://mp.weixin.qq.com/s/poFpNHQgHDr0qr2wqfVNdw)
* [Linux - 管道、标准输入输出](http://mp.weixin.qq.com/s/zL9Mw_2ig48gHrIjKM0CMw)
* [Linux - 命令运行监测和软件安装](http://mp.weixin.qq.com/s/TNU7X2mhfVVffaJ7NRBuNA)
* [Linux-常见错误和快捷操作](http://mp.weixin.qq.com/s/cDIN4_R4nETEB5irmIGFAQ)
* [Linux-文件列太多，很难识别想要的信息在哪列；别焦急，看这里。](http://mp.weixin.qq.com/s/1QaroFE7AH1pREuq-k2YAw)
* [Linux-文件排序和FASTA文件操作](http://mp.weixin.qq.com/s/R1OHRhZoDJuAdyVdJr2xHg)
* [Linux-应用Docker安装软件](http://mp.weixin.qq.com/s/HLHiWMLaWtB7SOJe_jP3mA)
* [Linux服务器数据定期同步和备份方式](http://mp.weixin.qq.com/s/c2cspK5b4sQScWYMBtG63g)
* [VIM的强大文本处理方法](https://mp.weixin.qq.com/s/4lUiZ60-aXLilRk9--iQhA)
* [Linux - Conda软件安装方法](http://mp.weixin.qq.com/s/A4_j8ZbyprMr1TT_wgisQQ)
* [查看服务器配置信息](http://mp.weixin.qq.com/s/xq0JfkHJJeHQk1acjOAJUQ)
* [Linux - SED操作，awk的姊妹篇](http://mp.weixin.qq.com/s/cywkIeRbhkYTZvkwTeIVSA)
* [Linux - 常用和不太常用的实用awk命令](http://mp.weixin.qq.com/s/8wD14FXt7fLDo1BjJyT0ew)
* [Bash概论 - Linux系列教程补充篇](http://mp.weixin.qq.com/s/lWNp_6W_jLiogmtlk9nO2A)

### CIRCOS系列

* [CIRCOS圈图绘制 - circos安装](http://mp.weixin.qq.com/s/OEBJU3BiQdQOeN_tD2o7sA)
* [CIRCOS圈图绘制 - 最简单绘图和解释](http://mp.weixin.qq.com/s/2E1Y5-cEdptkQGVm0bxKbQ)
* [CIRCOS圈图绘制 - 染色体信息展示和调整](https://mp.weixin.qq.com/s/o_3DyYdSubWCh5FfoVKBOg)
* [CIRCOS增加热图、点图、线图和区块属性](http://mp.weixin.qq.com/s/6L8wmsy0eOxtiAEs3hYgCA)

### R统计和作图

* [在R中赞扬下努力工作的你，奖励一份CheatShet](http://mp.weixin.qq.com/s/x3tWrQPriLRFXO8ZaD93EQ)
* [别人的电子书，你的电子书，都在bookdown](http://mp.weixin.qq.com/s/u8WfC4xQ562Uekhs4WVBoQ)
* [R语言 - 入门环境Rstudio](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483882&amp;idx=1&amp;sn=e16903b4b745a1ef51855be3824149f6&amp;chksm=ec0dc460db7a4d76a70bd4ca2d250f147225252ee963d3e577affaebeeb81dea1ff639d5e9aa#rd)
* [R语言 - 热图绘制 (heatmap)](http://mp.weixin.qq.com/s/mNSkf1rjWTCtE1pIOuI2rA)
* [R语言 - 基础概念和矩阵操作](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483891&amp;idx=1&amp;sn=40daf6435398c4d9a41f332e9bba4915&amp;chksm=ec0dc479db7a4d6fec413bfb90a4660eb035b440d2bbee998114f7af29e3b3338a8adf62540a#rd)
* [R语言 - 热图简化](https://mp.weixin.qq.com/s/_9LKs6t6rcjzokF_0gneSA)
* [R语言 - 热图美化](http://mp.weixin.qq.com/s/lKrhvYrwn93esC6MA3bHWw)
* [R语言 - 线图绘制](http://mp.weixin.qq.com/s/YB-9tE4ut9RN0yfS8qBhtQ)
* [R语言 - 线图一步法](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483947&amp;idx=1&amp;sn=7cf0252efff5433447507b977fcaff97&amp;chksm=ec0dc7a1db7a4eb77a269709bdf2c8ab51bcad89aa780ec0be171a333e1cb8f3cc27eff277a1#rd)
* [R语言 - 箱线图（小提琴图、抖动图、区域散点图）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483964&amp;idx=1&amp;sn=ee52ac37fb9a919f5c75c0abe2a49ad4&amp;chksm=ec0dc7b6db7a4ea0a51306347fc43265c41fda3eeaf4764ddc3795546371327579676cd74a38#rd)
* [R语言 - 箱线图一步法](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483971&amp;idx=1&amp;sn=1b40a1137ccb8b2fa1ab3eb1d0f05de9&amp;chksm=ec0dc7c9db7a4edf16ea4966b9acb7f23cd23bd6a2e59450ae11bdac899fa2fceb124264dcf4#rd)
* [R语言 - 火山图](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483996&amp;idx=1&amp;sn=9a29d52e78e9acffeb0a78077a14f9f2&amp;chksm=ec0dc7d6db7a4ec0163259e81e4ded54875a5dd8adaafbc6975a86c71223d863627ba37801e5#rd)
* [R语言 - 富集分析泡泡图 （文末有彩蛋）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483978&amp;idx=1&amp;sn=e0c158c0e92375553036cc37f4987e40&amp;chksm=ec0dc7c0db7a4ed6ac593493b7d8b52f11f2feb92d24fa00d19527fbb6f95b24f7e313ef9440#rd)
* [R语言 - 散点图绘制](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484056&amp;idx=1&amp;sn=f9b2b4f7495b432e9294b7cbf42eaf33&amp;chksm=ec0dc712db7a4e04769d322558364b4b401b0a8153097c7252e83170e9201a31c2a7abbaf101#rd)
* [一文看懂PCA主成分分析](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484036&amp;idx=1&amp;sn=22ee356d0c9680d56dada1b777985ed2&amp;chksm=ec0dc70edb7a4e182a21475e9ddcde35b907c291549cc8c2e767be260af445ff5455aa358b04#rd)
* [富集分析DotPlot，可以服](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484063&amp;idx=1&amp;sn=f4e93d428e4910b4abbee9c0430cd170&amp;chksm=ec0dc715db7a4e0318b388ba2ab3d51677741421c42ada474a0ac6046a0699283014eae84b6f#rd)
* [R语言 - 韦恩图](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&mid=2247484076&idx=1&sn=fa5af19a2a4db4b0c5c7f145bf93ca57&chksm=ec0dc726db7a4e30fe7a0492ed9ea8eb5fa1c34641b1442a2da003efde0546b30c48fde3f118#rd)
* [R语言 - 柱状图](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484134&amp;idx=1&amp;sn=ffb41298eae74834af2f5dad05d37921&amp;chksm=ec0dc76cdb7a4e7a852ac0670532c12c690399f140a2335f640eaf01f7da26bc5480941686a9#rd)
* [R语言 - 图形设置中英字体](http://mp.weixin.qq.com/s/NAwyvtTS7t5rRU7KKBwHTA)
* [R语言 - 非参数法生存分析](http://mp.weixin.qq.com/s/_Dy9Yn8fc8I0rASGxH5x9A)
* [基因共表达聚类分析和可视化](http://mp.weixin.qq.com/s/ST2SAmfKOptpJOHS8podmQ)
* [R中1010个热图绘制方法](http://mp.weixin.qq.com/s/N7oLvJ1oPIImgybJVVSxXg)
* [还在用PCA降维？快学学大牛最爱的t-SNE算法吧, 附Python/R代码](http://mp.weixin.qq.com/s/alBfj3Y08qCnZoz5JwVdaw)
* [一个函数抓取代谢组学权威数据库HMDB的所有表格数据](http://mp.weixin.qq.com/s/rYjcsfHrbcAhaFpQI5Yc6g)
* [文章用图的修改和排版](https://mp.weixin.qq.com/s/IJNyhinakY0lSXgCN7b9ug)
* [network3D: 交互式桑基图](http://mp.weixin.qq.com/s/3okqP0viU3EVML9p1bkQlw)
* [network3D 交互式网络生成](https://mp.weixin.qq.com/s/rK5SolI0xGisvBCIcb448A)

### 扩增子三步曲

* [1图表解读-理解文章思路](http://mp.weixin.qq.com/s/oiVHO2S1JgYrKXPDU6fH2g)  
* [2分析流程-把握分析细节](http://mp.weixin.qq.com/s/KrYyy3jjzAL0rQzVfV6h4A)  
* [扩展1：视频教程-夯实分析思路](http://mp.weixin.qq.com/s/SxWl0qBJgg8ziZUFDmKvpQ)  
* [扩展2：QIIME2教程-了解分析趋势](http://mp.weixin.qq.com/s/wkn-91BVOSWZLRvlcaaEgg)  
* [3统计绘图-冲击高分文章](http://mp.weixin.qq.com/s/6tNePiaDsPPzEBZjiCXIRg)  

### 宏基因组分析专题

* [1背景知识-Shell入门与本地blast实战](http://mp.weixin.qq.com/s/jASOBPzpwYCL-fWNUJJp8g)
* [2数据质控fastqc,  Trimmomatic,  MultiQC,  khmer](http://mp.weixin.qq.com/s/3O01eNMe79J_kUTaJjP6ag)
* [3组装拼接MEGAHIT和评估quast](http://mp.weixin.qq.com/s/NMKX0iDuR_qOzmLXxC8MEQ)
* [4基因注释Prokka](http://mp.weixin.qq.com/s/1TM61IrzrpVb5KhZ5A0kZQ)
* [5基于Kmer比较数据集sourmash](https://mp.weixin.qq.com/s/Rmx-z1zxj7GF9ivJGWVvLg)
* [6不比对快速估计基因丰度Salmon](http://mp.weixin.qq.com/s/2fwEtnEsBi5cJ65xyeoXxw)
* [7bwa序列比对,  samtools查看,  bedtools丰度统计](http://mp.weixin.qq.com/s/rdTFTFg0rZOIa2_tuFEOUA)
* [8分箱宏基因组binning,  MaxBin,  MetaBin,  VizBin](http://mp.weixin.qq.com/s/rZitcvykAlxnsNEzsW5JRg)
* [9组装assembly和分箱bin结果可视化—Anvio](http://mp.weixin.qq.com/s/FesH_mCunpZLpKC2pIg1UQ)
* [10绘制圈图-Circos安装与使用](http://mp.weixin.qq.com/s/FJlKY3kU5Fm6bYkjtwRkEw)
* [MetaPhlAn2分析有参宏基因组](http://mp.weixin.qq.com/s/xSjFGwcr1XIAZKdByJAWmQ)

### NGS基础

* [NGS基础 - FASTQ格式解释和质量评估](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484047&amp;idx=1&amp;sn=3e2a79d9f56040a57ac2e16cf1923b54&amp;chksm=ec0dc705db7a4e133e6e91de9ac11a6c0690f03d7b3b760b358e9b0d1a2d57974599419d9fff#rd)
* [NGS基础 - 高通量测序原理](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484034&amp;idx=1&amp;sn=e7680ee935f8603214227b37eeb2c567&amp;chksm=ec0dc708db7a4e1eca4e38845381f328c49c84a90ad6580c3ba3761511772636e5ec0f185931#rd)
* [NGS基础 - 参考基因组和基因注释文件](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484148&amp;idx=1&amp;sn=525233898721a9c3ebdf275babf14944&amp;chksm=ec0dc77edb7a4e686440e0cbe5fbf39f554c4183dc30e7870ab7584e285f4e018dd94b680f79#rd)
* [NGS基础 - GTF/GFF文件格式解读和转换](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484166&amp;idx=1&amp;sn=417e155672bd718def86003b16bf0078&amp;chksm=ec0dc68cdb7a4f9a6bcb62c18797a69040173e2b0af20f1cf87d3e0d75e3adee03c7ff524dc5#rd)
* [本地安装UCSC基因组浏览器](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484167&amp;idx=1&amp;sn=ef9699899164d23013d92b61331c6562&amp;chksm=ec0dc68ddb7a4f9bfb83b9942196622f8b8f52b041d3f4a12786e6464752fbeaf64c9a640e39#rd)
* [测序数据可视化 (一)](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483946&amp;idx=1&amp;sn=3f95769229f28a91ed8bf5889e2181be&amp;chksm=ec0dc7a0db7a4eb64d08c7799cfe698a1662e6d0d935a8b91c6c969aae86900df4decc469a0d#rd)
* [测序文章数据上传找哪里](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483843&amp;idx=1&amp;sn=43770d21f6c2da2393c31cd55fdbe31e&amp;chksm=ec0dc449db7a4d5f723842286bf7feab7830eba5d9778d351569810a069e5ace76040f94a6bd#rd)
* [GO、GSEA富集分析一网打进](http://mp.weixin.qq.com/s/d1KCETQZ88yaOLGwAtpWYg)
* [GSEA富集分析 - 界面操作](http://mp.weixin.qq.com/s/3Nd3urhfRGkw-F0LGZrlZQ)
* [去东方，最好用的在线GO富集分析工具](https://mp.weixin.qq.com/s/l6j2encDfEQkt2UeNCMFhg)
* [生信软件系列 - NCBI使用](http://mp.weixin.qq.com/s/4a5U8GdBoNFXkykL6m2EeA)

### 癌症数据库

* [UCSC XENA - 集大成者(TCGA, ICGC)](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484383&amp;idx=1&amp;sn=09c58de206f409fa375fb7af94d0084c&amp;chksm=ec0dc655db7a4f438cb7e53f281cb5c6bf2484619b3c72d7eafe064ea6a342f69587353531af#rd)
* [ICGC数据库使用](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484378&amp;idx=1&amp;sn=eb6a0f890326898b2fb0867c58f0cf90&amp;chksm=ec0dc650db7a4f46a0a265ec96b73f367d45f86318087507eef7dde117a369cb7ad427bebb1e#rd)
* [TCGA数据库在线使用](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484304&amp;idx=1&amp;sn=6ad44dafdc7613e33e13aac48edb32aa&amp;chksm=ec0dc61adb7a4f0c504f3aeb207132aef479572ea756ce15868cbc57f88e9ea25102752b646a#rd)
	
### Python

* [Python学习 - 可视化变量赋值、循环、程序运行过程](https://mp.weixin.qq.com/s/zhr251PCTDGBO1YxYB-P6Q)
* [Python极简教程 （一）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483866&amp;idx=1&amp;sn=310341a1c8d348958c304df03dfd06a0&amp;chksm=ec0dc450db7a4d46e369637cd2867b0e56389bf4f2e1d0dce409bba38882e61e5063308a13af#rd)
* [Python教程（二）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483866&amp;idx=2&amp;sn=bf3c07ee1b2936c7ea06b5d4ca820545&amp;chksm=ec0dc450db7a4d469f4f625babfb595b068137ea2b25a7682f9fb58ff771db6543f43def7950#rd)
* [Python教程（三）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483866&amp;idx=3&amp;sn=dec66c5f3f12919ce1b0bfbb545e3935&amp;chksm=ec0dc450db7a4d46e91b65446d6a192056ab6ff27c019fe3770cc32816b0ae3f16659ebba0a5#rd)
* [Python教程 （四）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483866&amp;idx=4&amp;sn=3a0b0c5c0f736ddeadc4524bae8b2a91&amp;chksm=ec0dc450db7a4d465602b74e0fa968519a3a085a1901b5cca97ff886163422a24089378ff8f0#rd)
* [Python教程（五）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483866&amp;idx=5&amp;sn=fd3526e11c4adf8194e1f92cd6d1749c&amp;chksm=ec0dc450db7a4d468c7d114352153eecbaedd7d37065f681caa28b74258a92038d1d2030056b#rd)
* [Python教程 （六）](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483866&amp;idx=6&amp;sn=ef7a0972abc002cfeba27815020e83aa&amp;chksm=ec0dc450db7a4d46f61328946fe257a1516785fb9a1f7c1663e86e4255ae6b616e3c07ac1cb0#rd)
* [Pandas，让Python像R一样处理数据，但快](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483865&amp;idx=1&amp;sn=a2e1474bbebce343ff4262e38653f4c4&amp;chksm=ec0dc453db7a4d45349076b1627eff5e292abceada59e832a46553f4ca614d62df96e097f871#rd)
* [Python解析psiBlast输出的JSON文件结果](http://mp.weixin.qq.com/s/BN6u2aJkoMzffPv7rvbm8g)
* [为啥我的Python这么慢 - 项查找 (二)](http://mp.weixin.qq.com/s/-0UTgmdRQbF7I4fib62ooA)
* [为啥我的Python这么慢 (一)](https://mp.weixin.qq.com/s/n5kkZfC8FGlzeBODarLHcw)
* [Python资源](http://mp.weixin.qq.com/s/1JlAROpOCBwaG574EwvkVw)
* [关于Python中的__main__和编程模板](http://mp.weixin.qq.com/s/JHDvdqq3Z-7uDmsyroblNQ)

### NGS软件

* [Rfam 12.0+本地使用 （最新版教程）](http://mp.weixin.qq.com/s/5OIRHA22ZLr5Z8bEhDiBqg)
* [轻松绘制各种Venn图](http://mp.weixin.qq.com/s/zn654JqG9OeO71rJUTDr2Q)
* [ETE构建、绘制进化树](http://mp.weixin.qq.com/s/DD1nZnx5mYxWGrohNgdPvQ)
* [psRobot：植物小RNA分析系统](http://mp.weixin.qq.com/s/kWkEQOX-6SKMAUQmAuc86w)
* [生信软件系列 - NCBI使用](http://mp.weixin.qq.com/s/4a5U8GdBoNFXkykL6m2EeA)
* [去东方，最好用的在线GO富集分析工具](https://mp.weixin.qq.com/s/l6j2encDfEQkt2UeNCMFhg)

### Cytoscape网络图

* [Cytoscape教程1](http://mp.weixin.qq.com/s/m9uJm8GwSXb3xaRxtod08Q)
* [Cytoscape之操作界面介绍](http://mp.weixin.qq.com/s/ZSoW7-qWs3BuSB7bkDnfmA)
* [新出炉的Cytoscape视频教程](http://mp.weixin.qq.com/s/sKEy_Pn9qnWw4W-aXraA5g)

### 分子对接

* [来一场蛋白和小分子的风花雪月](http://mp.weixin.qq.com/s/asAJDttAvsCLGd3PPU2agQ)
* [不是原配也可以-对接非原生配体](http://mp.weixin.qq.com/s/VDN1qAZGIMol6prwQW4umw)
* [简单可视化-送你一双发现美的眼睛](http://mp.weixin.qq.com/s/P62sjqhSTxmWVicrEAk-RQ)
* [你需要知道的那些前奏](http://mp.weixin.qq.com/s/5a5-6pXHfvyDc2Kfp4xDeQ)

### 生信宝典之傻瓜式

* [生信宝典之傻瓜式 (一) 如何提取指定位置的基因组序列](http://mp.weixin.qq.com/s/5bNdHkl3QDFmCNmrht3VWA)
* [生信宝典之傻瓜式 (二) 如何快速查找指定基因的调控网络](http://mp.weixin.qq.com/s/LPWaxbKuS-XlvzkSE-MupQ)
* [生信宝典之傻瓜式 (三) 我的基因在哪里发光 - 如何查找基因在发表研究中的表达](http://mp.weixin.qq.com/s/0Yvhn5Tlb-zvOXM0cU16Zg)
* [生信宝典之傻瓜式 (四) 蛋白蛋白互作网络在线搜索](http://mp.weixin.qq.com/s/JO1J66BtzuY-9a20x0XQcg)
* [生信宝典之傻瓜式 (五) 文献挖掘查找指定基因调控网络](http://mp.weixin.qq.com/s/DQ4fjCL777D2iEcPTnd-rA)

### 生信人写程序

* [生信人写程序1. Perl语言模板及配置](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483837&amp;idx=1&amp;sn=660358a38b7fa6d3de2c95280f7a4535&amp;chksm=ec0dc437db7a4d21368b312ac43ceae552e1544570639c949e96bf488113a55f67fa2306008e#rd)
* [生信人写程序2. Editplus添加Perl, Shell, R, markdown模板和语法高亮](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247483910&amp;idx=1&amp;sn=7813eaa4841d90b0bfc3982bb901de81&amp;chksm=ec0dc78cdb7a4e9a866f3e0cade3096a13366cac18c873820434f066fdba9bd22a7b5b3d210d#rd)

### 小技巧系列

* [参考文献中杂志名字格式混乱问题一次解决](http://mp.weixin.qq.com/s/Diwevx-TVe0Vq_rdgzIkrw)

### 招聘

* [易汉博欢迎您加入](http://mp.weixin.qq.com/s?__biz=MzI5MTcwNjA4NQ==&amp;mid=2247484036&amp;idx=5&amp;sn=bb1007d2c3d60e7a2bcf2d6fc7a9a2bb&amp;chksm=ec0dc70edb7a4e185bafd0f49440bf1a032915c7e8d8fc2cb37c70a81ce3446a4ae990df89a5#rd)

## 宏基因组

<http://mp.weixin.qq.com/s/5jQspEvH5_4Xmart22gjMA>

宏基因组/微生物组是当今世界科研最热门的研究领域之一，为加强本领域的技术交流与传播，推动中国微生物组计划发展，中科院青年科研人员创立“宏基因组”公众号，目标为打造本领域纯干货技术及思想交流平台。

本公众号每日推送，工作日分享宏基因组领域科研思路、实验和分析技术，理论过硬实战强；周末科普和生活专栏，轻松读文看片涨姿势。目前经过近半年发展，分享过百篇原创文章，已有14000+小伙伴在这里一起交流学习，感兴趣的赶快关注吧。

### 精选文章推荐

**5000+**

- [微生物组入门必读+宏基因组实操课程](http://mp.weixin.qq.com/s/sQyl5EctXFB95Oxg8YIasg)
- [你想要的生信知识全在这—生信宝典](http://mp.weixin.qq.com/s/2b3_8Vvv7McqCkEfUszW3A)
- [生物信息9天速成班—成为团队不可或缺的人](http://mp.weixin.qq.com/s/1nf7vwyvC3oemkTq_pu87A)
- [3分和30分文章差距在哪里？](http://mp.weixin.qq.com/s/kD-x7K4hI5KMgGXikyLt0Q)
- [肠道菌群在人体中的作用](http://mp.weixin.qq.com/s/3T768LA6MWujF4yuzK4MKQ)
- [看完此片我想把身上的细菌寄生虫供起来](http://mp.weixin.qq.com/s/_DUI6tOYTEq0Wu7K7iRTxw)
- [岛国科普—生命大跃进](http://mp.weixin.qq.com/s/O_0Il0G_v_aSwkUH_noZVA)
- [我们的未来在哪里？](https://mp.weixin.qq.com/s/l141ggt2c-h7Eymc0UQnfQ)
- [论文图表基本规范](http://mp.weixin.qq.com/s/SCT4oso_vI0UNIJZTaG95g)
- [DNA提取发Nature](http://mp.weixin.qq.com/s/lO5uiMjixJ6aYTjPX-IyaQ)
- [实验vs数据分析，谁对结果影响大?](http://mp.weixin.qq.com/s/cL_IAoPFfmelKMPMgltrfA)

**3000+**

- [扩增子图表解读-理解文章思路](http://mp.weixin.qq.com/s/oiVHO2S1JgYrKXPDU6fH2g)
- [扩增子分析流程-把握分析细节](http://mp.weixin.qq.com/s/KrYyy3jjzAL0rQzVfV6h4A)
- [扩增子统计绘图-冲击高分文章](http://mp.weixin.qq.com/s/6tNePiaDsPPzEBZjiCXIRg)
- [宏基因组分析教程](http://mp.weixin.qq.com/s/bcyvhFrNr6niqD13rQfZeg)
- [4500元的微生物组培训资料](http://mp.weixin.qq.com/s/li7SdZVaCEyFQF8h6MMh2A)
- [Co-occurrence网络图在R中的实现](http://mp.weixin.qq.com/s/s-Si_s5pk7EF5gueqruBRQ)
- [学术图表的基本配色方法](http://mp.weixin.qq.com/s/hq5p8Lqzn9Km2qVRLW2dVQ)
- [一文读懂进化树](https://mp.weixin.qq.com/s/GV8rU3FZdc8Y-x931k_yrQ)
- [自学生信-biostar handbook](http://mp.weixin.qq.com/s/JL-n2nD6YL8vwuRtTVmQlQ)
- [漱口水增加糖尿病，高血压风险](http://mp.weixin.qq.com/s/NxNcDljhyvubbYzVgggHfw)

**1000+**

- [微生物组——扩增子分析专题培训开课啦！！！](http://mp.weixin.qq.com/s/xxBC2VMpB7uz_rJFBSb5mQ)
- [最简单漂亮的免费在线生信绘图工具](http://mp.weixin.qq.com/s/O0QAQyfxnrXlFLw268B7lg)
- [小学生都学Python了，你还不知道怎么开始](http://mp.weixin.qq.com/s/RaxOgjq4hyr-RNGSB-RGzg)
- [五彩进化树与热图更配-ggtree美颜进化树](http://mp.weixin.qq.com/s/yWzFAS8Nk6fpTuAJzbG6nA)
- [扩增子分析还聚OTU就真OUT了](http://mp.weixin.qq.com/s/D3qKT7mYEg52nCfQWF75wg)
- [主流非聚类方法dada2,deblur和unoise3介绍与比较](http://mp.weixin.qq.com/s/hU4AavhMQcebNhBtMUg1tw)
- 16S预测微生物群落功能 [0概述](http://mp.weixin.qq.com/s/sztbvfdf9wa-3HJXc_m8TQ)   [1KO通路PICRUSt](https://mp.weixin.qq.com/s/LWtiwBbUCAadMZPaKKDMag)  [2元素循环FAPROTAX](http://mp.weixin.qq.com/s/J8EwJD_PTDhqRaD7kXlK1A)  [3表型bugbase](https://mp.weixin.qq.com/s/1WdysPZWo0H6NSYiNpcMUQ) [4KO通路Tax4Fun](http://mp.weixin.qq.com/s/dzsh44ue93xnAs7gTde7wg)  
- [一文读懂微生物组](https://mp.weixin.qq.com/s/KT4hJFbJFnGPQQYgQUd8fg)
- [2017年发展简史和十大热文盘点](https://mp.weixin.qq.com/s/9sUOcZTsfOXBjj03OHGy6Q)

### 培训、会议、征稿、招聘

- [3月10-19日，北京，微生物组——扩增子分析专题培训](http://mp.weixin.qq.com/s/xxBC2VMpB7uz_rJFBSb5mQ)
- [5月11-13日，北京，中国肠道大会](http://mp.weixin.qq.com/s/b_ron-vL6n-0CDJW87l2rQ)

### 科研经验

- [如何优雅的提问](http://mp.weixin.qq.com/s/H9gkepap0hy3NNskOkO44w)
- [公众号搜索方法大全](http://mp.weixin.qq.com/s/wn2bqIPgT5UD-GP1qzkJFA)
- **科研团队成长三部曲**：[1云笔记](http://mp.weixin.qq.com/s/OnwhWlq3cTycf-W1rxgV7g) [2云协作](http://mp.weixin.qq.com/s/W5By9mZ5PI57_xFfZ_JXiw) [3公众号](http://mp.weixin.qq.com/s/hd0sdBDAMqMJsXQs0pIjUg)
- 文献阅读 [1热心肠](http://mp.weixin.qq.com/s/1uBeAQ0utxuzTTtfUx_UXA) [2SemanticScholar](https://mp.weixin.qq.com/s/gaQiUrRqLpfTXzjyfbua6A) [3geenmedical](https://mp.weixin.qq.com/s/hc8g64aHN7qv8YhVfrsuvQ)
- 生信编程模板 [Perl](http://mp.weixin.qq.com/s/u2ZmTo-z6cbN-L6KVLYNwg)  [Shell](http://mp.weixin.qq.com/s/YevGR79NnBAF-xtrqL8gAA)  [R](http://mp.weixin.qq.com/s/OQiE882jM6pVwqTiIjyZ1Q)
- [生物信息之程序学习](http://mp.weixin.qq.com/s/xoLBg0pI9seEksa0hMXi0A)  
- [Endnote X8云同步：有网随时读文献](http://mp.weixin.qq.com/s/SPblPs5ByPdb2C400kIK3w)
- [论文Figures，你不能不知道的秘密](http://mp.weixin.qq.com/s/UQtKZ14_6WTyFYGZgiC00g)
- [转录组分析的正确姿势](http://mp.weixin.qq.com/s/sTzluM0EMNYLnwYa5JaKLg)
- [整个世界都是你的已知条件](http://mp.weixin.qq.com/s/9Sj5tI8RRa3uv2BgNarhxw)

### 软件和数据库使用

- SILVAngs:16S/18S在线分析[1](http://mp.weixin.qq.com/s/R4fzOl1JX097rxi18vfePw)  [2](http://mp.weixin.qq.com/s/2mv_w-RG50v54iojii7kuA)
- [METAGENassist帮你搞定宏基因分析的所有图形需求](http://mp.weixin.qq.com/s/kVrMGI8mtkJkltCpAbwUiw)
- [Windows不用虚拟机或双系统，轻松实现linux shell环境：gitforwindows](http://mp.weixin.qq.com/s/GYa5_0bcZO6Pfq-qim5vyA)
- [一条命令轻松绘制CNS顶级配图-ggpubr](http://mp.weixin.qq.com/s/EvlnWBI5OZOudWd0cieGJg)
- [ggbiplot-最好看的PCA图](http://mp.weixin.qq.com/s/GGCPxQEe_DXefdp-veQtag)
- [LDA分析、作图及添加置信-ggord](https://mp.weixin.qq.com/s/F9c_ISpOpjHyiCNahoYTqQ)
- [ggrepel-解决散点图样品标签重叠，方便筛选样品](http://mp.weixin.qq.com/s/hxBAlnK_1ZSGJQg1mwsssw)
- [Alpha多样性稀释曲线rarefraction curve](http://mp.weixin.qq.com/s/pQluUR7MYSZCheqVvAaNWA)
- [微生物组间差异分析神器-STAMP](http://mp.weixin.qq.com/s/f02mPAXCobPQijkIis-c2w)  
- [扩增子分析神器USEARCH](http://mp.weixin.qq.com/s/oJDfShs7gXCkOzYfa_winQ)
- [微生物扩增子数据库大全](http://mp.weixin.qq.com/s/DL7e6ihq6QppyW-87COiBg)  
- [antiSMASH：微生物次生代谢物基因簇预测](http://mp.weixin.qq.com/s/0MkmAw7f8uVQihrbUA2Z9Q)  
- [微生物网络构建：MENA, LSA, SparCC和CoNet](http://mp.weixin.qq.com/s/YPZar_aDmKE4W9s45NvhgQ)  
- [Cytoscape: MCODE增强包的网络模块化分析](https://mp.weixin.qq.com/s/jGHuP1ikCX0n3vKfS3VXPQ)
- [FUNGuild：真菌功能注释](http://mp.weixin.qq.com/s/pO3VCMLwEFLlcEgMQsUjDg) 
- [在线RaxML构建系统发育树](http://mp.weixin.qq.com/s/AWfT2szILVrCr25g0EdgvA)
- [Genevestigator: 查找基因在发表研究中的表达](https://mp.weixin.qq.com/s/mHBH-ooJ9vBpv0nvRFuF3A)
- [psRobot：植物小RNA分析系统](http://mp.weixin.qq.com/s/drpMN55hfbVwHbLYXC0oUw)  
- [RepeatMasker：基因组重复序列注释](http://mp.weixin.qq.com/s/vVamtB4mBAauqjpEFBg70A)  

### 扩增子学习三步曲

#### [1图表解读-理解文章思路](http://mp.weixin.qq.com/s/oiVHO2S1JgYrKXPDU6fH2g)  

#### [2分析流程-把握分析细节](http://mp.weixin.qq.com/s/KrYyy3jjzAL0rQzVfV6h4A)  

- [扩展1：视频教程-夯实分析思路](http://mp.weixin.qq.com/s/SxWl0qBJgg8ziZUFDmKvpQ)  
- [扩展2：QIIME2教程-了解分析趋势](http://mp.weixin.qq.com/s/wkn-91BVOSWZLRvlcaaEgg)  

#### [3统计绘图-冲击高分文章](http://mp.weixin.qq.com/s/6tNePiaDsPPzEBZjiCXIRg)  

### 宏基因组分析专题

- [1背景知识-Shell入门与本地blast实战](http://mp.weixin.qq.com/s/jASOBPzpwYCL-fWNUJJp8g)
- [2数据质控fastqc, Trimmomatic, MultiQC, khmer](http://mp.weixin.qq.com/s/3O01eNMe79J_kUTaJjP6ag)
- [3组装拼接MEGAHIT和评估quast](http://mp.weixin.qq.com/s/NMKX0iDuR_qOzmLXxC8MEQ)
- [4基因注释Prokka](http://mp.weixin.qq.com/s/1TM61IrzrpVb5KhZ5A0kZQ)
- [5基于Kmer比较数据集sourmash](https://mp.weixin.qq.com/s/Rmx-z1zxj7GF9ivJGWVvLg)
- [6不比对快速估计基因丰度Salmon](http://mp.weixin.qq.com/s/2fwEtnEsBi5cJ65xyeoXxw)
- [7bwa序列比对, samtools查看, bedtools丰度统计](http://mp.weixin.qq.com/s/rdTFTFg0rZOIa2_tuFEOUA)
- [8分箱宏基因组binning, MaxBin, MetaBin, VizBin](http://mp.weixin.qq.com/s/rZitcvykAlxnsNEzsW5JRg)
- [9组装assembly和分箱bin结果可视化—Anvi'o](http://mp.weixin.qq.com/s/FesH_mCunpZLpKC2pIg1UQ)
- [10绘制圈图-Circos安装与使用](http://mp.weixin.qq.com/s/FJlKY3kU5Fm6bYkjtwRkEw)
- [MetaPhlAn2分析有参宏基因组](http://mp.weixin.qq.com/s/xSjFGwcr1XIAZKdByJAWmQ)

### R统计绘图

- [视频教程：R语言recharts包绘制交互式图形](http://mp.weixin.qq.com/s/XOZD4ftYLPZjM2IVLYgUpA)
- [R语言聚类分析--cluster, factoextra](https://mp.weixin.qq.com/s/9EChqbVmFrNWi_Siu4hdqQ)
- [堆叠柱状图各成分连线画法：突出展示组间物种丰度变化](https://mp.weixin.qq.com/s/FZWinr14RTs6YSUE_juaug)
- [R相关矩阵可视化包ggcorrplot](http://mp.weixin.qq.com/s/AEfPqWO3S0mRnDZ_Ws9fnw)

### 实验设计与技术

- [微生物样本取样及微生物基因组DNA提取建议](http://mp.weixin.qq.com/s/L1XxsGDFt9wKk-4pSRwUUQ)
- 样品生物学重复数据选择 [1必要性](https://mp.weixin.qq.com/s/_qqeKbncKZmovajvPbskpA)  [2需要多少重复？](http://mp.weixin.qq.com/s/_qqeKbncKZmovajvPbskpA)
- 样品命名 [注意事项](http://mp.weixin.qq.com/s/3-UlDWEwCvU5TUlu-_ezmg)
- 扩增子引物选择 [16S结构](http://mp.weixin.qq.com/s/pBzh1LcdEy-EJop44z0mwA) [16S单V4区是最佳选择?](http://mp.weixin.qq.com/s/hMlfNQmXkt8o-ew_iSV30Q)
- [海洋可培养微生物的鉴定与分类](http://mp.weixin.qq.com/s/-0eqsE5slOyEcXFfjY7NNw)
- [怎么取粪便样品](http://mp.weixin.qq.com/s/fHwd2pc-E314JO_Ya4QEvQ)
- [Rhizosphere、Rhizoplane根际土如何取](http://mp.weixin.qq.com/s/6hOd-NV1TNXGQdxL0k9l0g)
- [Nat. Biotechnol.扩增子测序革命—用16S及18S rRNA全长进行微生物多样性研究](http://mp.weixin.qq.com/s/vUtQmuj1vIoH9L0J-YT5fQ)

### 基础知识

- [Microbiota, metagenome, microbiome区别](http://mp.weixin.qq.com/s/kBbWD6ircc4UHE-ma-6a1Q)
- [16S测序，不知道OTU你就out了！](http://mp.weixin.qq.com/s/yDmUgRzgJDtxdiJqwpGM1A)
- [计量宏基因组学数据分析的方法及进展](http://mp.weixin.qq.com/s/cDq1vwMig2V0lJrswP3gcA)
- [排序方法比较大全PCA、PCoA、NMDS、CCA](http://mp.weixin.qq.com/s/juMOVzZfdUD4w9M2l1Bh6g)
- [LEfSe分析，你真的懂了么](http://mp.weixin.qq.com/s/5K8OTMee6CwDZz51YWJEDg)
- [宏基因组基础知识梳理](http://mp.weixin.qq.com/s/d-cmrrnFlI8gOBQtKLHxWw)
- 扩增子SCI套路[1微群落结构差异](http://mp.weixin.qq.com/s/tRc4PBS-PZh6ghxX1nlNcw) [2组间差异分析](http://mp.weixin.qq.com/s/yI1KlyluNyoPM0DE5LOAfg) [3系统总结](http://mp.weixin.qq.com/s/V4VCrJU4cSSpof2QDoDKNQ)
- [环境因子关联分析——我应该选择CCA还是RDA分析？](http://mp.weixin.qq.com/s/8D4vlBIhyYg0ZHtsdGn_kA)
- [“P值”背后那些不可不知的事儿](http://mp.weixin.qq.com/s/lKkvJ7s8dshe7mvDOnl6_w)
- [Adonis和ANOSIM方法组间整体差异评估原理](http://mp.weixin.qq.com/s/b2kjedvI-8hYSkTQxKUalA)
- [轻松看懂机器学习十大常用算法](http://mp.weixin.qq.com/s/sU__UxDDmhs-4pMGX-5rSQ)
- [一文读懂“随机森林”在微生态中的应用](http://mp.weixin.qq.com/s/58VAF03uO3nBPfp7eboqUA)
- [你想知道的“ROC曲线”](http://mp.weixin.qq.com/s/wRISqBabnFrtWD4TrCgBOg)
- [人体对微生物的管控](https://mp.weixin.qq.com/s/DYykdQ8DtBRIG7rzEK9Xug)
- [简单读懂微生物基因组的泛基因组学](http://mp.weixin.qq.com/s/p7PMqo2Ld0Kbm8_3IgRuuQ)

### 必读综述

- [Nature：宏基因组关联分析](http://mp.weixin.qq.com/s/CcDuohwezquBRhBW3FvMSg)
- [Nature：肠道菌群如何划分肠型](http://mp.weixin.qq.com/s/K3t7BpJ3LZvi4RNf69cJeA)
- [Nature: 来自细菌的通告——群感效应简介](http://mp.weixin.qq.com/s/8ltHVYeYksKLCs70FUctpg)
- [Nature：呼吸道菌群—呼吸道健康的守门人](http://mp.weixin.qq.com/s/DBYuQh4Pz2ZNpFXW71dD_Q)
- [Nature: 拥抱未知-解析土壤微生物组的复杂性](http://mp.weixin.qq.com/s/Ff1s8SzMkfHKmM2vbcI7mw)
- [Cell：代谢控制中的脑肠轴](http://mp.weixin.qq.com/s/cwElaRsaInfabuz0VF60gA)
- [研究微生物，只靠多组学根本不够](http://mp.weixin.qq.com/s/OuK8frQaXPUoeFqXazkEgw)  
- [中国微生物组计划—农作物微生物组](https://mp.weixin.qq.com/s/Ssy1Rq8bWrBzymWI-Xslmw)  
- [Annu Rev：植物微生物组—系统见解与展望](https://mp.weixin.qq.com/s/rx2ae4BcXqqkeX5LDi0h-Q)  
- [Annual Reviews|微生物组与人](http://mp.weixin.qq.com/s/DVJSY3zKKI3IDV9vW3khJw)
- [微生物组学与植物病害微生物防治](https://mp.weixin.qq.com/s/Bba4ddqyvj2C0Mdx6cUm8A)  
- [组学重建真菌现有分类系统](https://mp.weixin.qq.com/s/qpK28hjqvtPSCKKB9lWtYg)  
- [微生物应用|农业废弃物资源化利用](http://mp.weixin.qq.com/s/zCk85qBaY5u5IHHHr99NNQ)  
- 宏基因组学入门[1初识](http://mp.weixin.qq.com/s/xVJtplV6LLofrt5DKqA9vA)  [2进一步](http://mp.weixin.qq.com/s/Otz6Kk_g4N_pu5vHWaJCfA)  [3拼接](http://mp.weixin.qq.com/s/a1b-4bdjushFn1PqJ6NU2Q)  
- [肠道微生物与人类密切相关的方方面面](http://mp.weixin.qq.com/s/KposoZo9X1TYxRCHYlLbtw)
- [Nature: 测序技术的前世今生](http://mp.weixin.qq.com/s/H-LF6dax0uYeJ-H1gDwycQ)
- [Nature Reviews：全新的益生元定义和范围](http://mp.weixin.qq.com/s/hMImkvaugXD6Jkv9i0SvTQ)
- [原核转录组非编码RNA研究](http://mp.weixin.qq.com/s/MwEHXbPdpkKO5tuNKjqI8Q)

### 高分文章套路解读

- [Nature: 培养组学—高通量细菌分离培养鉴定](http://mp.weixin.qq.com/s/_xaxicmV5cyKfnYoKHQQbg) 
- [SR: 真菌培养组学同揭示人类肠道真菌群落结构](https://mp.weixin.qq.com/s/_DjxjlXH3URKpZN50zPqWQ)
- [Nature: 地球微生物组计划首发成果—揭示地球多尺度微生物多样性](http://mp.weixin.qq.com/s/q9Tqbd8VITkYtZIFbByLtg)
- [Nature：如何做一篇肠道菌群免疫的顶级文章](http://mp.weixin.qq.com/s/tiBLevKw9HNAW9I0A_Of8A)
- [Nat Biotech: 宏表观组—DNA甲基化辅助宏基因组binning](http://mp.weixin.qq.com/s/j9HolFL4bqbjcLHrp4OJAA)
- [Nature: 甘露糖苷选择性抑制致病性大肠杆菌](http://mp.weixin.qq.com/s/45L9UNx7eqkMxFbckoTEYQ)  
- [Nature: 拟南芥根微生物组的结构和组成](http://mp.weixin.qq.com/s/OlFgv-ttRnFdIGXxYjoisw)  
- [Nature: 地球上最古老的热液喷口发现早期生命迹象](http://mp.weixin.qq.com/s/uth0BFcvAePl4dSGzv-psQ)
- [Nature Method: 宏基因组软件评估—人工重组宏基因组基准数据集](http://mp.weixin.qq.com/s/kDYiFfJ8egosETwLpKCFLQ)   
- [Nature Genetics：微生物基因组如何适应植物？(news & views)](http://mp.weixin.qq.com/s/rYyeVFp_ss9lITCytc9LUw)
- [NC：降低微生物群落复杂度突破组装难题](http://mp.weixin.qq.com/s/K8PwcuyWs3gnUEGwYEMceA)  
- [NC：自体免疫水泡皮肤病中鉴定基因与微生物组互作](https://mp.weixin.qq.com/s/kZ-_TsNcsrLJPaxqUex0Cg)  
- [GigaScience:植物MWAS研究—谷子产量与微生物组关联分析](http://mp.weixin.qq.com/s/TNCos80soqLAbhxHptRUhA)  
- [Microbiome：微生物组研究中你必须注意的细节](http://mp.weixin.qq.com/s/m1znPpGR6NbewL2AtJkKPw)  
- [Microbiome：HiSeq平台16S扩增子文库构建方法](http://mp.weixin.qq.com/s/E1qMskVQ64y6MKE8zDvNmQ)  
- [Microbiome: 简单套路发高分文章--杨树微生物组](http://mp.weixin.qq.com/s/Zod4Ca1tk3y5lIdI6RCiQQ)  
- [Microbiome：肠道菌群失衡促进高血压](http://mp.weixin.qq.com/s/n5u-Vm5e53x7XcxwYDbTRQ)  
- [Microbiome：重新定义“卫生”概念](http://mp.weixin.qq.com/s/jiQsN3sPgbJcdVa-SuSvGQ)
- [ME：网络分析揭示微生物群落应对环境扰动的稳定性机制](http://mp.weixin.qq.com/s/649mjxr62v9RHp3AGWLzpg)
- [SR: 土壤细菌定量方法结合相对丰度分析揭示种群的真实变化](http://mp.weixin.qq.com/s/ipBhAagpEPn1EIKXDUlGRw)

### 科普视频-寓教于乐

- [BBC人体奥秘之细胞的暗战](http://mp.weixin.qq.com/s/M35ebWAelDIK5Iqib06JzA)
- [BBC人体奥秘 Inside.the.Human.Body](https://mp.weixin.qq.com/s/xlCdN8il1hcutkYK-42fAQ)
- [NG人体内旅行Inside.the.Living.Body](http://mp.weixin.qq.com/s/xqgolgPlRDYQDkDiWu8zOA)
- [NG子宫日记 Womb](http://mp.weixin.qq.com/s/XZ5yNW56Bf4NFkcbuxgQYw)  
- [NHK: 再造人类生命的神奇细胞](https://mp.weixin.qq.com/s/IHN4O5xk6ySV5EC8QpBjDw)
- [CCTV9让尸体说话-法医密档](http://mp.weixin.qq.com/s/sHTTd_Rb7XibV4CoCVzcAQ)
- [豆瓣8.9，惹哭亿万中国人的纪录片-本草中华](http://mp.weixin.qq.com/s/nR2EiQYcEYH3VeR3RDlT5w)
- [2分钟视频回顾植物学家钟扬的贡献](http://mp.weixin.qq.com/s/qul0uhcLY3xS4Dyxbd7GaA)
- [一顿“寄生虫大餐”，或能治好干净引来的免疫病](https://mp.weixin.qq.com/s/hX0K9TOLPnrZ6f8lUoSYag)
- [只要11天，浓度1000倍的抗生素也无效——超级细菌](http://mp.weixin.qq.com/s/SXmXlu7XFnO9fIgejSWdtA)
- [致命病毒为何疯狂袭击人类？都怪我们那群会飞的远房亲戚](http://mp.weixin.qq.com/s/CAh-hYRCfvQbyDeh6xlyYA)
- [土豆上的小霉菌引发百万人死亡和逃难，却造就全球7千万后裔](http://mp.weixin.qq.com/s/jv2ZKWqDTB_IyLeMImHvDw)
- [看完这些能控制大脑的寄生虫，你会怀疑人类！](http://mp.weixin.qq.com/s/P2od51617RZGxrmLBMSKZw)
- [梅毒狂想曲](http://mp.weixin.qq.com/s/XfeuKLLg3ruXUCFnFAisog)

### 友军文章汇总推荐

- [学习生信的系列教程](https://mp.weixin.qq.com/s/VguRtaGpEcaNzmZEi48gLg)——纯生信一作发IF>20的大神


<!--chapter:end:11.ref.Rmd-->

